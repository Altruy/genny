{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Altruy/genny/blob/main/rag_for_hybrid_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ea1c38-24ac-46ee-b8f5-fdeb65511131",
      "metadata": {
        "id": "61ea1c38-24ac-46ee-b8f5-fdeb65511131"
      },
      "source": [
        "# RAG Chat Bot for Hybrid Search\n",
        "\n",
        "This is the accompanying notebook for the [Oct 19 (2023) RAG for Hybrid Search meetup](https://www.pinecone.io/community/events/sf-meetup-october-2023/).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9960f94c-11a1-4c9b-99fc-0552e3f20886",
      "metadata": {
        "id": "9960f94c-11a1-4c9b-99fc-0552e3f20886"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/rag-for-hybrid/rag-for-hybrid-search.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/rag-for-hybrid/rag-for-hybrid-search.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I1Pm3RfT6hjO",
      "metadata": {
        "id": "I1Pm3RfT6hjO"
      },
      "outputs": [],
      "source": [
        "!pip3 install colab-xterm # Just makes the shell commands interactive, in case you have to press ENTER or type in 'Y/n' etc.\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3b8d11-6a04-4e7c-ace2-2bc28ab64b7f",
      "metadata": {
        "id": "bc3b8d11-6a04-4e7c-ace2-2bc28ab64b7f"
      },
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "\n",
        "%xterm\n",
        "\n",
        "!pip3 install -qU \\\n",
        "  \"pinecone-client[grpc]\" \\\n",
        "  pinecone-text==0.5.4 \\\n",
        "  unstructured==0.10.24 \\\n",
        "  sentence-transformers==2.2.2 \\\n",
        "  langchain==0.0.327 \\\n",
        "  openai==0.28.1 \\\n",
        "  pdfminer.six \\\n",
        "  pdf2image==1.16.3 \\\n",
        "  python-dotenv==1.0.0 \\\n",
        "  pytesseract==0.3.10 \\\n",
        "  unstructured_pytesseract==0.3.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5g-la06jXtsn",
      "metadata": {
        "id": "5g-la06jXtsn"
      },
      "outputs": [],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6hrtPeeIa-I7",
      "metadata": {
        "id": "6hrtPeeIa-I7"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6af345ef-6321-4a30-b2e3-9e84cbd4d5b2",
      "metadata": {
        "id": "6af345ef-6321-4a30-b2e3-9e84cbd4d5b2"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0520a370-63a3-4f16-8cf1-acfc8cc7f914",
      "metadata": {
        "id": "0520a370-63a3-4f16-8cf1-acfc8cc7f914"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from uuid import uuid4\n",
        "from typing import IO, Any, Dict, List, Tuple\n",
        "from copy import deepcopy\n",
        "import requests\n",
        "\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from unstructured.documents.elements import Text\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone\n",
        "from openai import OpenAI\n",
        "from pinecone.core.client.model.query_response import QueryResponse\n",
        "import pandas as pd\n",
        "\n",
        "from pinecone_text.sparse import BM25Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5858c70-9d3f-437d-a289-066ae69a64e2",
      "metadata": {
        "id": "c5858c70-9d3f-437d-a289-066ae69a64e2"
      },
      "source": [
        "Set up the environment variables we'll need. We recommend using `dotenv`. It's a super simple way to keep your variables safe, but accessible. Simply create a `.env` file with your secrets in it, and use the Python `dotenv` and `os` libraries to load them.\n",
        "\n",
        "To import your `.env` file into Colab, upload it (or create it) in the `/content/` dir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb61e9a-c191-489a-90e2-48df47e0c77b",
      "metadata": {
        "id": "8fb61e9a-c191-489a-90e2-48df47e0c77b"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62f04ff-5339-4097-b8e4-98a29450e879",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62f04ff-5339-4097-b8e4-98a29450e879",
        "outputId": "aec7e86b-fde5-45ab-c181-296a87221ce5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sure dotenv is in our kernel environment & working\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d6d9c5-2cf2-4796-8141-564e1b94994b",
      "metadata": {
        "id": "e0d6d9c5-2cf2-4796-8141-564e1b94994b"
      },
      "outputs": [],
      "source": [
        "pinecone_api_key = os.getenv('PINECONE_API_KEY')  # You can get your Pinecone api key and env (e.g. \"us-east-1\") at app.pinecone.io\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535ecd2e-fe6e-40fb-99bf-8b8333ef01fe",
      "metadata": {
        "id": "535ecd2e-fe6e-40fb-99bf-8b8333ef01fe"
      },
      "outputs": [],
      "source": [
        "# Let's make sure our dotenv secrets loaded correctly\n",
        "\n",
        "assert len(pinecone_api_key) > 0\n",
        "assert len(openai_api_key) > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acfaeac9-d63a-4d5a-b316-f714f032c421",
      "metadata": {
        "id": "acfaeac9-d63a-4d5a-b316-f714f032c421"
      },
      "source": [
        "# Download some articles we're interested in learning more about.\n",
        "\n",
        "Remember, hybrid search is best for knowledge that contains a lot of unique keywords that you'd like to search for, along with concepts you'd like clarity on, etc. Data that works best for this type of thing include medical data, most types of research data, data with lots of entities in it, etc.\n",
        "\n",
        "We'll be using Arxiv.org articles about different vector search algorithms for this demo. They've got lots of jargon and concepts that'll work great for hybrid search!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc05aea-08ac-493a-8bfe-6b0a90dbfb8f",
      "metadata": {
        "id": "9cc05aea-08ac-493a-8bfe-6b0a90dbfb8f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def get_pdf(base_url: str, filename: str):\n",
        "    \"\"\"\n",
        "    Download and write a PDF file from a github repository.\n",
        "\n",
        "    :param url: URL of Github repository containing the file you want to download & write locally.\n",
        "    \"\"\"\n",
        "    res = requests.get(base_url+filename)\n",
        "    # Check if the request was successful (HTTP status code 200)\n",
        "    if res.status_code == 200:\n",
        "      with open(filename, 'wb') as f:\n",
        "          f.write(res.content)\n",
        "          print(f\"PDF downloaded and saved as {filename}\")\n",
        "    else:\n",
        "      print(f\"Failed to download the PDF. HTTP status code: {res.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f32da6-5ae9-47ac-a3d3-06bcdef1dfb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5f32da6-5ae9-47ac-a3d3-06bcdef1dfb7",
        "outputId": "6a9627fa-80b8-4432-ecbb-bc0c42d52450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF downloaded and saved as freshdiskann_paper.pdf\n",
            "PDF downloaded and saved as hnsw_paper.pdf\n",
            "PDF downloaded and saved as ivfpq_paper.pdf\n"
          ]
        }
      ],
      "source": [
        "# Download our files to the /content/ dir in Colab\n",
        "\n",
        "github_dir = \"https://github.com/pinecone-io/examples/raw/master/learn/generation/rag-for-hybrid/\"\n",
        "filenames = [\"freshdiskann_paper.pdf\", \"hnsw_paper.pdf\", \"ivfpq_paper.pdf\"]\n",
        "\n",
        "for f in filenames:\n",
        "  get_pdf(github_dir, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tpgyK79h8ta0",
      "metadata": {
        "id": "tpgyK79h8ta0"
      },
      "outputs": [],
      "source": [
        "# Read in our file paths\n",
        "# Note: change this path to your local dir if running this notebook locally (i.e. not on Colab)\n",
        "\n",
        "freshdisk = os.path.join(\"./\", filenames[0])\n",
        "hnsw = os.path.join(\"./\", filenames[1])\n",
        "ivfpq = os.path.join(\"./\", filenames[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e91a7b-2287-4200-b268-da25dec4f8c9",
      "metadata": {
        "id": "c8e91a7b-2287-4200-b268-da25dec4f8c9"
      },
      "source": [
        "# Partitioning & Cleaning our PDFs\n",
        "\n",
        "This step is optional. Partitioning simply uses ML to break a document up into pages, paragraphs, the title, etc. It's a nice-to-have that allows you to exclude certain elements you might not want to index, such as an article's bibliography (although we'll keep that since it could be useful information).\n",
        "\n",
        "If you want to skip this step, you can just read the PDFs into text or json, etc. and make your chunks straight from that object(s).\n",
        "\n",
        "Note: this notebook assumes you have partitioned your PDF. If you want to run this notebook from start to finish as-is, you'll need to run this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fd90300-2c17-4b6d-bd12-624453c82fcc",
      "metadata": {
        "id": "2fd90300-2c17-4b6d-bd12-624453c82fcc"
      },
      "outputs": [],
      "source": [
        "# Let's partition all of our PDFs and store their partitions in a dictionary for easy retrieval & inspection later\n",
        "\n",
        "# Note: This takes a few mins to run (~12 mins; will be faster if running locally (~3 mins))\n",
        "\n",
        "partitioned_files = {\n",
        "    \"freshdisk\": partition_pdf(freshdisk, url=None, strategy = 'ocr_only'),\n",
        "    \"hnsw\": partition_pdf(hnsw, url=None, strategy = 'ocr_only'),\n",
        "    \"ivfpq\": partition_pdf(ivfpq, url=None, strategy = 'ocr_only'),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0867ae78",
      "metadata": {
        "id": "0867ae78",
        "outputId": "5efdf195-3911-41f7-b0aa-2dee8c145a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To determine the optimal value of a, we perform the Fresh- Vamana steady-state experiments with different values of a. In the plots in Figure 3, we use the same value of a for'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partitioned_files[\"freshdisk\"][410].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1cb1014-b774-42ba-8eb1-598762f3b434",
      "metadata": {
        "id": "b1cb1014-b774-42ba-8eb1-598762f3b434"
      },
      "outputs": [],
      "source": [
        "# Let's make an archived copy of partitioned_files dict so if we mess it up while cleaning, we don't have to re-ocr our PDFs:\n",
        "\n",
        "partitioned_files_copy = deepcopy(partitioned_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7c9628-de78-45b1-946b-50e525e42f23",
      "metadata": {
        "id": "ea7c9628-de78-45b1-946b-50e525e42f23"
      },
      "outputs": [],
      "source": [
        "partitioned_files.get('freshdisk')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1173112f-8449-4449-b520-2a19740fd940",
      "metadata": {
        "id": "1173112f-8449-4449-b520-2a19740fd940"
      },
      "source": [
        "You can see in the preview above that each of our PDFs now has elements classifying different parts of the text, such as `Text`, `Title`, and `EmailAddress`.\n",
        "\n",
        "Data cleaning matters a lot when it comes to hybrid search, because for the keyword-search part we care about each individual token (word).\n",
        "\n",
        "Let's filter out all of the email addresses to start with, since we don't need those for any reason."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0236621-8c64-453a-bb8b-44b7019c6671",
      "metadata": {
        "id": "a0236621-8c64-453a-bb8b-44b7019c6671",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def remove_unwanted_categories(elements: Dict[str, List[Text]], unwanted_cat: str) -> None:\n",
        "    \"\"\"\n",
        "    Remove partitions containing an unwanted category.\n",
        "\n",
        "    :parameter elements: Partitioned pieces of our documents.\n",
        "    :parameter unwanted_cat: The name of the category we'd like filtered out.\n",
        "    \"\"\"\n",
        "    for key, value in elements.items():\n",
        "        elements[key] = [i for i in value if not i.category == unwanted_cat]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00045ae3-4821-4200-a2fa-a3be94b216c1",
      "metadata": {
        "id": "00045ae3-4821-4200-a2fa-a3be94b216c1"
      },
      "outputs": [],
      "source": [
        "# Remove unwanted EmailAddress category from dictionary of partitioned PDFs\n",
        "\n",
        "remove_unwanted_categories(partitioned_files, 'EmailAddress')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e35647-586a-4887-975e-bb86d091b7cd",
      "metadata": {
        "id": "f9e35647-586a-4887-975e-bb86d091b7cd"
      },
      "source": [
        "No more `EmailAddress` elements!:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644d52c1-a0dd-4209-87c7-86f022630111",
      "metadata": {
        "id": "644d52c1-a0dd-4209-87c7-86f022630111"
      },
      "outputs": [],
      "source": [
        "# partitioned_files.get('freshdisk')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb46a39a-8dcd-46cd-bbfb-f755d1052754",
      "metadata": {
        "id": "bb46a39a-8dcd-46cd-bbfb-f755d1052754"
      },
      "source": [
        "To actually see what our elements are, we can call the `.text` attribute of each object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbabf1e0-656e-42e2-af4a-f6a3708e1cf2",
      "metadata": {
        "id": "dbabf1e0-656e-42e2-af4a-f6a3708e1cf2"
      },
      "outputs": [],
      "source": [
        "# Text preview of what's actually in one of our dictionary items:\n",
        "\n",
        "# [i.text for i in partitioned_files.get('freshdisk')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfade5a5-baa1-4479-8deb-8968cb8376ba",
      "metadata": {
        "id": "bfade5a5-baa1-4479-8deb-8968cb8376ba"
      },
      "source": [
        "You can see there are weird things like blank spaces, single letters, etc. as their own partitions. We don't want these either, so let's get rid of them.\n",
        "\n",
        "You can also see where some page breaks were that spanned single words -- these are identifiable by a word ending with a `- `. For these, we want to get rid of the `- ` and squish the word back together, so it makes sense.\n",
        "\n",
        "(You can also see that not all of the email addresses were caught by Unstructured's ML. It's too cumbersome to go through each doc and weed those out by hand, so we'll just have to leave them for now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22413a4e-1b61-41c6-83f3-1c7e3cc1ff54",
      "metadata": {
        "id": "22413a4e-1b61-41c6-83f3-1c7e3cc1ff54"
      },
      "outputs": [],
      "source": [
        "# Remove empty spaces & single-letter/-digit partitions:\n",
        "\n",
        "def remove_space_and_single_partitions(elements: Dict[str, List[Text]]) -> None:\n",
        "    \"\"\"\n",
        "    Remove empty partitions & partitions with lengths of 1.\n",
        "\n",
        "    :parameter elements: Partitioned pieces of our documents.\n",
        "    \"\"\"\n",
        "    for key, value in elements.items():\n",
        "        elements[key] = [i for i in value if len(i.text.strip()) > 1 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e8aa65-d26e-4fc7-8f34-0ec2bc72da00",
      "metadata": {
        "id": "33e8aa65-d26e-4fc7-8f34-0ec2bc72da00"
      },
      "outputs": [],
      "source": [
        "remove_space_and_single_partitions(partitioned_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "562a2d57-7f94-4ff9-8ef0-96e5fa1ed7d2",
      "metadata": {
        "id": "562a2d57-7f94-4ff9-8ef0-96e5fa1ed7d2"
      },
      "source": [
        "No more single-character partitions or partitions with only whitespace, perfect!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a7a897-8803-40eb-baaa-9dce221c03b3",
      "metadata": {
        "id": "b6a7a897-8803-40eb-baaa-9dce221c03b3",
        "outputId": "65c4f9e8-73ff-4880-b395-5378083e4406"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['arXiv:2105.09613v1 [cs.IR] 20 May 2021',\n",
              " 'FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search',\n",
              " 'Aditi Singh',\n",
              " 'Microsoft Research India',\n",
              " 'Abstract',\n",
              " 'Approximate nearest neighbor search (ANNS) is a funda- mental building block in information retrieval with graph- based indices being the current state-of-the-art [7] and widely used in the industry. Recent advances [51] in graph-based in- dices have made it possible to index and search billion-point datasets with high recall and millisecond-level latency on a single commodity machine with an SSD.',\n",
              " 'However, existing graph algorithms for ANNS support only static indices that cannot reflect real-time changes to the corpus required by many key real-world scenarios (e.g. index of sentences in documents, email or a news index). To overcome this drawback, the current industry practice for manifesting updates into such indices is to periodically re-build these indices, which can be prohibitively expensive.',\n",
              " 'In this paper, we present the first graph-based ANNS in- dex that reflects corpus updates into the index in real-time without compromising on search performance. Using update tules for this index, we design FreshDiskANN, a system that can index over a billion points on a workstation with an SSD and limited memory, and support thousands of concurrent real-time inserts, deletes and searches per second each, while retaining > 95% 5-recall@5. This represents a 5-10x reduc- tion in the cost of maintaining freshness in indices when compared to existing methods.',\n",
              " '1 Introduction',\n",
              " 'In the Nearest Neighbor Search problem, we are given a dataset P of points along with a pairwise distance function. The goal is to design a data structure that, given a target k and a query point q, efficiently retrieves the k closest neigh- bors for q in the dataset P according to the given distance function. This fundamental problem is well studied in the research community [6, 9, 11, 16, 32, 35, 38, 43, 59] and is a critical component for diverse applications in computer vision [57], data mining [19], information retrieval [44], clas- sification [26], and recommendation systems [21], to name a few. As advances in deep learning have made embedding- based approaches the state-of-the-art in these applications, there has been renewed interest in the problem at scale. Sev- eral open-source inverted-index based search engines now support NNS [49, 50, 55], and new search engines based on',\n",
              " '“Work done while at Microsoft. + Authors listed in alphabetical order.',\n",
              " 'Suhas Jayaram Subramanya',\n",
              " 'Carnegie Mellon University',\n",
              " 'Ravishankar Krishnaswamy',\n",
              " 'Harsha Vardhan Simhadri',\n",
              " '{rakri, harshasi}@microsoft.com',\n",
              " 'Microsoft Research India',\n",
              " 'NNS are being developed [45, 56]. In newer applications of this problem, the dataset to be indexed and the queries are the output of a deep learning model — objects such as sentences or images are mapped so that semantically similar objects are mapped to closer points [10, 23]. These points reside in a space of dimension d (typically 100-1000), and the distance function is the Euclidean distance (¢) or cosine similarity (which is identical to f, when the data is normalized).',\n",
              " 'Since it is impossible to retrieve the exact nearest neigh- bors without a cost linear in the size of the dataset in the general case (see [32, 59]) due to a phenomenon known as the curse of dimensionality [20], one aims to find the approx- imate nearest neighbors (ANN) where the goal is to retrieve k neighbors that are close to being optimal. The quality of an ANN algorithm is judged by the trade-off it provides be- tween accuracy and the hardware resources such as compute, memory and I/O consumed for the search.',\n",
              " 'Even though this abstraction of ANN search is widely studied, it does not capture many important real-world sce- narios where user interactions with a system creates and destroys data, and results in updates to P (especially in the literature on graph-based ANNS indices [58]). For example, consider an enterprise-search scenario where the system in- dexes sentences in documents generated by users across an enterprise. Changes to sentences in a document would cor- respond to a set of new points inserted and previous points deleted. Another scenario is an email server where arrival and deletion of emails correspond to insertion and deletion of points into an ANNS index. ANNS systems for such ap- plications would need to host indices containing trillions of points with real-time updates that can reflect changes to the corpus in user searches, ideally in real-time.',\n",
              " 'Motivated by such scenarios, we are interested in solv- ing the fresh-ANNS problem, where the goal is to support ANNS on a continually changing set of points. Formally, we define the fresh-ANNS problem thus: given a time varying dataset P (with state P; at time t), the goal is to maintain a dynamic index that computes the approximate nearest neighbors for any query q issued at time t only on the active dataset P;. Such a system must support three operations (a) insert a new point, (b) delete an existing point, and (c) search for the nearest neighbors given a query point. The overall quality of a fresh-ANNS system is measured by:',\n",
              " 'The recall',\n",
              " 'latency tradeoff for search queries, and its robustness over time as the dataset P evolves.',\n",
              " 'Throughput and latency of insertions and deletions.',\n",
              " 'Overall hardware cost (CPU, RAM and SSD footprint) to build and maintain such an index.',\n",
              " 'We are interested in quiescent consistency [22, 31], where the results of search operations executed at any time t are consistent with some total ordering of all insert and delete operations completed before t.',\n",
              " 'We use the following notion of recall in this paper. !',\n",
              " 'Definition 1.1 (k-recall@k). For a query vector q over dataset P, suppose that (a) G C P is the set of actual k nearest neighbors in P, and (b) X C P is the output of a k-ANNS query to an index. Then the k-recall@k for the index for query q is oct Recall for a set of queries refers to the',\n",
              " 'average recall over all queries.',\n",
              " 'Goal. Motivated by real-world scenarios, we seek to build the most cost-effective system for the fresh-ANNS problem which can maintain a billion-point index using commodity machines with 128GB RAM and a 2TB SSD? and support thousands of real-time inserts and deletes per second, and also thousands of searches per second with high accuracy of 95+% 5-recall@5. Indeed, the current state-of-art system for fresh-ANNS which can support comparable update and search performance on a billion-point dataset is based on the classical LSH algorithm [54], and requires a hundred ma- chines of 32GB RAM (translating to around 25 machines of our stated configuration). In this work, we seek to reduce this deployment cost down to a single machine per billion points. To handle trillion-point indices (as in web-search scenar- ios), one can employ a simple distributed approach wherein thousand machines host a billion points each — queries are broadcast and results aggregates while updates are routed to the appropriate nodes.',\n",
              " '1.1 Shortcoming of existing algorithms',\n",
              " 'Of all the algorithms for static-ANNS, the ones most easily capable of supporting streaming support are the ones based on simple hashing algorithms such as LSH (locality sensitive hashing). However, these algorithms suffer from either being too memory intensive, needing to store hundreds of hash functions in main memory, or become extremely slow for query processing when the index is stored on secondary storage. For example, the state-of-art system for streaming similarity search (or fresh-ANNS), PLSH [54], is a parallel and distributed LSH-based mechanism. While it offers com- parable update throughput and search performance as our system, it ends up needing 25X more machines due to the high RAM consumption. A similar issue can be seen with',\n",
              " '1An index that provides good k-recall@k can be used to satisfy other notions of recall such as finding all neighbors within a certain radius. 2Henceforth, when we refer to “a machine”, we implicitly refer to this configuration unless otherwise specified.',\n",
              " 'PM-LSH, another state-of-art system based on LSH [62], where the memory footprint is a bit lower than PLSH (due to the system using fewer LSH tables), but the query laten- cies are an order of magnitude slower than our system and PLSH. Alternately, disk-based LSH indices such as SRS [53] can host a billion-point index on a single machine, but the query latencies are extremely slow with the system fetch- ing around 15% of the total index (running into GBs per query) from the disk to provide good accuracy. Another re- cent algorithm HD-Index [5] can serve a billion-point index with just a few megabytes of RAM footprint, but it suffers from search latencies of a few seconds to get accuracy of around 30%. Moreover, the algorithm only handles insertions, and simply performs a variant of blacklisting for deletions, and hence would need periodic rebuilding. Finally, there are other classes of ANNS algorithms such as kd-Tree [14], Cover Trees [17] which support reasonably efficient update policies, but these algorithms work well only when the data dimen- sionality is moderately small (under 20); their performance drops when the data dimensionality is 100 or more which is typical for points generated by deep-learning models..',\n",
              " 'At the other end of the spectrum of ANNS indices are graph-based indexing algorithms [28, 33, 34, 43, 51, 52]. Sev- eral comparative studies [7, 25, 41, 58] of ANNS algorithms have concluded that they significantly out-perform other techniques in terms of search throughput on a range of real- world static datasets. These algorithms are also widely used in the industry at scale. However, all known graph indices are static and do not support updates, especially delete re- quests [18], possibly due to the fact that simple graph modi- fication rules for insertions and deletions do not retain the same graph quality over a stream of insertions and deletions.',\n",
              " 'As a result, the current practice in industry is to period- ically re-build such indices from scratch [18] to manifest recent changes to the underlying dataset. However, this is a very expensive operation. It would take about 1.5-2 hours on a dedicated high-end 48-core machine to build a good qual- ity HNSW index [47] over 100M points. So we would need three dedicated machines for constantly rebuilding indices to maintain even six-hourly freshness guarantee over a billion- point index. This is apart from the cost of actually serving the indices, which would again be anywhere between one for DRAM-SSD hybrid indices [51] to four for in-memory in- dices [47] depending on the exact algorithm being deployed. This paper aims to serve and update an index over a billion points with real-time freshness using just one machine. This represents a significant cost advantage for web and enterprise-scale search platforms that need to serve indices spanning trillions of points.',\n",
              " '1.2 Our Contributions',\n",
              " 'In this paper, we present the FreshDiskANN system to solve the fresh-ANNS problem for points in Euclidean space with real-time freshness, and with 5-10x fewer machines than',\n",
              " 'the current state-of-the-art. As part of this, we make several technical contributions:',\n",
              " '1. We demonstrate how simple graph update rules result in degradation of index quality over a stream of inser- tions and deletions for popular graph-based algorithms such as HNSW [43] and NSG [28].',\n",
              " '2. We develop FreshVamana, the first graph-based index that supports insertions and deletions, and empirically demonstrate its stability over long streams of updates.',\n",
              " '3. In order to enable scale, our system stores the bulk of the graph-index on an SSD, with only the most re- cent updates stored in memory. To support this, we design a novel two-pass StreamingMerge algorithm which makes merges the in-memory index with the SSD-index in a very write-efficient manner (crucial since burdening the SSD would lead to worse search performance as well). Notably, the time and space com- plexity of the merge procedure is proportional to the change set, thereby making it possible to update large billion-point indices on a machine with limited RAM using an order of magnitude less compute and memory than re-building the large index from scratch.',\n",
              " '4. Using these ideas, we design the FreshDiskANN sys- tem to consist of a long-term SSD-resident index over the majority of the points, and a short-term in-memory index to aggregate recent updates. Periodically, unbe- knownst to the end user, FreshDiskANN consolidates the short-term index into the long-term index using our StreamingMerge process in the background to bound the memory footprint of the short-term index, and hence the overall system.',\n",
              " 'We conduct rigorous week-long experiments of this sys-',\n",
              " 'tem on an (almost) billion point subset of the popular SIFT1B [36]',\n",
              " 'dataset on a 48 core machine and 3.2TB SSD. We monitor recall stability, end-user latency and throughput for updates and searches. Some highlights are:',\n",
              " 'The system uses less than 128GB of DRAM at all times.',\n",
              " 'The StreamingMerge can merge a 10% change to the index (5% inserts + 5% deletes) to a billion',\n",
              " 'scale index in ~10% of the time than it takes to rebuild the index.',\n",
              " 'FreshDiskANN can support a steady',\n",
              " 'state through',\n",
              " 'put of 1800 inserts and 1800 deletes per second while retaining freshness and without backlogging back',\n",
              " 'ground merge. The system can also support short bursts of much higher change rate, up to even 40,000 inserts/second.',\n",
              " 'The user latency of insertion and deletion is under 1ms, even when a background merge is underway.',\n",
              " 'FreshDiskANN supports 1000 searches/sec with 95+% 5',\n",
              " 'recall@5 over the latest content of the index, with mean search latency well under 20ms.',\n",
              " '2 Related Work',\n",
              " 'ANNS is a classical problem with a large body of research work. Recent surveys and benchmarks [7, 25, 41] provide a great overview and comparison of the state-of-the-art ANN algorithms. This section focuses on the algorithms relevant for vectors in high-dimensional space with Euclidean metrics, and examines their suitability for the fresh-ANNS setting we consider in this paper. Beyond ANNS for points in Euclidean spaces, there has been work for tailored inputs and other notions of similarity such as those for time series data, e.g., [1, 19, 40]. The work [25] provides a comprehensive study of such algorithms and their applicability.',\n",
              " 'Trees. Some of the early research on ANNS focused on low-dimensional points (say, d < 20). For such points, spa- tial partitioning ideas such as R*-trees [13], kd-trees [14] and Cover Trees [16] work well, but these typically do not scale well for high-dimensional data owing to the curse of dimensionality. There have been some recent advances in maintaining several trees and combining them with new ideas to develop good algorithms such as FLANN [46] and Annoy [15]. However, they are built for static indices, and moreover, even here, the graph-based algorithms outperform them [7] on most datasets.',\n",
              " 'Hashing. In a breakthrough result, Indyk and Motwani [32] show that a class of algorithms, known as locality sensitive hashing can yield provably approximate solutions to the ANNS problem with a polynomially-sized index and sub- linear query time. Subsequent to this work, there has been a plethora of different LSH-based algorithms [3, 32, 62], in- cluding those which depend on the data [4], use spectral methods [61], distributed LSH [54], etc. While the advan- tage of the simpler data-independent hashing methods are that updates are almost trivial, the indices are often entirely resident in DRAM and hence do not scale very well. Im- plementations which make use of auxiliary storage such as SRS [53] typically have several orders of magnitude slower query latencies compared to the graph-based algorithms. Other hashing-based methods [37, 42, 48] learn an optimal hash family by exploiting the neighborhood graph. Updates to an index would require a full re-computation of the family and hashes for every database point, making them impracti- cal for fresh-ANNS.',\n",
              " 'Data quantization and Inverted indices based algo- rithms have seen success w.r.t the goal of scaling to large datasets with low memory footprint. These algorithms ef- fectively reduce the dimensionality of the ANNS problem by quantizing vectors into a compressed representation so that they may be stored using smaller amount of DRAM. Some choices of quantizers [38] can support GPU-accelerated search on billion-scale datasets. Popular methods like IV-',\n",
              " 'FADC [35], OPQ [29], LOPQ [39], FAISS [38], IVFOADC+G+P [12]',\n",
              " 'and IMI [8] exploit the data distribution to produce low',\n",
              " 'memory-footprint indices with reasonable search perfor- mance when querying for a large number of neighbors. While most methods[9, 29, 35, 38] minimize the vector recon- struction error ||x — x‘ ||?, where x is a database vector and x? is its reconstruction from the quantized representation, Anisotropic Vector Quantization [30] optimizes for error for maximum inner-product search. Some of these systems such as FAISS [38] support insert and delete operations on an ex- isting index under reasonable conditions like stationary data distributions. However, due to the irreversible loss due to the compression/quantization, these methods fail to achieve even moderate values of 1-recall@1, sometimes plateauing at 50% recall. These methods offer good guarantees on weaker notions such as 1-recall@100, which is the likelihood that the true nearest neighbor for a query appears in a list of 100 candidates output by the algorithm. Hence they are not the methods of choice for high-recall high-throughput scenarios.',\n",
              " 'A recent work, ADBV [60], proposes a hybrid model for supporting streaming inserts and deletes. New points are inserted into an in-memory HNSW [43] index while the main on-disk index utilises a new PQ-based indexing algorithm called VGPQ. In order to mitigate the accuracy loss due to PQ, VGPQ search performs a large number of distance compu- tations and incurs high search latencies. As distributed sys- tem over several powerful nodes, the model has low search throughput even when no inserts and deletes are going on. Hence, such a system cannot be used in high-throughput scenarios.',\n",
              " 'A recent work, ADBV [60], proposes a hybrid SQL-vector search model. New vectors are inserted into an in-memory HNSW index while the main on-disk index spanning upto a billion points is spread across multiple machines. The on-disk index is an extension of IVF-clustering [35] which is far less efficient for search compared to graph indices in terms of the number of distance comparisons and I/O. As a result, their aggregate search throughput on a billion point index spread across disks on 16 machines is lesser than the throughput of FreshDiskANN with one machine. Our work achieves this by designing an on-SSD updatable graph index which is far more efficient for search. Their insertion throughput on an index spread across 70 machines is also much lesser than that of FreshDiskANN on one machine.',\n",
              " '3 Graph',\n",
              " 'based ANNS indices',\n",
              " 'In this section, we recap how most state-of-the-art graph- based indices work for static-ANNS and also highlight the issues they face with supporting deletions.',\n",
              " '3.1 Notation',\n",
              " 'The primary data structure in graph indices is a directed graph with vertices corresponding to points in P, the dataset that is to be indexed, and edges between them. With slight notation overload, we denote the graph G = (P, E) by letting P also denote the vertex set. Given a node p in this directed',\n",
              " 'Algorithm 1: GreedySearch(s, Xq k, L) Data: Graph G with start node s, query xq, result size k, search list size L > k Result: Result set £ containing k-approx NNs, and a set V containing all the visited nodes',\n",
              " 'begin initialize sets £< {s} and V<O while £\\\\V #0 do let px — argminye p\\\\y xp — Xqll update £< L£UNout(p*) and V — VU {p*} if |L|>L then update £ to retain closest L points i to xq',\n",
              " 'return [closest k points from V; V]',\n",
              " 'graph, we let Nout(p) and Nin(p) denote the set of out- and in-edges of p. We denote the number of points by n = |P|. Finally, we let xp denote the database vector corresponding to p, and let d(p, q) = ||xp — Xq|| denote the f distance between two points p and q. We now describe how graph-based ANNS indices are built and used for search.',\n",
              " '3.2 Navigability and Index Search',\n",
              " 'Roughly speaking, navigability of a directed graph is the property that ensures that the index can be queried for near- est neighbors using a greedy search algorithm. The greedy search algorithm traverses the graph starting at a designated navigating or start node s € P. The search iterates by greed- ily walking from the current node u to a node v € Nout(u) that minimizes the distance to the query, and terminates when it reaches a locally-optimal node, say p*, that has the property d(p*,q) < d(p,q) Vp € Nou(p*). Greedy search cannot improve distance to the query point by navigating out of p* and returns it as the candidate nearest neighbor for query q. Algorithm 1 describes a variant of this greedy search algorithm that returns k nearest neighbor candidates. Index Build consists of constructing a navigable graph. The graph is typically built to achieve two contrasting objectives to minimize search complexity: (i) make the greedy search algorithm applied to each base point p € P in the vertex set converge to p in the fewest iterations (intuitively, this would ensure that Algorithm 1 converges to p when searching for a query Xq if p is the nearest-neighbor for xq), and (ii) have a maximum out-degree of at most R for all p € P, a parameter typically between 16 — 128.',\n",
              " 'Algorithms like NN-Descent [24] use gradient descent techniques to determine G. Others start with a specific type of graph — an empty graph with no edges [43, 51] or an approximate k—NN graph [27, 28] — and iteratively refine G using the following two-step construction algorithm to improve navigability:',\n",
              " 'Candidate Generation',\n",
              " 'For each base point xp, run Algorithm 1 on G to obtain V, £. V U £ contains nodes visited and/or closest to p in G during the search in the current graph G, making them good candidates for adding to Nout(p) and Nin(p), thereby improving the navigability to p in the updated graph G.',\n",
              " 'Edge Pruning',\n",
              " 'When the out',\n",
              " 'degree of a node p exceeds R, a pruning algorithm (like Algorithm 3 with a set to 1) filters out similar kinds of (or redundant) edges from the adjacency list to ensure |Nout(p)| < R. Intuitively, the procedure sorts the neighbors of p in increasing order of distance from p, and only retains an edge (p, p’’) if there is no edge (p, p’) which has been retained and p’ is closer to p” than p (ie., if Algorithm 1 can reach p” from p through p’, then we can safely remove the edge (p, p’’)).',\n",
              " '3.3 Why are Deletions Hard?',\n",
              " 'While graph-indices offer state-of-the-art search performance, all known algorithms apply for the static-ANNS problem. In particular, deletions pose a big challenge for all these algo- rithms — e.g., see this discussion [18] on HNSW supporting delete requests by adding them to a blacklist and omitting from search results. Arguably, this is due to the lack of meth- ods which modify the navigable graphs while retaining the original search quality. To further examine this phenomenon, we considered three popular static-ANNS algorithms, namely HNSW, NSG, and Vamana and tried the following natural update policies when faced with insertions and deletions.',\n",
              " 'Insertion Policy. For insertion of a new point p, we run the candidate generation algorithm as used by the respective algorithms and add the chosen in- and out-edges, and if necessary, whenever the degree of any vertex exceeds the budget, run the corresponding pruning procedure.',\n",
              " 'Delete Policy A. When a point p is deleted, we simply re- move all in- and out-edges incident to p, without adding any newer edges to compensate for potential loss of navigability. Indeed, note that p might have been on several navigating paths to other points in the graph.',\n",
              " 'Delete Policy B. When a point p is deleted, we remove all in- and out-edges incident to p, and add edges in the local neighborhood of p as follows: for any pair of directed edges (pin, p) and (p, Pout) in the graph, add the edge (pin, Pout) in the updated graph. If the degree bound of any vertex is violated, we run the pruning procedure associated with the respective algorithm to control the degrees.',\n",
              " 'Figure 1 shows that both of these delete policies are not ef- fective. In this experiment, we consider the SIFT1M dataset [2] comprising of a million points in 128 dimensions, and start with the static-ANNS index for each of the algorithms. We then compose an update stream by selecting 5% of the points at random and deleting them, followed by presenting them again as insertions. We then repeat this process over multiple',\n",
              " 'Delete Policy A Delete Policy B 100 T T T T 100 T T T T to @ 95} 4 95} 4 s is} = 90 ie 90 | | w 85 1 | | | 85 | 1 1 | 0 5 10 15 20 0 5 10 15 20 Batches (5% size) HNSW Vamana NSG',\n",
              " 'Figure 1. Search recall over 20 cycles of deleting and re- inserting 5% of SIFT1M dataset with statically built HNSW, Vamana, and NSG indices with L; = 44, 20, 27, respectively.',\n",
              " 'cycles. A stable update policy should result in similar search performance after each cycle since the index is over the same dataset. However, all of the algorithms show a consistently deteriorating trend in search performance (the recall drops for a fixed candidate list size). The left plot in Figure 1 shows the trend for HNSW and Vamana indices with Delete Policy A, while the other considers the Delete Policy B for the NSG index. Other combinations show similar trends but we omit them due to lack of space.',\n",
              " '4 The FreshVamana algorithm',\n",
              " 'Following the experiments in Section 3.3, we investigated the reason that the recall drops over multiple cycles of updates for deleting and re-inserting the same set of points. It turns out that the graph becomes sparse (lesser average degree) as we update it, and hence it becomes less navigable. We suspect that this is due to the very aggressive pruning policies of existing algorithms such as HNSW and NSG use to favor highly sparse graphs.',\n",
              " 'Fortunately, the sparsity-vs-navigability issue has recently been studied from a different perspective in [51], where the authors seek to build denser graphs to ensure the navigating paths converge much quicker. This in turn enables them to store such graphs on the SSD and retrieve the neighborhood information required by Algorithm 1 as required from the',\n",
              " 'SSD without incurring large SSD latencies.',\n",
              " 'a-RNG Property. The crucial idea in the graphs constructed in [51] is a more relaxed pruning procedure, which removes an edge (p, p’”’) only if there is an edge (p, p’) and p’ must be significantly closer to p” than p, ie., d(p’, p’”) < toe\") for some @ > 1. Generating such a graph using @ > 1 intuitively ensures that the distance to the query vector progressively decreases geometrically in a in Algorithm 1 since we remove edges only if there is a detour edge which makes significant progress towards the destination. Consequently, the graphs become denser as @ increases.',\n",
              " 'We now present one of our crucial findings and contributions — graph index update rules for insertions and deletions that',\n",
              " 'Algorithm 2: Insert(xp, s, L, a, R) Data: Graph G(P, E) with start node s, new point to be added with vector Xp. distance threshold a > 1, out degree bound R, search list size L Result: Graph G’(P’, E’) where P’ = P U {p} begin initialize set of expanded nodes V <« @ initialize candidate list £<-0 [L,V] — GreedySearch(s, p, 1, L) set p’s out-neighbors to be Nout(p) <— RobustPrune(p, V,a,R) (Algorithm 3)',\n",
              " 'foreach j € Nout(p) do if |Nout(j) U {p}| > R then Nout (i) — RobustPrune(j, Nout(j) U {p}. @, R) else L update Nout(j) — Nout(j) U {p}',\n",
              " 'Algorithm 3: RobustPrune(p, V, a, R) Data: Graph G, point p € P, candidate set V, distance threshold a > 1, degree bound R Result: G is modified by setting at most R new out-neighbors for p',\n",
              " 'begin',\n",
              " 'V — (VU Nout(p)) \\\\ {}',\n",
              " 'Nout (p) — ®',\n",
              " 'while V #0 do p* —argminy ey d(p, p’) Nout(p) — Nout(p) U {p*} if |Nout(p)| =R then |. break for p’€V do',\n",
              " 'if a',\n",
              " 'd(p',\n",
              " ',p’) <d(p,p’) then',\n",
              " '| [| remove p’ from V',\n",
              " 'exploit the a-RNG property to ensure continued navigability of the graph and retain stable recall over multiple modifications.',\n",
              " '4.1 Insertion',\n",
              " 'A new point x, is inserted into a FreshVamana index us- ing Algorithm 2. Intuitively, it queries the current index for nearest neighbors of p to obtain the visited set V, gener- ates candidate out-neighbors for xp using pruning procedure in Algorithm 3 on VV, and adds bi-directed edges between p and the pruned candidates. If out-degree of any vertex exceeds R, Algorithm 3 can be used to prune it to R.',\n",
              " 'We use lock-based concurrency control to guard access to Nout(p) for a node p, allowing for high insertion throughput using multiple threads. Due to the fine granularity of locking',\n",
              " 'Algorithm 4: Delete(Lp, R, a) Data: Graph G(P, E) with |P| = n, set of points to be deleted Lp Result: Graph on nodes P’ where P’ = P \\\\ Lp begin foreach p € P\\\\ Lp s.t. Nout(p) NLp # @ do D — Nout(p) Lp C—Nou(p)\\\\D //initialize candidate list foreach v€ D do L C —CU Nout(v)',\n",
              " 'C-—C\\\\D Nout (p) <— RobustPrune(p, C, a, R)',\n",
              " 'and the short duration for which the locks are held, insertion throughput scales near-linearly with threads (see Appendix).',\n",
              " '4.2 Deletion',\n",
              " 'Our deletion algorithm Algorithm 4 is along the lines of Delete Policy B in Section 3.3, with the crucial feature being using the relaxed a-pruning algorithm to retain density of the modified graph. Specifically, if p is deleted, we add edges (p’,p’’) whenever (p’, p) and (p, p’”) are directed edges in the current graph. In this process, if |Nout(p’)| exceeds the maximum out-degree R, we prune it using Algorithm 3, pre- serving the a—RNG property.',\n",
              " 'However, since this operation involves editing the neigh- borhood for all the in-neighbors of p, it could result be ex- pensive to do eagerly, i.e., processing deletes as they arrive. FreshVamana employs a lazy deletion strategy - when a point p is deleted, we add p to a DeleteList without chang- ing the graph. DeleteList contains all the points that have been deleted but are still present in the graph. At search time, a modified Algorithm 1 uses nodes in the DeleteList for navigation, but filters them out from the result set.',\n",
              " 'Delete Consolidation. After accumulating a non-trivial number of deletions (say 1-10% of the the index size), we batch-update the graph using Algorithm 4 to update the neighborhoods of points with out-edges to these deleted nodes. This operation is trivially parallelized using prefix sums to consolidate the vertex list, and a parallel map opera- tion to locally update the graph around the deleted nodes.',\n",
              " '4.3. Recall stability of FreshVamana',\n",
              " 'We now demonstrate how using our insert and delete al- gorithms (along with a choice of a > 1) ensures that the resulting index is stable over a long stream of updates.',\n",
              " 'We start with a statically built Vamana index and subject it to multiple cycles of insertions and deletions using the FreshVamana update rules described in Section 4. In each cycle, we delete 5%, 10% and 50% of randomly chosen points from the existing index, and re-insert the same points. We then choose appropriate L, (the candidate list size during',\n",
              " '5% Index Size 10% Index Size 50% Index Size 100 100 100 3 99 99 - 7 99 | ——  SIFTIM © 98 98 | | 98 4 ——  DeepiM a 97 97|- | 97 4 2 96 96 96 by Sydieoeatd ——  GISTIM fe 95 95 Saeeeoceaell 95 “ah —— SIFT100M 94 94 ; ; 94 ; ; 0 20 40 20 40 Cycles Cycles',\n",
              " 'Figure 2. 5-recall@5 for FreshVamana indices for 50 cycles of deletion and re-insertion of 5%, 10%, and 50% of index size on the million-point and 5% of SIFT100M datasets. L, is chosen to obtain 5-recall@5~ 95% on Cycle 0 index.',\n",
              " 'SIFT1M Deep1M 98 to ® 96 ‘Ss 94 # ite) 92 90 - 20 40 0 20 40 Cycles (5% index size) a=1 a=1.1 a=1.2 a=13',\n",
              " 'Figure 3. Recall trends for FreshVamana indices on SIFT1M and Deep1M over multiple cycles of inserting and deleting 5% of points using different values of a for building and updating the index. L, is chosen to obtain 5—recall@5 = 95% for Cycle 0 index.',\n",
              " 'search) for 95% 5-recall@5 and plot the search recall as the index is updated. Since both the index contents and L, are the same after each cycle, a good set of update rules would keep the recall stable over these cycles. Figure 2 confirms that is indeed the case, for the million point datasets and the 100 million point SIFT100M dataset. In all these experiments, we use an identical set of parameters L, a, R for the static Vamana index we begin with as well as our FreshVamana updates. Note that in some of these plots, there is a small initial drop in recall; this is possibly due to the fact that the static Vamana indices which we are starting from are built by making two passes of refinement over the dataset and hence might have slightly better quality than the streaming FreshVamana algorithm.',\n",
              " 'Effect of a. Finally we study the effect of a on recall stability. In Figure 3, we run the FreshVamana update rules for a stream of deletions and insertions with different @ values, and track how the recall changes as we perform our updates. Note that recall is stable for all indices except for the one with @ = 1, validating the importance of using @ > 1.',\n",
              " '5 The FreshDiskANN system',\n",
              " 'While FreshVamana can support fast concurrent inserts, deletes and searches with an in-memory index, it will not',\n",
              " 'scale to a billion-points per machine due to the large memory footprint of storing the graph and data in RAM. The main idea of overall system FreshDiskANN is to store a bulk of the graph-index on an SSD, and store only the recent changes in RAM- To further reduce the memory footprint, we can simply store compressed vector representation (using an idea such as Product Quantization (PQ) [35]) of all the data vec- tors. In fact, these ideas of using a-RNG graphs and storing only compressed vectors formed the crux of the SSD-based DiskANN static-ANNS index [51].',\n",
              " 'While this will reduce the memory footprint of our index, and will also ensure reasonable search latencies, we cannot immediately run our insert and delete Algorithms 2 and 4 on to a SSD-resident FreshVamana index. Indeed, the insertion of a new point xp has to update the neighborhoods of as many as R (the parameter controlling the degree bound) many points to add edges to p, which would trigger up to R random writes to the SSD. For typical indices, R would be as large as 64 or 128, requiring as many random SSD writes per insert. This would severely limit the insertion throughput and also reduce the search throughput as a high write load on the SSD also affects its read performance, which is critical to search latency. Similarly, each delete operation, if applied eagerly, would result in Rin writes, where Rin is the in-degree of the deleted point, which can be very large.',\n",
              " 'The FreshDiskANN system circumvents these issues and brings together the efficiency of a SSD-based system and the interactive latency of an in-memory system by splitting the index into two parts: (i) an in-memory FreshVamana component comprising of recent updates, and (ii) a larger SSD-resident index with longer term data.',\n",
              " '3.As FreshVamana graphs are constructed using the a-RNG property (Sec- tion 4), the number of steps that the greedy search algorithm takes to converge to a locally optima is much smaller than other graph algorithms. Hence the total search latency to fetch the graph neighborhoods from SSD is small. So the a-RNG property helps us with both ensuring recall stability as well as obtaining tolerable search latencies for SSD-based indices.',\n",
              " '5.1 Components',\n",
              " 'The overall system maintains two types of indices: one Long- Term Index (aka LTI) and one or more instances of Temporary Index (a.k.a TempIndex), along with a DeleteList.',\n",
              " 'LTl is an SSD',\n",
              " 'resident index that supports search re',\n",
              " 'quests. Its memory footprint is small, and consists only of about 25',\n",
              " '32 bytes of compressed representations for each point. The associated graph index and full',\n",
              " 'precision data is stored on the SSD like [51]. Insertions and deletions do not affect the LTI in real',\n",
              " 'time.',\n",
              " 'One or more TempIndex objects, which are instances of the FreshVamana index stored entirely in DRAM (both the data and the associated graph). By design, they contain points that have been recently inserted to P. As a result, their memory footprint is a small fraction of the entire index.',\n",
              " 'DeleteList is the list of points that are present either in the LTI or the TempIndex, but have been requested for deletion by the user. This list is used to filter out the deleted points returned in the search results.',\n",
              " 'RO- and RW-Templndex: To aid with crash recovery, FreshDiskANN uses two types of TempIndex. At all times,',\n",
              " 'FreshDiskANN will maintain one mutable read-write TempIndex',\n",
              " '(called RW-TempIndex) which can accept insert requests. We periodically convert the RW-TempIndex into a read-only in-memory index called RO-TempIndex, and also snapshot it to persistent storage. We then create a new empty RW- Temp!ndex to ingest new points.',\n",
              " '5.2 FreshDiskANN API The following three operations are supported:',\n",
              " 'Insert(x,) to insert a new point to the index is routed to the sole instance of RW',\n",
              " 'TempIndex, which ingests the point using in Algorithm 2.',\n",
              " 'Delete(p) request to delete an existing point p is added to the DeleteList.',\n",
              " 'Search(xg, K, L) to search for the K nearest candidates using a candidate list of size L is served by querying LTI, RW-TempIndex, and all instances of RO-TempIndex with parameters K and L, aggregating the results and removing deleted entries from DeleteList.',\n",
              " '5.3. The StreamingMerge Procedure',\n",
              " 'Finally, to complete the system design, we now present de- tails of the StreamingMerge procedure. Whenever the total memory footprint of the various RO-TempIndex exceeds a pre-specified threshold, the system invokes a background merge procedure serves to change the SSD-resident LTI to reflect the inserts from the various instances of the RO- TempIndex and also the deletes from the DeleteList. To this end, for notational convenience, let dataset P reflect the points in the LTI, and N denote points currently staged in the different RO-TempIndex instances, and D denote the',\n",
              " 'points marked for deletion in DeleteList. Then the desired end-result of the StreamingMerge is an SSD-resident LTI over the dataset (P U N) \\\\ D. Following the successful com- pletion of the merge process, the system clears out the RO- TempIndex instances thereby keeping the total memory foot- print under control. There are two important constraints that the procedure must follow:',\n",
              " 'Have a memory footprint proportional to size of the changes |D| and |N|, and not the size of overall index |P|. This is critical since the LTI can be much larger than the memory of the machine.',\n",
              " 'Use SSD I/Os efficiently so that searches can still be served while a merge runs in the background, and so that the merge itself can complete fast.',\n",
              " 'At a high level, StreamingMerge first runs Algorithm 4 to process the deletes from D to obtain an intermediate-LTI index over the points P\\\\ D. Then StreamingMerge runs Algo- rithm 2 to insert each of the points in N into the intermediate- LTI to obtain the resultant LTI. However, Algorithms 2 and 4 assume that both the LTI graph, as well as the full-precision vectors all the datapoints are stored in memory. The crucial challenges in StreamingMerge is to simulate these algorithm invocations in a memory and SSD-efficient manner. This is done in three phases outlined below.',\n",
              " '1. Delete Phase: This phase works on the input LTI in- stance and produces an intermediate-LT| by running Algo- rithm 4 to process the deletions D. To do this in a memory- efficient manner, we load the points in LTI and their neigh- borhoods in the LT! block-by-block from the SSD, and ex- ecute Algorithm 4 for the nodes in the block using multi- ple threads, and write the modified block back to SSD on the intermediate-LTI. Furthermore, whenever Algorithm 4 or Algorithm 3 make any distance comparisons, we use the compressed PQ vectors which are already stored on behalf of the LTI to calculate the approximate distances. Note that this idea of replacing any exact distance computations with ap- proximate distances using the compressed vectors will be used in the subsequent phases of the StreamingMerge also.',\n",
              " '2. Insert Phase: This phase adds all the new points in N to the intermediate-LTI by trying to simulate Algorithm 2. As a first step, we run the GreedySearch(s, p, 1, L) on the SSD- resident intermediate-LTI to get the set V of vertices visited on the search path. Since the graph is stored on the SSD, any requested neighborhood Nou(p’) by the search algorithm is fetched from the SSD. The a-RNG property ensures that the number of such neighborhood requests is small, and hence the overall latency per point is bounded. We then run the RobustPrune(p, V, a, R) procedure to determine the candi- date set of neighbors for p. However, unlike Algorithm 2, we do not immediately attempt to insert p into Nour(p’) for P’ © Nout(p) (the backward edges) since this could result in an impractical number of random reads and writes to',\n",
              " 'the SSD. Instead, we maintain an in-memory data-structure A(p’) and add p to that.',\n",
              " '3. Patch Phase: After processing all the inserts, we patch the A data-structure into the output SSD-resident LTI index. For this, we fetch all points p in the intermediate-LTI block- by-block from the SSD, add the relevant out-edges for each node p from A, and check the new degree | Nou (p) UA(p)| ex- ceeds R. If so, prune the neighborhood by setting Nour(p) = RobustPrune(p, Nour (p) U A(p), «, +). Within each block read from the SSD, this operation can be applied to each vertex in a data-parallel manner. Subsequently, the updated block is written back to SSD before loading a new block.',\n",
              " '5.4 Complexity of StreamingMerge',\n",
              " '1/0 cost. The procedure does exactly two sequential passes over the SSD-resident data structure in the Delete and Patch Phases. Due to the a-RNG property of the intermediate- LTI, the insertion algorithm performs a small number of random 4KB reads per inserted point (about 100 disk reads, a little more than the candidate list size parameter, which we typically set to 75). Note that this number would be much larger without the a-RNG property due to the possibility of very long navigation paths.',\n",
              " 'Memory footprint: Throughout the StreamingMerge process, A data structure has size O(|N|R) where R is the max-degree parameter of the index which is typically a small constant. For example, if |N| = 30M and R = 64, this foot- print will be ~7GB. In addition, for approximate distances, recall that we keep a copy of PQ coordinates for all points in the index (~ 32GB for a billion-point index).',\n",
              " 'Compute requirement: The complexity of the insert phase and the patch phase is essentially linear in the size of the new points N to insert, since the insert phase simply runs a search using Algorithm 1 for new point in N and updates the A data structure, and the patch phase adds the backward edges in a block-by-block manner.',\n",
              " 'The delete phase has a small fixed cost to scan Nou(p) of each point p € P and check if there any deleted points and a larger variable cost, linear in the delete set size |D| that we will bound by O(|D|R’) (in expectation over random deletes). We detail this calculation in Appendix D.',\n",
              " '5.5 Recall Stability of StreamingMerge',\n",
              " 'While we have already demonstrated that our update algo- rithms Algorithms 2 and 4 ensure recall stability over long streams of updates in Section 4.3, the actual form in which these algorithms are implemented in our StreamingMerge procedure is different, especially with the use of approximate compressed vectors for distance computations. Indeed, as we process more cycles of the StreamingMerge procedure, we expect the initial graph to be replaced by a graph entirely built based on approximate distances. Hence, we expect a',\n",
              " 'recall@5',\n",
              " '100 96 98 | 1p 9 7 96 | 29F 1 393 | 94 | fob zs 92 4 Poh | 90 | 1 | 90 1 1 0 10 20 30 40 0 20 40 60 #Batches #Batches —+— L 95 —+— L300 Figure 4. Recall evolution over multiple cycles of',\n",
              " 'StreamingMerge in steady-state over (left) 80M point index with 10% deletes and inserts and (right) 800M point index with 30M insertions and deletions.',\n",
              " 'small drop in recall in the initial cycles, following which we expect the recall to stabilize.',\n",
              " 'In the experiment in Figure 4, we start with a statically built SSD-index built on 80M points randomly sampled from the SIFT100M dataset. Then, in each cycle, we update the in- dex to reflect 8M deletions and an equal number of insertions from the spare pool of 20M points using StreamingMerge. We run this experiment for a total of 40 cycles and trace recall for the index after each cycle in Figure 4. Note that the index stabilizes at a lower recall value compared to the static index it starts out with, due to the use of approximate distances in the StreamingMerge process. We observe recall stabilization after ~ 20 cycles of deletion and insertion of 10% of the index size, at which point we expect most of the graph to be deter- mined using approximate distances. Figure 4 (right) shows a similar plot for the 800M point subset of SIFT1B. We have thus empirically demonstrated that the FreshDiskANN index has stable recall over a stream of updates at steady-state.',\n",
              " '5.6 Crash Recovery',\n",
              " 'To support crash recover, all index update operations are written into a redo-log. When a crash leads to the loss of the single RW-TempIndex instance and the DeleteList, they are rebuilt by replaying updates from the redo-log since the most recent snapshot. Since RO-TempIndex and LTI instances are read-only and periodically snapshotted to disk, they can be simply reloaded from disk.',\n",
              " 'The frequency at which RW-TempIndex is snapshotted to a RO-TempIndex depends on the intended recovery time. More frequent snapshots lead to small reconstruction times for RW- TempIndex but create many instances of RO-TempIndex all of which have to be searched for each query. While searching a few additional small in-memory indices is not the rate limiting step for answering the query (searching the large LTI is), creating too many could can lead to inefficient search. A typical set up for a billion-point index would hold up to 30M points in the TempIndex between merges to the LTI. Limiting each in-memory index to 5M points results in at',\n",
              " 'most 6 instances TempIndex which can each be searched in 0.77ms, compared to 0.89ms needed to search a single 30M size index, for Ls = 100. On the flip side, reconstructing the RW-TempIndex from the log using a 48 core machine takes just about 2.5 minutes if it has size 5M points as opposed to 16 minutes for a size of 30M points.',\n",
              " '6 Evaluation',\n",
              " 'We now study the FreshDiskANN system on billion-scale datasets. We first describe the datasets and the machines used for all experiments reported in this paper. We defer presentation of recall-vs-latency curves for FreshVamana and FreshDiskANN at k = 1, 10, 100 to Appendix E.',\n",
              " '6.1 Experimental Setup Hardware. All experiments are run on one of two machines: e (mem-mc) — a 64-vcore E64d_v4 Azure virtual machine instance used to measure latencies and recall for in- memory indices and the FreshVamana update rules. e (ssd-mc) — a bare-metal server with 2x Xeon 8160 CPUs (48 cores, 96 threads) and a 3.2TB Samsung PM1725a PCle SSD to evaluate SSD-based indices and the overall FreshDiskANN system.',\n",
              " 'Datasets. We evaluate our algorithms and systems on the following widely-used public benchmark datasets.',\n",
              " '1 million point image descriptor datasets SIFT1M[2], GIST1M[2], and DEEP1M[10] in 128, 960 and 98 dimen',\n",
              " 'sions respectively. They are all in float32. DEEP1M is generated by convolutional neural networks.',\n",
              " '1 billion point SIFT1B[2] image descriptors in 128 di',\n",
              " 'mensions. It is the largest publicly available dataset and is in uint8 precision (total data size 128GB). We take a random 100M point subset of this dataset, rep',\n",
              " 'resented in float32 format and call it the SIFT100M dataset. We think that this smaller dataset captures many realistic medium',\n",
              " 'scale scenarios for ANNS.',\n",
              " '6.2 Billion',\n",
              " 'Scale FreshDiskANN Evaluation',\n",
              " 'We now study the complete FreshDiskANN system in a real- istic scenario — maintaining a large scale billion-scale index on the ssd machine and serving thousands of inserts, deletes and searches per second concurrently over multiple days. For this experiment, we use the SIFT1B dataset, but limit the size of our indices to around 800M points, so that we have a sufficiently big spare pool of 200M points for insertions at all times.',\n",
              " 'Parameters. We use R = 64, L, = 75 and a = 1.2 for all the system. Recall that R is the maximum degree of the graph, L, is the list size used during the candidate generation phase of the algorithms (the parameter is used in Algorithm 2), and a is used in the pruning phase for ensuring the a-RNG property. We also use B = 32 bytes per data vector as the compression target in PQ (each data vector is compressed',\n",
              " '10',\n",
              " 'down to 32 bytes) for the SSD-based LTI indices. We also set a limit M of 30M points on the total size of the TempIndex so that the memory footprint of the TempIndex is bounded by around 13GB (128 bytes per point for the vector data, 256 bytes per point for the neighborhood information with R = 64, and some locks and other auxiliary data structures accounting for another 100 bytes per point). Finally, we use a maximum of T = 40 threads for the StreamingMerge process which runs in the background.',\n",
              " 'Memory Footprint of FreshDiskANN Deployment. As mentioned above, the memory footprint of the TempIndex is around 13 GB for 30M points, and our index will at any time store at most TempI!ndex instances totaling 60M points, contributing a total of ~26GB. The memory footprint index of the LTI for 800M points is essentially only the space needed to store the compressed vectors, which is around 24 GB. The space requirement for the background StreamingMerge process is again at most 50 GB (to store the compressed vectors of the 800M points of the LTI index and around 2-R-4 bytes per inserted point for forward and backward edges in the A data structure), giving us a peak memory footprint of around 100GB. Since our index operated with a steady-state size of 800M points, this will roughly correspond to around 125GB for a billion-point index.',\n",
              " 'Our experiment can be divided into two phases: in the first phase, starting with a statically built index on a random 100M subset of SIFT1B, we define our update stream to com- prise only of inserts until the total number of points in the index reaches around 800M points. We call this the ramp-up phase. We then transition into what we call a steady-state phase, where we update the index by deleting and inserting points at the same rate. We delete existing points and insert points from the spare pool of 200M points from the SIFT1B dataset. We then continue this for several days and observe the behaviour of the system in terms of latencies and recall.',\n",
              " 'How fast can we feed inserts into the system in these phases, i.e., how many threads can we use to concurrently insert into the FreshDiskANN system? If we use too many threads for insertion, the TempIndex will reach the limit M of 30M points before the StreamingMerge process has completed. This would result in a backlog of inserts not consolidate to LT] on SSD. With the benefit of some prior ex- periments (of how long each cycle of the StreamingMerge takes), we arrive at the number of threads which concur- rently feed inserts into the FreshDiskANN system in each of the phases and describe them below.',\n",
              " 'Stage 1: Ramp Up. In the first stage of the experiment, we use the FreshDiskANN system to start with an index of 100M points randomly chosen from the SIFT1B dataset, and constantly feed inserts. 3 threads were used for concurrently inserting points from the spare pool of points from SIFT1B, and 10 threads for issuing concurrent search requests from the query set (with search parameters set to provide > 92%',\n",
              " 'Pe Db ww',\n",
              " 'ounucuan',\n",
              " 'Search latency(ms)',\n",
              " 'ou',\n",
              " '10°',\n",
              " 'Time elapsed since beginning of experiment (seconds)',\n",
              " 'Figure 5. Search latencies for Ls = 100 (always > 92% 5- recall@5) over the course of ramping up an index to size 800M. Each point is mean latency over a 10000-query batch.',\n",
              " '5-recall@5 at all times). We chose 3 threads for inserts so that the merge process does not get backlogged, i.e., in the time taken by StreamingMerge to merge the previous batch of 30M inserts to LTI, the TempIndex does not accumulate more than 30M points. The insertions continued until the index grew to a size of 800M points, which took around 3 days. User-perceived mean search latency over the course of the ramp-up fluctuates mostly between 5ms, when no merge is happening, and 15ms when StreamingMerge is running in the background and is presented in Figure 5.',\n",
              " 'Stage 2: Steady State. In the second stage of the experiment, we maintain an index size of around 800M while supporting a large number of equal inserts and deletes. Externally, 2 threads insert points into the index, 1 thread issues deletes, and 10 threads concurrently search it. Since the deletes hap- pen near instantly, we added a sleep timer between the delete requests to ensure that the rate of deletions is similar to that of insertions. Note that we reduced the number of insert threads from 3 to 2 to slow down the insertion rate to accom- modate the longer merge times compared to the ramp-up experiment — the StreamingMerge process now processes 30M deletes in addition to 30M inserts. We present user- perceived latencies for search and insertions in Figure 6.',\n",
              " 'Variations in Search Latency During StreamingMerge. The middle plot in Figure 6 shows that the user-perceived search latencies varies across based on the phase of the StreamingMerge process in progress. Since the Insert phase generates a significant number of random reads to the LTI index which interfere with the random read requests issued by the search threads, it results in slightly higher latencies. On the other hand, while the typical latencies are smaller during the Delete and Patch phases of StreamingMerge, the latencies occasionally spike as high as 40ms, which we',\n",
              " 'M1',\n",
              " 'think is likely due to head-of-line blocking by the large se- quential read and write operations that copy the LTI index to and from the main memory.',\n",
              " 'Update Throughput of System. While FreshDiskANN pro- vides latencies of about 1ms for insert (Figure 6) and 0.1: for delete (since they are simply added to a DeleteList), in practice they need to be throttled so that the in-memory TempIndex do not grow too large before the ongoing back- ground merge completes. As a result, the speed of the merge operation dictates the update rates the system can sustain over long periods of time. The threads allocation described above helps us control the rate of external insert and delete operations to what the StreamingMerge procedure can com- plete before the TempIndex grows to 30M points.',\n",
              " 'To better understand the thread allocation, we record the time taken for the StreamingMerge process to merge 30M inserts into an index of size roughly 800M using T = 40 threads. This takes around 8400s per cycle. To prevent the TempIndex from growing too much while the merge proce- dure is running, we throttle the inserts to around 3500 inserts per second, so that the TempIndex accumulates under 30M newly inserted points in one merge cycle. Since the insertion latencies into in-memory FreshVamana indices is around 1ms (Figure 6), we allocated a total of 3 threads concurrently feeding into the system. This ensured that the system never backlogged throughout the ramp-up experiment.',\n",
              " 'In the steady-state experiment where the index maintains a constant size of about 800M points and is updated in cycles of equal sized insertions and deletions of 30M points, the StreamingMerge procedure takes about 16277 seconds as it has to process deletes in addition to the inserts. Hence, in order to ensure that the system does not get backlogged, we throttled the insertion throughput to around 1800 inserts per second (and similarly for deletes). We achieved this by using two threads for the insertions, and one thread (with a sleep timer) for deletes to match the insertion throughput.',\n",
              " 'Trade-off of Varying Number of Merge Threads T. If we increase the merge threads T, the merges happen faster, which means we can ingest insertions and deletions into the system at a faster throughput (without the TempIndex size growing too large). On the other hand, if T is large, the SSD- bandwidth used by the StreamingMerge process increases and this adversely affects the search throughput. We examine the merge times with varying threads in Figure 7 (left) and the search latencies when different numbers of threads are performing background merge in Figure 8.',\n",
              " '1/0 Cost of Search. Running search with candidate list size L, = 100 gives us the desired steady-state recall in these experiments. For this L, value, the average I/O complexity of searches ends up being a mere 120 random 4KB reads per query, and the total number of distance comparisons made is around 8000, a really tiny fraction of the cost of doing brute',\n",
              " '70 30 1.6 PARAL @ 60 B95 ~ £ 50 & a 1.4} jth Ea > ZS fs 520 = th ——s0 & 40 3 g 1.27 5) £45 5 goth = 30 - 3 1} = = 19 Sipe] £ 20 9 - 3 § v 0. 8 = | HB 10 a» 1) eo 1 i 4 0 i | fi Ll Lo Lo 0.6 Ap nneteernne| 0 2-105 4-10° 6-10° 5,000 10,000 15,000 0 10 20 30 40 Time elapsed since start of experiment (seconds) Time since merge start (sec) #Batches Figure 6. Mean latency‘measurements for the week-long steady-state experiment with an 800M FreshDiskANN index',\n",
              " 'processing concurrent inserts, deletes, and periodic background merge. (left) Search latency with Ls = 100 over the entire',\n",
              " 'experiment; (middle) Search latency during one StreamingMerge run, zoomed in from the left plot; (right) 10\", 50°\" and 9',\n",
              " 'percentile insert latency over the entire experiment.',\n",
              " 'B Patch 6,000',\n",
              " 'BF insert',\n",
              " '4,500',\n",
              " '3,000',\n",
              " '1,500',\n",
              " 'Throughput (queries/s)',\n",
              " '0 20 40 60',\n",
              " 'Number of threads',\n",
              " 'Number of merge threads',\n",
              " 'Figure 7. (left) StreamingMerge runtime with different number of threads to merge 30M inserts and 30M deletes into a 800M SIFT index, and (right) Trend of search throughput with increasing search threads.',\n",
              " 'force. In contrast, systems like SRS [53] end up scanning = 15% of similar-sized datasets for achieving moderate recall.',\n",
              " '1/O Cost of Updates. Inserts and deletes involve reading and writing the entire LT] (= 320GB), twice over. Since our system amortizes this cost over 30M inserts and deletes, the SSD write cost per update operation is around 10KB, which is very small for a high dimensional problem that requires data structure and algorithm with random access patterns. Scaling of Search Throughput. When the index is not processing any inserts, deletes or merges, search throughput scales almost linearly with the number of threads issuing search queries (see Figure 7) (right), and with lesser latency than in Figure 6. With 64 threads, the system can support a throughput of ~ 6500 queries/sec with a mean and 99% latency of under 10 and 12ms respectively.',\n",
              " 'The Cost of StreamingMerge. The StreamingMerge pro- cedure with 40 threads takes around 16000 seconds to merge 30M inserts and deletes into a 800M point LTI (a 7.5% change), which is 8.5% of the ~ 190000 seconds it would take to re- build the index from scratch with a similar thread-count. We conclude that the merge process is significantly more',\n",
              " '4Mean latency computed on a batch of 10k query points with one query per search thread',\n",
              " '12',\n",
              " 'oth',\n",
              " 'Delete',\n",
              " 'rch latency(ms',\n",
              " 'oun Ss',\n",
              " 'T T T',\n",
              " 'Search latenc',\n",
              " 'Time elapsed(sec)',\n",
              " 'Figure 8. Trend of search latencies for 92% search recall, zoomed in over one cycle of merging 30M inserts and deletes into a 800M index, using 20 threads (red) and 40 threads (blue) for merge (time-axes are normalized to align the phases).',\n",
              " 'cost-effective than periodically rebuilding the indices, which is the current choice of system design for graph indices. Fur- ther, StreamingMerge scales near linearly with the number of threads (see Figure 7). While the Delete phase scales lin- early, the Patch and Insert phases scale sub-linearly due to intensive SSD I/O. Using fewer threads also results in more predictable search latencies (esp. 99% latency) due to the reduced SSD contention. This allows us to set the number of threads StreamingMerge uses to meet the desired update rate — 3600 updates/sec require 40 threads, but if we were only required to support 1000 updates/sec, we could choose to run StreamingMerge with 10 threads, and take advantage of higher search throughput and predictable latencies.',\n",
              " '7 Conclusion',\n",
              " 'In this paper, we develop FreshVamana, the first graph- based fresh-ANNS algorithm capable of reflecting updates to an existing index using compute proportional to the size of updates, while ensuring the index quality is similar to one rebuilt from scratch on the updated dataset. Using up- date rules from FreshVamana, we design a novel two-pass StreamingMerge procedure which reflects these updates into an SSD-resident index with minimal write amplification. Using FreshVamana and StreamingMerge, we develop and rigorously evaluate FreshDiskANN, a highly-scalable fresh- ANNS system that can maintain a dynamic index of a billion points on a commodity machine while concurrently support- ing inserts, deletes, and search operations at millisecond- scale latencies.',\n",
              " '13',\n",
              " 'References',\n",
              " '10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " 'Rakesh Agrawal, Christos Faloutsos, and Arun Swami. 1993. Effi- cient similarity search in sequence databases. In Foundations of Data Organization and Algorithms, David B. Lomet (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 69-84.',\n",
              " 'Laurent Amsaleg and Hervé Jegou. 2010. Datasets for approximate nearest neighbor search. http://corpus-texmex.irisa.fr/. [Online; accessed 20-May-2018].',\n",
              " 'Alexandr Andoni and Piotr Indyk. 2008. Near-optimal Hashing Al- gorithms for Approximate Nearest Neighbor in High Dimensions. Commun. ACM 51, 1 (Jan. 2008), 117-122. https://doi.org/10.1145/ 1327452.1327494',\n",
              " 'Alexandr Andoni and Ilya Razenshteyn. 2015. Optimal Data- Dependent Hashing for Approximate Near Neighbors. In Proceedings of the Forty-seventh Annual ACM Symposium on Theory of Comput- ing (Portland, Oregon, USA) (STOC ’15). ACM, New York, NY, USA, 793-801. https://doi.org/10.1145/2746539.2746553',\n",
              " 'Akhil Arora, Sakshi Sinha, Piyush Kumar, and Arnab Bhattacharya. 2018. HD-Index: Pushing the Scalability-Accuracy Boundary for Ap- proximate kNN Search in High-Dimensional Spaces. Proceedings of the VLDB Endowment 11 (04 2018). https://doi.org/10.14778/3204028. 3204034',\n",
              " 'Sunil Arya and David M. Mount. 1993. Approximate Nearest Neighbor Queries in Fixed Dimensions. In Proceedings of the Fourth Annual ACM- SIAM Symposium on Discrete Algorithms (Austin, Texas, USA) (SODA ’93). Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 271-280. http://dl.acm.org/citation.cfm?id=313559.313768 Martin Aumiiller, Erik Bernhardsson, and Alexander Faithfull. 2020. ANN-Benchmarks: A benchmarking tool for approximate nearest neighbor algorithms. Information Systems 87 (2020). http://www. sciencedirect.com/science/article/pii/S03064379 18303685',\n",
              " 'A. Babenko and V. Lempitsky. 2012. The inverted multi-index. In 2012 IEEE Conference on Computer Vision and Pattern Recognition. 3069- 3076.',\n",
              " 'Artem Babenko and Victor S. Lempitsky. 2014. Additive Quantization for Extreme Vector Compression. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2014, Columbus, OH, USA, June 23-28, 2014. IEEE Computer Society, 931-938. https://doi.org/10.1109/ CVPR.2014.124',\n",
              " 'Artem Babenko and Victor S. Lempitsky. 2016. Efficient Indexing of Billion-Scale Datasets of Deep Descriptors. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016. 2055-2063. https://doi.org/10.1109/CVPR.2016. 226',\n",
              " 'Dmitry Baranchuk, Artem Babenko, and Yury Malkov. 2018. Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors. In The European Conference on Computer Vision (ECCV).',\n",
              " 'Dmitry Baranchuk, Artem Babenko, and Yury Malkov. 2018. Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors. CoRR abs/1802.02422 (2018). arXiv:1802.02422 http://arxiv.org/abs/ 1802.02422',\n",
              " 'Norbert Beckmann, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger. 1990. The R*-Tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD Rec. 19, 2 (May 1990), 322-331. https://doi.org/10.1145/93605.98741',\n",
              " 'Jon Louis Bentley. 1975. Multidimensional Binary Search Trees Used for Associative Searching. Commun. ACM 18, 9 (Sept. 1975), 509-517. https://doi.org/10.1145/361002.361007',\n",
              " 'Erik Bernhardsson. 2018. Annoy: Approximate Nearest Neighbors in C++/Python. https://pypi-org/project/annoy/ Python package version 1.13.0.',\n",
              " 'Alina Beygelzimer, Sham Kakade, and John Langford. 2006. Cover Trees for Nearest Neighbor. In Proceedings of the 23rd International Con- ference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML',\n",
              " '14',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '20',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '30',\n",
              " '31',\n",
              " '32',\n",
              " '’06). Association for Computing Machinery, New York, NY, USA, 97-104. https://doi.org/10.1145/1143844.1143857',\n",
              " 'Alina Beygelzimer, Sham Kakade, and John Langford. 2006. Cover Trees for Nearest Neighbor. In Proceedings of the 23rd International Con- ference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML ’06). Association for Computing Machinery, New York, NY, USA, 97-104. https://doi.org/10.1145/1143844.1143857',\n",
              " 'Leonid Boytsov. [n.d.]._https://github.com/nmslib/nmslib/issues/73 A. Camerra, E. Keogh, T. Palpanas, and J. Shieh. 2010. iSAX 2.0: Index- ing and Mining One Billion Time Series. In 2013 IEEE 13th International Conference on Data Mining. IEEE Computer Society, Los Alamitos, CA, USA, 58-67. https://doi.org/10.1109/ICDM.2010.124',\n",
              " 'Kenneth L. Clarkson. 1994. An Algorithm for Approximate Closest- point Queries. In Proceedings of the Tenth Annual Symposium on Com- putational Geometry (Stony Brook, New York, USA) (SCG 94). ACM, New York, NY, USA, 160-164. https://doi.org/10.1145/177424.177609 Kunal Dahiya, Deepak Saini, Anshul Mittal, Ankush Shaw, Kushal Dave, Akshay Soni, Himanshu Jain, Sumeet Agarwal, and Manik Varma. 2021. DeepXML: A Deep Extreme Multi-Label Learning Frame- work Applied to Short Text Documents. In Proceedings of the 14th International Conference on Web Search and Data Mining (Jerusalem, Israel) (WSDM 21). Association for Computing Machinery, New York, NY, USA, 8.',\n",
              " 'John Derrick, Brijesh Dongol, Gerhard Schellhorn, Bogdan Tofan, Oleg Travkin, and Heike Wehrheim. 2014. Quiescent Consistency: Defining and Verifying Relaxed Linearizability. In FM 2014: Formal Methods, Cliff Jones, Pekka Pihlajasaari, and Jun Sun (Eds.). Springer International Publishing, Cham, 200-214.',\n",
              " 'Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Lan- guage Understanding. CoRR abs/1810.04805 (2018). arXiv:1810.04805 http://arxiv.org/abs/1810.04805',\n",
              " 'Wei Dong, Charikar Moses, and Kai Li. 2011. Efficient K-nearest Neighbor Graph Construction for Generic Similarity Measures. In Proceedings of the 20th International Conference on World Wide Web (Hyderabad, India) (WWW ’11). ACM, New York, NY, USA, 577-586. https://doi.org/10.1145/1963405. 1963487',\n",
              " 'Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, and Houda Benbrahim. 2019. Return of the Lernaean Hydra: Experimental Evalua- tion of Data Series Approximate Similarity Search. Proc. VLDB Endow. 13, 3 (2019), 403-420. https://doi.org/10.14778/3368289.3368303 Evelyn Fix and J. L. Hodges. 1989. Discriminatory Analysis. Nonpara- metric Discrimination: Consistency Properties. International Statisti- cal Review / Revue Internationale de Statistique 57, 3 (1989), 238-247. http://www.jstor.org/stable/1403797',\n",
              " 'Cong Fu and Deng Cai. [n.d.]. https://github.com/ZJULearning/efanna Cong Fu, Chao Xiang, Changxu Wang, and Deng Cai. 2019. Fast Ap- proximate Nearest Neighbor Search With The Navigating Spreading- out Graphs. PVLDB 12, 5 (2019), 461 - 474. https://doi.org/10.14778/ 3303753.3303754',\n",
              " 'Tiezheng Ge, Kaiming He, Qifa Ke, and Jian Sun. 2014. Optimized Product Quantization. IEEE Trans. Pattern Anal. Mach. Intell. 36, 4 (2014), 744-755. https://doi.org/10.1109/TPAMI.2013.240',\n",
              " 'Ruiqi Guo, Quan Geng, David Simcha, Felix Chern, Sanjiv Kumar, and Xiang Wu. 2019. New Loss Functions for Fast Maximum Inner Product Search. CoRR abs/1908.10396 (2019). arXiv:1908.10396 http: //arxiv.org/abs/1908.10396',\n",
              " 'Maurice Herlihy and Nir Shavit. 2012. The Art of Multiprocessor Pro- gramming, Revised Reprint (1st ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.',\n",
              " 'Piotr Indyk and Rajeev Motwani. 1998. Approximate Nearest Neigh- bors: Towards Removing the Curse of Dimensionality. In Proceed- ings of the Thirtieth Annual ACM Symposium on Theory of Computing (Dallas, Texas, USA) (STOC ’98). ACM, New York, NY, USA, 604-613.',\n",
              " '[33]',\n",
              " '[34]',\n",
              " '[35]',\n",
              " '[36]',\n",
              " '37',\n",
              " '38',\n",
              " '39',\n",
              " '40',\n",
              " '41',\n",
              " '42',\n",
              " '43',\n",
              " '44',\n",
              " '45',\n",
              " '46',\n",
              " '47',\n",
              " '48',\n",
              " '49',\n",
              " '50',\n",
              " '51',\n",
              " 'https://doi.org/10.1145/276698.276876',\n",
              " 'M Iwasaki. [n.d.]. _https://github.com/yahoojapan/NGT/wiki Masajiro Iwasaki and Daisuke Miyazaki. 2018. Optimization of In- dexing Based on k-Nearest Neighbor Graph for Proximity Search in High-dimensional Data.',\n",
              " 'Hervé Jégou, Matthijs Douze, and Cordelia Schmid. 2011. Product Quantization for Nearest Neighbor Search. IEEE Transactions on Pattern Analysis and Machine Intelligence 33, 1 (Jan. 2011), 117-128. https: //doi.org/10.1109/TPAMI.2010.57',\n",
              " 'Herve Jegou, Romain Tavenard, Matthijs Douze, and Laurent Am- saleg. 2011. Searching in one billion vectors: Re-rank with source coding. In Proceedings of the IEEE International Conference on Acous- tics, Speech, and Signal Processing, ICASSP 2011, May 22-27, 2011, Prague Congress Center, Prague, Czech Republic. 861-864. https: //doi.org/10.1109/ICASSP.2011.5946540',\n",
              " 'Qing-Yuan Jiang and Wu-Jun Li. 2015. Scalable Graph Hashing with Feature Transformation. In Proceedings of the 24th International Con- ference on Artificial Intelligence (Buenos Aires, Argentina) (IJCAI’15). AAAI Press, 2248-2254.',\n",
              " 'Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2017. Billion-scale similarity search with GPUs. arXiv preprint arXiv:1702.08734 (2017). Yannis Kalantidis and Yannis Avrithis. 2014. Locally Optimized Product Quantization for Approximate Nearest Neighbor Search. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2014, Columbus, OH, USA, June 23-28, 2014. 2329-2336. https://doi.org/10. 1109/CVPR.2014.298',\n",
              " 'Haridimos Kondylakis, Niv Dayan, Kostas Zoumpatianos, and Themis Palpanas. 2018. Coconut: A Scalable Bottom-Up Approach for Building Data Series Indexes. Proceedings of the VLDB Endowment 11 (03 2018). https://doi.org/10.14778/3184470.3184472',\n",
              " 'W. Li, Y. Zhang, Y. Sun, W. Wang, M. Li, W. Zhang, and X. Lin. 2020. Approximate Nearest Neighbor Search on High Dimensional Data — Experiments, Analyses, and Improvement. JEEE Transactions on Knowledge and Data Engineering 32, 8 (2020), 1475-1488. https://doi. org/10.1109/TKDE.2019.2909204',\n",
              " 'Wei Liu, Jun Wang, Sanjiv Kumar, and Shih-Fu Chang. 2011. Hashing with graphs. In ICML.',\n",
              " 'Yury A. Malkov and D. A. Yashunin. 2016. Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs. CoRR abs/1603.09320 (2016). arXiv:1603.09320 http://arxiv.org/abs/1603.09320',\n",
              " 'Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schiitze. 2008. Introduction to Information Retrieval. Cambridge University Press, USA.',\n",
              " 'Milvus. [n.d.]. https://milvus.io/',\n",
              " 'M. Muja and D. G. Lowe. 2014. Scalable Nearest Neighbor Algorithms for High Dimensional Data. IEEE Transactions on Pattern Analysis and Machine Intelligence 36, 11 (2014), 2227-2240.',\n",
              " 'Header only C++/python library for fast approximate nearest neigh- bors. [n.d.]._ https://github.com/nmslib/hnswlib',\n",
              " 'Yongjoo Park, Michael Cafarella, and Barzan Mozafari. 2015. Neighbor- Sensitive Hashing. Proc. VLDB Endow. 9, 3 (Nov. 2015), 144-155. https: //doi.org/10.14778/2850583.2850589',\n",
              " 'Nick Pentreath, Abdulla Abdurakhmanov, and Rob Royce. 2017. Michael Sokolov. 2020. https://issues.apache.org/jira/browse/ LUCENE-9004',\n",
              " 'Suhas Jayaram Subramanya, Fnu Dewvrit, Rohan Kadekodi, Ravis- hankar Krishnawamy, and Harsha Vardhan Simhadri. 2019. DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Sin- gle Node. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada, Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence',\n",
              " '52',\n",
              " '53',\n",
              " '54',\n",
              " '55',\n",
              " '56',\n",
              " '57',\n",
              " '58',\n",
              " '59',\n",
              " '60',\n",
              " '61',\n",
              " '62',\n",
              " 'd’Alché-Buc, Emily B. Fox, and Roman Garnett (Eds.). 13748- 13758. _ http://papers.nips.cc/paper/9527-rand-nsg-fast-accurate- billion- point-nearest-neighbor-search-on-a-single-node',\n",
              " 'Kohei Sugawara, Hayato Kobayashi, and Masajiro Iwasaki. 2016. On Approximately Searching for Similar Word Embeddings. 2265-2275. https://doi.org/10.18653/v1/P 16-1214',\n",
              " 'Yifang Sun, Wei Wang, Jianbin Qin, Ying Zhang, and Xuemin Lin. 2014. SRS: Solving c-Approximate Nearest Neighbor Queries in High Dimensional Euclidean Space with a Tiny Index. Proc. VLDB Endow. 8, 1 (Sept. 2014), 1-12. https://doi.org/10.14778/2735461.2735462 Narayanan Sundaram, Aizana Turmukhametova, Nadathur Satish, Todd Mostak, Piotr Indyk, Samuel Madden, and Pradeep Dubey. 2013. Streaming Similarity Search over One Billion Tweets Using Parallel Locality-Sensitive Hashing. Proc. VLDB Endow. 6, 14 (Sept. 2013), 1930-1941. https://doi.org/10.14778/2556549.2556574',\n",
              " 'Julie Tibshirani. 2019. _https://www.elastic.co/blog/text',\n",
              " 'similarity',\n",
              " 'search',\n",
              " 'with',\n",
              " 'vectors',\n",
              " 'in',\n",
              " 'elasticsearch',\n",
              " 'Vespa. [n.d.]._ https://vespa.ai',\n",
              " 'J. Wang, J. Wang, G. Zeng, Z. Tu, R. Gan, and S. Li. 2012. Scalable k-NN graph construction for visual descriptors. In 2012 IEEE Conference on Computer Vision and Pattern Recognition. 1106-1113. https://doi.org/ 10.1109/CVPR.2012.6247790',\n",
              " 'Mengzhao Wang, Xiaoliang Xu, Qiang Yue, and Yuxiang Wang. 2021. A Comprehensive Survey and Experimental Comparison of Graph- Based Approximate Nearest Neighbor Search. CoRR abs/2101.12631 (2021). arXiv:2101.12631 https://arxiv.org/abs/2101.12631',\n",
              " 'Roger Weber, Hans-Jérg Schek, and Stephen Blott. 1998. A Quanti- tative Analysis and Performance Study for Similarity-Search Meth- ods in High-Dimensional Spaces. In Proceedings of the 24rd Inter- national Conference on Very Large Data Bases (VLDB ’98). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 194-205. http: //dl.acm.org/citation.cfm?id=645924.671192',\n",
              " 'Chuangxian Wei, Bin Wu, Sheng Wang, Renjie Lou, Chaoqun Zhan, Feifei Li, and Yuanzhe Cai. 2020. AnalyticDB-V: A Hybrid Analytical Engine Towards Query Fusion for Structured and Unstructured Data. Proc. VLDB Endow. 13, 12 (2020), 3152-3165. https://doi.org/10.14778/ 3415478.3415541',\n",
              " 'Yair Weiss, Antonio Torralba, and Rob Fergus. 2008. Spectral Hashing. In Proceedings of the 21st International Conference on Neural Information Processing Systems (Vancouver, British Columbia, Canada) (NIPS’08). Curran Associates Inc., Red Hook, NY, USA, 1753-1760.',\n",
              " 'Bolong Zheng, Xi Zhao, Lianggui Weng, Nguyen Quoc Viet Hung, Hang Liu, and Christian S. Jensen. 2020. PM-LSH: A Fast and Accurate LSH Framework for High-Dimensional Approximate NN Search. Proc. VLDB Endow. 13, 5 (Jan. 2020), 643-655. _https://doi.org/10.14778/ 3377369.3377374',\n",
              " 'Recall Stability of FreshVamana Indices',\n",
              " 'Ramp-Up. We now measure the recall of an FreshVamana',\n",
              " 'index as it grows in size. We start with a Vamana index built on a subset of 100K points randomly sampled from the million point datasets. In each cycle, we delete 10K points from the index at random, and insert 12K new points from the remaining pool of points, so that index grows by 2000',\n",
              " 'points. The experiment concludes when the index reaches the full size of a million points. We plot the search recall varies over the cycles in Figure 9 with varying search list size. While the recall trends down for a fixed search list size',\n",
              " '15',\n",
              " 'recall@5',\n",
              " '94 94 0 100 200 300 400 0 100 200 300 400',\n",
              " 'cycles over SIFT1M cycles over GISTIM L24 L125',\n",
              " 'L45 L60 L300 L450',\n",
              " 'Figure 9. Search 5-recall@5 after each cycle of 12K inser- tions and 10K deletions to FreshVamana, ramping up from 100K to 1M points. Horizontal lines indicate recall of the corresponding batch built Vamana index.',\n",
              " '100 — 100 9 | “49 ——= © 98 98 = 97 97 5 96 - 96 + 4 © 95 /- 7 95 | 94 |- 94 93 ! ! ! 93 ! ! 0 20 40 60 0 20 40 #cycles #cycles L60 L150 L 220 L55 L100 L200',\n",
              " 'Figure 10. Search recall FreshVamana on SIFT100M while (left) ramping up from 1 point; and (right) ramping up start- ing from 30M points, and steady-state after 45 cycles. Hor- izontal lines indicate recall of the Vamana index with the same build time.',\n",
              " 'Las expected’, note that the final index quality is at least as good as indices built in one shot using Vamana, whose recall or the same parameters is marked by horizontal lines.',\n",
              " 'B_ Index build times',\n",
              " 'n Table 1 we compare the build time of Vamana and Fresh- Vamana for the same build parameters. The trade-off for this speed-up comes in the form of increased search latency for the same k-recall@k. In Figure 11, we show that using FreshVamana to make updates to the index takes only a frac- tion of the time to rebuild it from scratch using Vamana. We show a similar comparison of DiskANN and FreshDiskANN in Table 2. Despite using more than double the resources, uilding a 800M index from scratch using DiskANN takes more than 7x the time that FreshDiskANN takes to reflect the same changes into the index.',\n",
              " 'C_ Effect of a on recall stability',\n",
              " 'To determine the optimal value of a, we perform the Fresh- Vamana steady-state experiments with different values of a. In the plots in Figure 3, we use the same value of a for',\n",
              " '5This is true of any index - a larger index over data from the same distribu- tion will provide lower recall with the search parameter/complexity.',\n",
              " '16',\n",
              " 'Table 1. Index build times for Vamana and FreshVamana on mem with R = 64, L, = 75,a = 1.2',\n",
              " 'Dataset | Vamana | FreshVamana | Speedup SIFT1M 32.38 21.8 s 1.48x DEEP1M 26.9s 17.78 1.52x GIST1M 417.2s 228.15 1.83x SIFT100M | 7187.1s 4672.1s 1.54x v S a as 5 : ey Sf & 0.5 g ° = s 8 s g e5l}| sé E\\\\y]s 2 g 02 a = xs ss S Z 01 a',\n",
              " 'do slo lo acto oho oho ste, lo logs ole ote SITS THYST CYST TY Ss',\n",
              " 'SIFT1M DEEPIM GIST1M  SIFT100M',\n",
              " 'Figure 11. Time taken to merge delete and re-insert of 5%, 10%, and 50% of index size into a FreshVamana index, ex- pressed relative to index rebuild time for Vamana.',\n",
              " 'Table 2. Full build time with DiskANN (96 threads) versus FreshDiskANN (40 threads) to update a 800M index with 30M inserts and deletes',\n",
              " 'Dataset',\n",
              " 'SIFT800M',\n",
              " 'DiskANN(sec)',\n",
              " '83140 s',\n",
              " 'StreamingMerge (sec)',\n",
              " '15832 s',\n",
              " 'building the intial Vamana index and for updating it. Other build and update parameters are same for each plot (R = 64, L = 75). We compare the evolution of search recall in the 95% range and average degree with different a. Finally we compare search recall versus latency for static indices built with different a to choose the best candidate. For all a > 1, average degree increases over the course of the ex- periments and recall stabilises around the initial value. For static indices, latency at the same recall value improves from 1 to 1.2 after which further increasing a shows now notice- able improvement as evidenced by recall-vs-latency plots for Vamana indices in Figure 13. Since we want to minimise the memory footprint of our index, we choose the a value with best search performance and lowest average degree, which in this case is 1.2.',\n",
              " 'SIFT1M Deep1M',\n",
              " 'y 64',\n",
              " 'Ea! ¢',\n",
              " '2 48 |',\n",
              " '& 32',\n",
              " '° 16',\n",
              " '< 0',\n",
              " '0 20 40 0 20 40 Cycles (5% index size) a=1 a=1.1 a=1.2 a=13',\n",
              " 'Figure 12. Evolution trends of recall and average degree for FreshVamana indices on SIFT1M and Deep1M over multiple cycles of inserting and deleting 5% of the index, where each trend represents a different a value used for building and updating the index.',\n",
              " 'SIFT1M Deep1M 100 — 100 g 99 + 99 4 5 98 | 98 4 2 97 | 97 4 © 96 | 96 4 95 | | 95 | | 1 200 400 600 00 200 300 400 500 Mean query latency (js) a@=1 a=1.1 a=1.2 @=13 Figure 13. Recall vs latency curves for Vamana indices on SIFT1M and Deep1M built with different values of a',\n",
              " 'D Amortized Cost of Delete Phase in StreamingMerge',\n",
              " 'Any non-trivial computation in the delete phase happens only for undeleted points p € P which have neighbors from the delete list. For each such point p, Algorithm 4 applies the pruning process on the candidate list consisting of the undeleted neighbors of p and the undeleted neighbors of the deleted neighbors of p to select the best R points from to its updated neighborhood. In order to perform an average-case analysis, let us assume that the delete set D is a randomly chosen set from the active points P, and suppose |P| = N and PI = B. The expected size of the candidate list will be R(1 — B) + R’B(1 — B). Here the first term accounts for undeleted neighbors of p and the second term accounts for undeleted neighbors of deleted neighbors of p. The expected number of undeleted points in the index is N(1 — ). Therefore the total number of expected operations in the delete phase will be proportional to NR(1— f)? (1 + Rf). This assumes that the complexity of the prune procedure is linear in the size of the candidate list which we validated empirically below. For large values of , the (1— )? term is diminishingly small and the deletion phase is quick. For small values of £ (around 5%— 10%) and typical values of R € [64, 128], RB > 1',\n",
              " '17',\n",
              " 'and hence it dominates the value of the expression. Since Nf = |D|, the time complexity becomes directly proportional to the size of the delete list.',\n",
              " 'We demonstrate the linear time complexity of Algorithm 3 in Figure 14. We delete a small fraction(10%) of SIFT1M Vamana index and record the time taken by Algorithm 3 as the candidate list size increases.',\n",
              " 'es',\n",
              " '3700',\n",
              " '£600',\n",
              " '500',\n",
              " '© 400',\n",
              " '£300',\n",
              " 'E200',\n",
              " '55100',\n",
              " '0 200',\n",
              " '400',\n",
              " '#Points in candidate list',\n",
              " '600',\n",
              " 'Figure 14. Trend of Algorithm 3 run time with increasing size of candidate list when 10% of the SIFT1M index is being deleted.',\n",
              " 'E_ k-recall@k for various k values E.1_ FreshVamana',\n",
              " 'E.1.1 Search Latency vs Recall. In Figures 15 to 17, we compare the search latencies for Vamana and build time- normalized FreshVamana (build parameters adjusted to match the build time of Vamana) for various k-recall@k. For 1- recall@1 and 10-recall@10, we compare latencies for 95%, 98% and 99% recall. For 100-recall@100, we compare over 98% and 99% recall because the lowest search list parameter L value gives 98% recall.',\n",
              " 'E.1.2 Recall stability of FreshVamana. In Figure 18, we demonstrate k-recall@k stability of FreshVamana for com- monly used k values. We show the post-insertion recall trends for 1-recall@1, 10-recall@10 and 100-recall@100. For k = 1, we show how the 95% and 99.9% recall are stable. For k = 10, we show that 95% and 99% recall are stable. For k = 100, the lowest valid search list parameter L value is 100 and this gives 98% recall. So we show the stability of 98% and 99% recall.',\n",
              " 'E.2. FreshDiskANN',\n",
              " 'E.2.1 Search latencies over one merge cycle. In ? ?? ?, we present the evolution of mean search latency for 100- recall@100 and 10-recall@10 over the course of one merge cycle in a 800M FreshDiskANN steady-state experiment.',\n",
              " 's > 4g Z = 4 5 ° & > i08 a 2 3 an aa vo a] ow s,/. “ Ea SS E\\\\|Sp EB g sb nH B 1} Sees ht} ghee o xeSso® | SASSSS eee Gf | eam! by nn 95 98 99 95 98 99 95, 98 99 95 98 99 SIFT1IM DEEP1IM GIST1M _ SIFT100M',\n",
              " 'Q0Vamana [0FreshVamana',\n",
              " 'Figure 15. Query latency for Vamana and build-time nor- malized FreshVamana 1-recall@1 at 95%, 98%, and 99%.',\n",
              " 'g —°® aun = 3 3 g 4 go S v ° eal q 3 = yaa 4 > &N REGS Bo S = = 3 ane | suman aeedak | geass Oly aedsde | SS ssas | | ono mi ooo { 95 98 99 95 98 99 95 98 99 95 98 99 SIFTIM DEEPIM GISTiM  SIFT100M',\n",
              " 'O0Vamana_ [0 FreshVamana',\n",
              " 'Figure 16. Query latency for Vamana and build-time nor- malized FreshVamana 10-recall@10 at 95%, 98%, and 99%.',\n",
              " 'R24 Bs x & 7 ag 2 6 In on $3 ag Ss 4 mo 3 BS 2+ ma 2% a a y| 82 25 82 | 32 of of on no Wy 98 99 99 98 99 SIFT1M DEEPIM GISTiM SIFT100M. Q0Vamana [0FreshVamana',\n",
              " 'Figure 17. Query latency for Vamana and build-time nor- malized FreshVamana 100-recall@100 at 98%, and 99%.',\n",
              " 'F Search latency of FreshDiskANN',\n",
              " 'In Figure 21, we observe the effect of number of search threads on mean search latencies for 800M index when no merge is going on.',\n",
              " '18',\n",
              " '100 ————_$$——',\n",
              " 'Ivasrmernenneeennernrnernnenteeeaetarat —— k=1,Ls=18 eae —— k=1,Ls=165 po —— k=10,Ls = 26 z 98 —~— k=10,Ls=75 v 97} —-— k = 100,Ls = 116 we 96 Mae | —.— k = 100, Ls = 162 95 | | 0 20 40 #Batches(5% size) 100 ———$—_____—— | eseraetenatteneaanetatntntettasnteesnetee —— k=1,Ls=18 we IF —— k=1,Ls = 165 iS) 98 [ores —-— k=10,Ls =26 3 — 0,Ls = 75 2 97} —.— k = 100, Ls = 116 95 L L 0 20 40 #Batches(10% size) 100 peep | —— k=1,Ls=18 we IF —— k=1,Ls=165 © 99 beeen —— k=10,Ls=26 S ——— k=10,Ls=75 2 OTF —.— k = 100, Ls = 116 ~~ 96) —-— k = 100, Ls = 162 os Ruane | 0 20 40',\n",
              " '#Batches(50% size)',\n",
              " 'Figure 18. Post-insertion search k-recall@k for k = 1, 10, 100 of FreshVamana index over 50 cycles of deletion and re-insertion of 5%, 10% and 50% (rows 1, 2 and 3 re- spectively) of SIFT1M index with varying search list size parameter L.',\n",
              " 'G Concurrency during StreamingMerge',\n",
              " 'In this section, we present our observations on search latency during merge through in-depth experiments on FreshDiskANN merge with varying thread allocations. All experiments are 30M insertions and deletions into a 800M FreshDiskANN index.',\n",
              " 'G.1 Search threads fixed',\n",
              " 'varying merge threads',\n",
              " 'We run the merge on SIFT800M index with different thread allocations to understand the effect of merge on search la- tency. In Figure 8, we plot a smoothed curve of mean search latencies when merge uses 20 and 40 threads. Merge with 40 threads takes approximately half the time as that with 20, so there are two x axes adjusted to roughly align their Delete, Insert and Patch phases. As evident from the figure, search',\n",
              " 'an',\n",
              " 'Search latency(ms)',\n",
              " 'iS)',\n",
              " '0 10 20 30 Number of threads Figure 21. Trend of mean latencies for 95% search recall on',\n",
              " 'a 800M SIFT index with different number of threads. Each point is calculated over a search batch of 10000 queries',\n",
              " \"30 T T Patch D25 + : to | & 4 —1 > 1 rio 2 320} Delete ' Insert ' |! 4 £ i |i 4 & tt _ 6 gh rte | 3 w Hh B10 | 5 1 n | n 1 1 0 0.5 1 1.5 “104\",\n",
              " 'Time elapsed(sec)',\n",
              " 'Figure 22. Trend of mean search latencies for 92% search recall, zoomed in over one cycle of inserting and deleting 30M points concurrently into a 800M SIFT index, using different number of threads for search. Each point is the mean latency over a search batch of 10000 queries.',\n",
              " '19',\n",
              " \"70 T T rola 1 ' 1 1 oo fF ' Pateh 4 = toi 350} Delete Insert! ' uv 2 it = 40} 1 th 4 3 1 g boha F330 PL air hechathaiornhaetehyy tha rod 20 1 | 1 | L 4 0 0.2 04 0.6 0.8 1.2 104\",\n",
              " 'Time elapsed(sec)',\n",
              " 'Figure 19. Trend of mean search latencies for 95% search 100-recall@100, zoomed in over one cycle of inserting and deleting 30M points concurrently into a 800M SIFT index, using different 10 for search. Each point is the mean latency over a search batch of 10000 queries.',\n",
              " 'td',\n",
              " 'Delete',\n",
              " 'an',\n",
              " 'Search latency(ms)',\n",
              " 'it',\n",
              " 'Time elapsed(sec)',\n",
              " 'Figure 20. Trend of mean search latencies for 95% search 10-recall@10, zoomed in over one cycle of inserting and deleting 30M points concurrently into a 800M SIFT index, using different 10 for search. Each point is the mean latency over a search batch of 10000 queries.',\n",
              " 'latencies with 40 thread merge are consistently higher in the Delete and Insert phases of merge.',\n",
              " 'G.2 Merge threads fixed',\n",
              " 'varying search threads',\n",
              " 'We run the merge on SIFT800M index with different thread allocations to understand the effect of number of search threads used during merge on search latency. We increase',\n",
              " 'the number of search threads while fixing 40 threads for merge, and observe how the search latency trend evolves in',\n",
              " 'over one merge cycle Figure 22.']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[i.text for i in partitioned_files.get('freshdisk')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c439c74-8a6b-4962-af7e-7e8d450e5b54",
      "metadata": {
        "id": "5c439c74-8a6b-4962-af7e-7e8d450e5b54"
      },
      "source": [
        "Let's now get rid of those strange words that have been split across page breaks (e.g. `funda- mental`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e62b963-64eb-4b03-a50c-7ae5d98e7197",
      "metadata": {
        "id": "7e62b963-64eb-4b03-a50c-7ae5d98e7197"
      },
      "outputs": [],
      "source": [
        "# Note: this function transforms our elemenets into their text representations\n",
        "\n",
        "def rejoin_split_words(elements: Dict[str, List[Text]]) -> None:\n",
        "    \"\"\"\n",
        "    Rejoing words that are split over pagebreaks.\n",
        "\n",
        "    :parameter elements: Partitioned pieces of our documents.\n",
        "    \"\"\"\n",
        "    for key, value in elements.items():\n",
        "        elements[key] = [i.text.replace('- ', '') for i in value if '- ' in i.text]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee954160-75f7-44b4-a5c1-5bda0037fcce",
      "metadata": {
        "id": "ee954160-75f7-44b4-a5c1-5bda0037fcce"
      },
      "outputs": [],
      "source": [
        "rejoin_split_words(partitioned_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eaf8942-ed2b-4053-9a51-55a678ed8909",
      "metadata": {
        "id": "1eaf8942-ed2b-4053-9a51-55a678ed8909"
      },
      "outputs": [],
      "source": [
        "# partitioned_files.get('freshdisk')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5325d394-1266-4292-bf46-1d2d41a798ad",
      "metadata": {
        "id": "5325d394-1266-4292-bf46-1d2d41a798ad"
      },
      "source": [
        "You can see now that we've sewn those split words back together:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551b2690-d91f-44a6-9969-fe2cc2142cc5",
      "metadata": {
        "id": "551b2690-d91f-44a6-9969-fe2cc2142cc5"
      },
      "source": [
        "The last cleaning step we'll want to take is removing the inline citations, e.g. `[6, 9, 11, 16, 32, 35, 38, 43, 59]` and `[12]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6383895a-72ec-4923-aa00-f2848822d35e",
      "metadata": {
        "id": "6383895a-72ec-4923-aa00-f2848822d35e"
      },
      "outputs": [],
      "source": [
        "def remove_inline_citation_numbers(elements: Dict[str, List[Text]]) -> None:\n",
        "    \"\"\"\n",
        "    Remove inline citation numbers from partitions.\n",
        "\n",
        "    :parameter elements: Partitioned pieces of our documents.\n",
        "    \"\"\"\n",
        "    for key, value in elements.items():\n",
        "        pattern = re.compile(r'\\[\\s*(\\d+\\s*,\\s*)*\\d+\\s*\\]')\n",
        "        elements[key] = [pattern.sub('', i) for i in value]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c59afe18-b664-4a0a-8103-91049ecb9bca",
      "metadata": {
        "id": "c59afe18-b664-4a0a-8103-91049ecb9bca"
      },
      "outputs": [],
      "source": [
        "remove_inline_citation_numbers(partitioned_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17d99d35-605f-4dfc-af6f-47488aa2c7ab",
      "metadata": {
        "id": "17d99d35-605f-4dfc-af6f-47488aa2c7ab"
      },
      "source": [
        "We've still got some weird numbers in there, but it's pretty good!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f6cb1c5-ea66-4be9-9246-ae8a39e4ab28",
      "metadata": {
        "id": "8f6cb1c5-ea66-4be9-9246-ae8a39e4ab28"
      },
      "outputs": [],
      "source": [
        "# partitioned_files.get('freshdisk')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a653859f-4a0e-44b8-b49d-dc904cb141c9",
      "metadata": {
        "id": "a653859f-4a0e-44b8-b49d-dc904cb141c9"
      },
      "source": [
        "Now that we've cleaned our data, we can zip all the partitions (per PDF) back together so we're starting our chunking from a single, coherent text object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a8190b3-7d9d-45cd-8463-4e47729f9016",
      "metadata": {
        "id": "7a8190b3-7d9d-45cd-8463-4e47729f9016"
      },
      "outputs": [],
      "source": [
        "# Sew our partitions back together, per PDF:\n",
        "\n",
        "def stitch_partitions_back_together(elements: Dict[str, List[Text]]) -> None:\n",
        "    \"\"\"\n",
        "    Stitch partitions back into single string object.\n",
        "\n",
        "    :parameter elements:  Partitioned pieces of our documents.\n",
        "    \"\"\"\n",
        "    for key, value in elements.items():\n",
        "        elements[key] = ' '.join(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7051c57-483e-4262-92a1-84dfa00c3f6e",
      "metadata": {
        "id": "c7051c57-483e-4262-92a1-84dfa00c3f6e"
      },
      "outputs": [],
      "source": [
        "stitch_partitions_back_together(partitioned_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc64d40-6205-4371-9b0b-a503b8fb45ef",
      "metadata": {
        "id": "afc64d40-6205-4371-9b0b-a503b8fb45ef"
      },
      "source": [
        "Good to go! All of our PDFs are now cleaned and single globs of text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a985d1a-caa0-4e91-a510-0b8b440f1a22",
      "metadata": {
        "id": "0a985d1a-caa0-4e91-a510-0b8b440f1a22",
        "scrolled": true,
        "outputId": "f0572d7b-7181-4838-bafa-07dd83fd62c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'freshdisk': 'Approximate nearest neighbor search (ANNS) is a fundamental building block in information retrieval with graphbased indices being the current state-of-the-art  and widely used in the industry. Recent advances  in graph-based indices have made it possible to index and search billion-point datasets with high recall and millisecond-level latency on a single commodity machine with an SSD. In this paper, we present the first graph-based ANNS index that reflects corpus updates into the index in real-time without compromising on search performance. Using update tules for this index, we design FreshDiskANN, a system that can index over a billion points on a workstation with an SSD and limited memory, and support thousands of concurrent real-time inserts, deletes and searches per second each, while retaining > 95% 5-recall@5. This represents a 5-10x reduction in the cost of maintaining freshness in indices when compared to existing methods. In the Nearest Neighbor Search problem, we are given a dataset P of points along with a pairwise distance function. The goal is to design a data structure that, given a target k and a query point q, efficiently retrieves the k closest neighbors for q in the dataset P according to the given distance function. This fundamental problem is well studied in the research community  and is a critical component for diverse applications in computer vision , data mining , information retrieval , classification , and recommendation systems , to name a few. As advances in deep learning have made embeddingbased approaches the state-of-the-art in these applications, there has been renewed interest in the problem at scale. Several open-source inverted-index based search engines now support NNS , and new search engines based on Since it is impossible to retrieve the exact nearest neighbors without a cost linear in the size of the dataset in the general case (see ) due to a phenomenon known as the curse of dimensionality , one aims to find the approximate nearest neighbors (ANN) where the goal is to retrieve k neighbors that are close to being optimal. The quality of an ANN algorithm is judged by the trade-off it provides between accuracy and the hardware resources such as compute, memory and I/O consumed for the search. Even though this abstraction of ANN search is widely studied, it does not capture many important real-world scenarios where user interactions with a system creates and destroys data, and results in updates to P (especially in the literature on graph-based ANNS indices ). For example, consider an enterprise-search scenario where the system indexes sentences in documents generated by users across an enterprise. Changes to sentences in a document would correspond to a set of new points inserted and previous points deleted. Another scenario is an email server where arrival and deletion of emails correspond to insertion and deletion of points into an ANNS index. ANNS systems for such applications would need to host indices containing trillions of points with real-time updates that can reflect changes to the corpus in user searches, ideally in real-time. Motivated by such scenarios, we are interested in solving the fresh-ANNS problem, where the goal is to support ANNS on a continually changing set of points. Formally, we define the fresh-ANNS problem thus: given a time varying dataset P (with state P; at time t), the goal is to maintain a dynamic index that computes the approximate nearest neighbors for any query q issued at time t only on the active dataset P;. Such a system must support three operations (a) insert a new point, (b) delete an existing point, and (c) search for the nearest neighbors given a query point. The overall quality of a fresh-ANNS system is measured by: Goal. Motivated by real-world scenarios, we seek to build the most cost-effective system for the fresh-ANNS problem which can maintain a billion-point index using commodity machines with 128GB RAM and a 2TB SSD? and support thousands of real-time inserts and deletes per second, and also thousands of searches per second with high accuracy of 95+% 5-recall@5. Indeed, the current state-of-art system for fresh-ANNS which can support comparable update and search performance on a billion-point dataset is based on the classical LSH algorithm , and requires a hundred machines of 32GB RAM (translating to around 25 machines of our stated configuration). In this work, we seek to reduce this deployment cost down to a single machine per billion points. To handle trillion-point indices (as in web-search scenarios), one can employ a simple distributed approach wherein thousand machines host a billion points each — queries are broadcast and results aggregates while updates are routed to the appropriate nodes. Of all the algorithms for static-ANNS, the ones most easily capable of supporting streaming support are the ones based on simple hashing algorithms such as LSH (locality sensitive hashing). However, these algorithms suffer from either being too memory intensive, needing to store hundreds of hash functions in main memory, or become extremely slow for query processing when the index is stored on secondary storage. For example, the state-of-art system for streaming similarity search (or fresh-ANNS), PLSH , is a parallel and distributed LSH-based mechanism. While it offers comparable update throughput and search performance as our system, it ends up needing 25X more machines due to the high RAM consumption. A similar issue can be seen with PM-LSH, another state-of-art system based on LSH , where the memory footprint is a bit lower than PLSH (due to the system using fewer LSH tables), but the query latencies are an order of magnitude slower than our system and PLSH. Alternately, disk-based LSH indices such as SRS  can host a billion-point index on a single machine, but the query latencies are extremely slow with the system fetching around 15% of the total index (running into GBs per query) from the disk to provide good accuracy. Another recent algorithm HD-Index  can serve a billion-point index with just a few megabytes of RAM footprint, but it suffers from search latencies of a few seconds to get accuracy of around 30%. Moreover, the algorithm only handles insertions, and simply performs a variant of blacklisting for deletions, and hence would need periodic rebuilding. Finally, there are other classes of ANNS algorithms such as kd-Tree , Cover Trees  which support reasonably efficient update policies, but these algorithms work well only when the data dimensionality is moderately small (under 20); their performance drops when the data dimensionality is 100 or more which is typical for points generated by deep-learning models.. At the other end of the spectrum of ANNS indices are graph-based indexing algorithms . Several comparative studies  of ANNS algorithms have concluded that they significantly out-perform other techniques in terms of search throughput on a range of realworld static datasets. These algorithms are also widely used in the industry at scale. However, all known graph indices are static and do not support updates, especially delete requests , possibly due to the fact that simple graph modification rules for insertions and deletions do not retain the same graph quality over a stream of insertions and deletions. As a result, the current practice in industry is to periodically re-build such indices from scratch  to manifest recent changes to the underlying dataset. However, this is a very expensive operation. It would take about 1.5-2 hours on a dedicated high-end 48-core machine to build a good quality HNSW index  over 100M points. So we would need three dedicated machines for constantly rebuilding indices to maintain even six-hourly freshness guarantee over a billionpoint index. This is apart from the cost of actually serving the indices, which would again be anywhere between one for DRAM-SSD hybrid indices  to four for in-memory indices  depending on the exact algorithm being deployed. This paper aims to serve and update an index over a billion points with real-time freshness using just one machine. This represents a significant cost advantage for web and enterprise-scale search platforms that need to serve indices spanning trillions of points. 1. We demonstrate how simple graph update rules result in degradation of index quality over a stream of insertions and deletions for popular graph-based algorithms such as HNSW  and NSG . 3. In order to enable scale, our system stores the bulk of the graph-index on an SSD, with only the most recent updates stored in memory. To support this, we design a novel two-pass StreamingMerge algorithm which makes merges the in-memory index with the SSD-index in a very write-efficient manner (crucial since burdening the SSD would lead to worse search performance as well). Notably, the time and space complexity of the merge procedure is proportional to the change set, thereby making it possible to update large billion-point indices on a machine with limited RAM using an order of magnitude less compute and memory than re-building the large index from scratch. 4. Using these ideas, we design the FreshDiskANN system to consist of a long-term SSD-resident index over the majority of the points, and a short-term in-memory index to aggregate recent updates. Periodically, unbeknownst to the end user, FreshDiskANN consolidates the short-term index into the long-term index using our StreamingMerge process in the background to bound the memory footprint of the short-term index, and hence the overall system. Trees. Some of the early research on ANNS focused on low-dimensional points (say, d < 20). For such points, spatial partitioning ideas such as R*-trees , kd-trees  and Cover Trees  work well, but these typically do not scale well for high-dimensional data owing to the curse of dimensionality. There have been some recent advances in maintaining several trees and combining them with new ideas to develop good algorithms such as FLANN  and Annoy . However, they are built for static indices, and moreover, even here, the graph-based algorithms outperform them  on most datasets. Hashing. In a breakthrough result, Indyk and Motwani  show that a class of algorithms, known as locality sensitive hashing can yield provably approximate solutions to the ANNS problem with a polynomially-sized index and sublinear query time. Subsequent to this work, there has been a plethora of different LSH-based algorithms , including those which depend on the data , use spectral methods , distributed LSH , etc. While the advantage of the simpler data-independent hashing methods are that updates are almost trivial, the indices are often entirely resident in DRAM and hence do not scale very well. Implementations which make use of auxiliary storage such as SRS  typically have several orders of magnitude slower query latencies compared to the graph-based algorithms. Other hashing-based methods  learn an optimal hash family by exploiting the neighborhood graph. Updates to an index would require a full re-computation of the family and hashes for every database point, making them impractical for fresh-ANNS. Data quantization and Inverted indices based algorithms have seen success w.r.t the goal of scaling to large datasets with low memory footprint. These algorithms effectively reduce the dimensionality of the ANNS problem by quantizing vectors into a compressed representation so that they may be stored using smaller amount of DRAM. Some choices of quantizers  can support GPU-accelerated search on billion-scale datasets. Popular methods like IV- memory-footprint indices with reasonable search performance when querying for a large number of neighbors. While most methods minimize the vector reconstruction error ||x — x‘ ||?, where x is a database vector and x? is its reconstruction from the quantized representation, Anisotropic Vector Quantization  optimizes for error for maximum inner-product search. Some of these systems such as FAISS  support insert and delete operations on an existing index under reasonable conditions like stationary data distributions. However, due to the irreversible loss due to the compression/quantization, these methods fail to achieve even moderate values of 1-recall@1, sometimes plateauing at 50% recall. These methods offer good guarantees on weaker notions such as 1-recall@100, which is the likelihood that the true nearest neighbor for a query appears in a list of 100 candidates output by the algorithm. Hence they are not the methods of choice for high-recall high-throughput scenarios. A recent work, ADBV , proposes a hybrid model for supporting streaming inserts and deletes. New points are inserted into an in-memory HNSW  index while the main on-disk index utilises a new PQ-based indexing algorithm called VGPQ. In order to mitigate the accuracy loss due to PQ, VGPQ search performs a large number of distance computations and incurs high search latencies. As distributed system over several powerful nodes, the model has low search throughput even when no inserts and deletes are going on. Hence, such a system cannot be used in high-throughput scenarios. In this section, we recap how most state-of-the-art graphbased indices work for static-ANNS and also highlight the issues they face with supporting deletions. graph, we let Nout(p) and Nin(p) denote the set of outand in-edges of p. We denote the number of points by n = |P|. Finally, we let xp denote the database vector corresponding to p, and let d(p, q) = ||xp — Xq|| denote the f distance between two points p and q. We now describe how graph-based ANNS indices are built and used for search. Roughly speaking, navigability of a directed graph is the property that ensures that the index can be queried for nearest neighbors using a greedy search algorithm. The greedy search algorithm traverses the graph starting at a designated navigating or start node s € P. The search iterates by greedily walking from the current node u to a node v € Nout(u) that minimizes the distance to the query, and terminates when it reaches a locally-optimal node, say p*, that has the property d(p*,q) < d(p,q) Vp € Nou(p*). Greedy search cannot improve distance to the query point by navigating out of p* and returns it as the candidate nearest neighbor for query q. Algorithm 1 describes a variant of this greedy search algorithm that returns k nearest neighbor candidates. Index Build consists of constructing a navigable graph. The graph is typically built to achieve two contrasting objectives to minimize search complexity: (i) make the greedy search algorithm applied to each base point p € P in the vertex set converge to p in the fewest iterations (intuitively, this would ensure that Algorithm 1 converges to p when searching for a query Xq if p is the nearest-neighbor for xq), and (ii) have a maximum out-degree of at most R for all p € P, a parameter typically between 16 — 128. While graph-indices offer state-of-the-art search performance, all known algorithms apply for the static-ANNS problem. In particular, deletions pose a big challenge for all these algorithms — e.g., see this discussion  on HNSW supporting delete requests by adding them to a blacklist and omitting from search results. Arguably, this is due to the lack of methods which modify the navigable graphs while retaining the original search quality. To further examine this phenomenon, we considered three popular static-ANNS algorithms, namely HNSW, NSG, and Vamana and tried the following natural update policies when faced with insertions and deletions. Insertion Policy. For insertion of a new point p, we run the candidate generation algorithm as used by the respective algorithms and add the chosen inand out-edges, and if necessary, whenever the degree of any vertex exceeds the budget, run the corresponding pruning procedure. Delete Policy A. When a point p is deleted, we simply remove all inand out-edges incident to p, without adding any newer edges to compensate for potential loss of navigability. Indeed, note that p might have been on several navigating paths to other points in the graph. Delete Policy B. When a point p is deleted, we remove all inand out-edges incident to p, and add edges in the local neighborhood of p as follows: for any pair of directed edges (pin, p) and (p, Pout) in the graph, add the edge (pin, Pout) in the updated graph. If the degree bound of any vertex is violated, we run the pruning procedure associated with the respective algorithm to control the degrees. Figure 1 shows that both of these delete policies are not effective. In this experiment, we consider the SIFT1M dataset  comprising of a million points in 128 dimensions, and start with the static-ANNS index for each of the algorithms. We then compose an update stream by selecting 5% of the points at random and deleting them, followed by presenting them again as insertions. We then repeat this process over multiple Figure 1. Search recall over 20 cycles of deleting and reinserting 5% of SIFT1M dataset with statically built HNSW, Vamana, and NSG indices with L; = 44, 20, 27, respectively. A new point x, is inserted into a FreshVamana index using Algorithm 2. Intuitively, it queries the current index for nearest neighbors of p to obtain the visited set V, generates candidate out-neighbors for xp using pruning procedure in Algorithm 3 on VV, and adds bi-directed edges between p and the pruned candidates. If out-degree of any vertex exceeds R, Algorithm 3 can be used to prune it to R. Our deletion algorithm Algorithm 4 is along the lines of Delete Policy B in Section 3.3, with the crucial feature being using the relaxed a-pruning algorithm to retain density of the modified graph. Specifically, if p is deleted, we add edges (p’,p’’) whenever (p’, p) and (p, p’”) are directed edges in the current graph. In this process, if |Nout(p’)| exceeds the maximum out-degree R, we prune it using Algorithm 3, preserving the a—RNG property. However, since this operation involves editing the neighborhood for all the in-neighbors of p, it could result be expensive to do eagerly, i.e., processing deletes as they arrive. FreshVamana employs a lazy deletion strategy when a point p is deleted, we add p to a DeleteList without changing the graph. DeleteList contains all the points that have been deleted but are still present in the graph. At search time, a modified Algorithm 1 uses nodes in the DeleteList for navigation, but filters them out from the result set. Delete Consolidation. After accumulating a non-trivial number of deletions (say 1-10% of the the index size), we batch-update the graph using Algorithm 4 to update the neighborhoods of points with out-edges to these deleted nodes. This operation is trivially parallelized using prefix sums to consolidate the vertex list, and a parallel map operation to locally update the graph around the deleted nodes. We now demonstrate how using our insert and delete algorithms (along with a choice of a > 1) ensures that the resulting index is stable over a long stream of updates. 5% Index Size 10% Index Size 50% Index Size 100 100 100 3 99 99 7 99 | ——  SIFTIM © 98 98 | | 98 4 ——  DeepiM a 97 97|| 97 4 2 96 96 96 by Sydieoeatd ——  GISTIM fe 95 95 Saeeeoceaell 95 “ah —— SIFT100M 94 94 ; ; 94 ; ; 0 20 40 20 40 Cycles Cycles SIFT1M Deep1M 98 to ® 96 ‘Ss 94 # ite) 92 90 20 40 0 20 40 Cycles (5% index size) a=1 a=1.1 a=1.2 a=13 scale to a billion-points per machine due to the large memory footprint of storing the graph and data in RAM. The main idea of overall system FreshDiskANN is to store a bulk of the graph-index on an SSD, and store only the recent changes in RAMTo further reduce the memory footprint, we can simply store compressed vector representation (using an idea such as Product Quantization (PQ) ) of all the data vectors. In fact, these ideas of using a-RNG graphs and storing only compressed vectors formed the crux of the SSD-based DiskANN static-ANNS index . 3.As FreshVamana graphs are constructed using the a-RNG property (Section 4), the number of steps that the greedy search algorithm takes to converge to a locally optima is much smaller than other graph algorithms. Hence the total search latency to fetch the graph neighborhoods from SSD is small. So the a-RNG property helps us with both ensuring recall stability as well as obtaining tolerable search latencies for SSD-based indices. The overall system maintains two types of indices: one LongTerm Index (aka LTI) and one or more instances of Temporary Index (a.k.a TempIndex), along with a DeleteList. ROand RW-Templndex: To aid with crash recovery, FreshDiskANN uses two types of TempIndex. At all times, (called RW-TempIndex) which can accept insert requests. We periodically convert the RW-TempIndex into a read-only in-memory index called RO-TempIndex, and also snapshot it to persistent storage. We then create a new empty RWTemp!ndex to ingest new points. Finally, to complete the system design, we now present details of the StreamingMerge procedure. Whenever the total memory footprint of the various RO-TempIndex exceeds a pre-specified threshold, the system invokes a background merge procedure serves to change the SSD-resident LTI to reflect the inserts from the various instances of the ROTempIndex and also the deletes from the DeleteList. To this end, for notational convenience, let dataset P reflect the points in the LTI, and N denote points currently staged in the different RO-TempIndex instances, and D denote the points marked for deletion in DeleteList. Then the desired end-result of the StreamingMerge is an SSD-resident LTI over the dataset (P U N) \\\\ D. Following the successful completion of the merge process, the system clears out the ROTempIndex instances thereby keeping the total memory footprint under control. There are two important constraints that the procedure must follow: At a high level, StreamingMerge first runs Algorithm 4 to process the deletes from D to obtain an intermediate-LTI index over the points P\\\\ D. Then StreamingMerge runs Algorithm 2 to insert each of the points in N into the intermediateLTI to obtain the resultant LTI. However, Algorithms 2 and 4 assume that both the LTI graph, as well as the full-precision vectors all the datapoints are stored in memory. The crucial challenges in StreamingMerge is to simulate these algorithm invocations in a memory and SSD-efficient manner. This is done in three phases outlined below. 1. Delete Phase: This phase works on the input LTI instance and produces an intermediate-LT| by running Algorithm 4 to process the deletions D. To do this in a memoryefficient manner, we load the points in LTI and their neighborhoods in the LT! block-by-block from the SSD, and execute Algorithm 4 for the nodes in the block using multiple threads, and write the modified block back to SSD on the intermediate-LTI. Furthermore, whenever Algorithm 4 or Algorithm 3 make any distance comparisons, we use the compressed PQ vectors which are already stored on behalf of the LTI to calculate the approximate distances. Note that this idea of replacing any exact distance computations with approximate distances using the compressed vectors will be used in the subsequent phases of the StreamingMerge also. 2. Insert Phase: This phase adds all the new points in N to the intermediate-LTI by trying to simulate Algorithm 2. As a first step, we run the GreedySearch(s, p, 1, L) on the SSDresident intermediate-LTI to get the set V of vertices visited on the search path. Since the graph is stored on the SSD, any requested neighborhood Nou(p’) by the search algorithm is fetched from the SSD. The a-RNG property ensures that the number of such neighborhood requests is small, and hence the overall latency per point is bounded. We then run the RobustPrune(p, V, a, R) procedure to determine the candidate set of neighbors for p. However, unlike Algorithm 2, we do not immediately attempt to insert p into Nour(p’) for P’ © Nout(p) (the backward edges) since this could result in an impractical number of random reads and writes to 3. Patch Phase: After processing all the inserts, we patch the A data-structure into the output SSD-resident LTI index. For this, we fetch all points p in the intermediate-LTI blockby-block from the SSD, add the relevant out-edges for each node p from A, and check the new degree | Nou (p) UA(p)| exceeds R. If so, prune the neighborhood by setting Nour(p) = RobustPrune(p, Nour (p) U A(p), «, +). Within each block read from the SSD, this operation can be applied to each vertex in a data-parallel manner. Subsequently, the updated block is written back to SSD before loading a new block. 1/0 cost. The procedure does exactly two sequential passes over the SSD-resident data structure in the Delete and Patch Phases. Due to the a-RNG property of the intermediateLTI, the insertion algorithm performs a small number of random 4KB reads per inserted point (about 100 disk reads, a little more than the candidate list size parameter, which we typically set to 75). Note that this number would be much larger without the a-RNG property due to the possibility of very long navigation paths. Memory footprint: Throughout the StreamingMerge process, A data structure has size O(|N|R) where R is the max-degree parameter of the index which is typically a small constant. For example, if |N| = 30M and R = 64, this footprint will be ~7GB. In addition, for approximate distances, recall that we keep a copy of PQ coordinates for all points in the index (~ 32GB for a billion-point index). While we have already demonstrated that our update algorithms Algorithms 2 and 4 ensure recall stability over long streams of updates in Section 4.3, the actual form in which these algorithms are implemented in our StreamingMerge procedure is different, especially with the use of approximate compressed vectors for distance computations. Indeed, as we process more cycles of the StreamingMerge procedure, we expect the initial graph to be replaced by a graph entirely built based on approximate distances. Hence, we expect a In the experiment in Figure 4, we start with a statically built SSD-index built on 80M points randomly sampled from the SIFT100M dataset. Then, in each cycle, we update the index to reflect 8M deletions and an equal number of insertions from the spare pool of 20M points using StreamingMerge. We run this experiment for a total of 40 cycles and trace recall for the index after each cycle in Figure 4. Note that the index stabilizes at a lower recall value compared to the static index it starts out with, due to the use of approximate distances in the StreamingMerge process. We observe recall stabilization after ~ 20 cycles of deletion and insertion of 10% of the index size, at which point we expect most of the graph to be determined using approximate distances. Figure 4 (right) shows a similar plot for the 800M point subset of SIFT1B. We have thus empirically demonstrated that the FreshDiskANN index has stable recall over a stream of updates at steady-state. The frequency at which RW-TempIndex is snapshotted to a RO-TempIndex depends on the intended recovery time. More frequent snapshots lead to small reconstruction times for RWTempIndex but create many instances of RO-TempIndex all of which have to be searched for each query. While searching a few additional small in-memory indices is not the rate limiting step for answering the query (searching the large LTI is), creating too many could can lead to inefficient search. A typical set up for a billion-point index would hold up to 30M points in the TempIndex between merges to the LTI. Limiting each in-memory index to 5M points results in at 6.1 Experimental Setup Hardware. All experiments are run on one of two machines: e (mem-mc) — a 64-vcore E64d_v4 Azure virtual machine instance used to measure latencies and recall for inmemory indices and the FreshVamana update rules. e (ssd-mc) — a bare-metal server with 2x Xeon 8160 CPUs (48 cores, 96 threads) and a 3.2TB Samsung PM1725a PCle SSD to evaluate SSD-based indices and the overall FreshDiskANN system. We now study the complete FreshDiskANN system in a realistic scenario — maintaining a large scale billion-scale index on the ssd machine and serving thousands of inserts, deletes and searches per second concurrently over multiple days. For this experiment, we use the SIFT1B dataset, but limit the size of our indices to around 800M points, so that we have a sufficiently big spare pool of 200M points for insertions at all times. Our experiment can be divided into two phases: in the first phase, starting with a statically built index on a random 100M subset of SIFT1B, we define our update stream to comprise only of inserts until the total number of points in the index reaches around 800M points. We call this the ramp-up phase. We then transition into what we call a steady-state phase, where we update the index by deleting and inserting points at the same rate. We delete existing points and insert points from the spare pool of 200M points from the SIFT1B dataset. We then continue this for several days and observe the behaviour of the system in terms of latencies and recall. How fast can we feed inserts into the system in these phases, i.e., how many threads can we use to concurrently insert into the FreshDiskANN system? If we use too many threads for insertion, the TempIndex will reach the limit M of 30M points before the StreamingMerge process has completed. This would result in a backlog of inserts not consolidate to LT] on SSD. With the benefit of some prior experiments (of how long each cycle of the StreamingMerge takes), we arrive at the number of threads which concurrently feed inserts into the FreshDiskANN system in each of the phases and describe them below. Figure 5. Search latencies for Ls = 100 (always > 92% 5recall@5) over the course of ramping up an index to size 800M. Each point is mean latency over a 10000-query batch. Stage 2: Steady State. In the second stage of the experiment, we maintain an index size of around 800M while supporting a large number of equal inserts and deletes. Externally, 2 threads insert points into the index, 1 thread issues deletes, and 10 threads concurrently search it. Since the deletes happen near instantly, we added a sleep timer between the delete requests to ensure that the rate of deletions is similar to that of insertions. Note that we reduced the number of insert threads from 3 to 2 to slow down the insertion rate to accommodate the longer merge times compared to the ramp-up experiment — the StreamingMerge process now processes 30M deletes in addition to 30M inserts. We present userperceived latencies for search and insertions in Figure 6. think is likely due to head-of-line blocking by the large sequential read and write operations that copy the LTI index to and from the main memory. Update Throughput of System. While FreshDiskANN provides latencies of about 1ms for insert (Figure 6) and 0.1: for delete (since they are simply added to a DeleteList), in practice they need to be throttled so that the in-memory TempIndex do not grow too large before the ongoing background merge completes. As a result, the speed of the merge operation dictates the update rates the system can sustain over long periods of time. The threads allocation described above helps us control the rate of external insert and delete operations to what the StreamingMerge procedure can complete before the TempIndex grows to 30M points. To better understand the thread allocation, we record the time taken for the StreamingMerge process to merge 30M inserts into an index of size roughly 800M using T = 40 threads. This takes around 8400s per cycle. To prevent the TempIndex from growing too much while the merge procedure is running, we throttle the inserts to around 3500 inserts per second, so that the TempIndex accumulates under 30M newly inserted points in one merge cycle. Since the insertion latencies into in-memory FreshVamana indices is around 1ms (Figure 6), we allocated a total of 3 threads concurrently feeding into the system. This ensured that the system never backlogged throughout the ramp-up experiment. Trade-off of Varying Number of Merge Threads T. If we increase the merge threads T, the merges happen faster, which means we can ingest insertions and deletions into the system at a faster throughput (without the TempIndex size growing too large). On the other hand, if T is large, the SSDbandwidth used by the StreamingMerge process increases and this adversely affects the search throughput. We examine the merge times with varying threads in Figure 7 (left) and the search latencies when different numbers of threads are performing background merge in Figure 8. 70 30 1.6 PARAL @ 60 B95 ~ £ 50 & a 1.4} jth Ea > ZS fs 520 = th ——s0 & 40 3 g 1.27 5) £45 5 goth = 30 3 1} = = 19 Sipe] £ 20 9 3 § v 0. 8 = | HB 10 a» 1) eo 1 i 4 0 i | fi Ll Lo Lo 0.6 Ap nneteernne| 0 2-105 4-10° 6-10° 5,000 10,000 15,000 0 10 20 30 40 Time elapsed since start of experiment (seconds) Time since merge start (sec) #Batches Figure 6. Mean latency‘measurements for the week-long steady-state experiment with an 800M FreshDiskANN index The Cost of StreamingMerge. The StreamingMerge procedure with 40 threads takes around 16000 seconds to merge 30M inserts and deletes into a 800M point LTI (a 7.5% change), which is 8.5% of the ~ 190000 seconds it would take to rebuild the index from scratch with a similar thread-count. We conclude that the merge process is significantly more cost-effective than periodically rebuilding the indices, which is the current choice of system design for graph indices. Further, StreamingMerge scales near linearly with the number of threads (see Figure 7). While the Delete phase scales linearly, the Patch and Insert phases scale sub-linearly due to intensive SSD I/O. Using fewer threads also results in more predictable search latencies (esp. 99% latency) due to the reduced SSD contention. This allows us to set the number of threads StreamingMerge uses to meet the desired update rate — 3600 updates/sec require 40 threads, but if we were only required to support 1000 updates/sec, we could choose to run StreamingMerge with 10 threads, and take advantage of higher search throughput and predictable latencies. In this paper, we develop FreshVamana, the first graphbased fresh-ANNS algorithm capable of reflecting updates to an existing index using compute proportional to the size of updates, while ensuring the index quality is similar to one rebuilt from scratch on the updated dataset. Using update rules from FreshVamana, we design a novel two-pass StreamingMerge procedure which reflects these updates into an SSD-resident index with minimal write amplification. Using FreshVamana and StreamingMerge, we develop and rigorously evaluate FreshDiskANN, a highly-scalable freshANNS system that can maintain a dynamic index of a billion points on a commodity machine while concurrently supporting inserts, deletes, and search operations at millisecondscale latencies. Rakesh Agrawal, Christos Faloutsos, and Arun Swami. 1993. Efficient similarity search in sequence databases. In Foundations of Data Organization and Algorithms, David B. Lomet (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 69-84. Alexandr Andoni and Piotr Indyk. 2008. Near-optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions. Commun. ACM 51, 1 (Jan. 2008), 117-122. https://doi.org/10.1145/ 1327452.1327494 Alexandr Andoni and Ilya Razenshteyn. 2015. Optimal DataDependent Hashing for Approximate Near Neighbors. In Proceedings of the Forty-seventh Annual ACM Symposium on Theory of Computing (Portland, Oregon, USA) (STOC ’15). ACM, New York, NY, USA, 793-801. https://doi.org/10.1145/2746539.2746553 Akhil Arora, Sakshi Sinha, Piyush Kumar, and Arnab Bhattacharya. 2018. HD-Index: Pushing the Scalability-Accuracy Boundary for Approximate kNN Search in High-Dimensional Spaces. Proceedings of the VLDB Endowment 11 (04 2018). https://doi.org/10.14778/3204028. 3204034 Sunil Arya and David M. Mount. 1993. Approximate Nearest Neighbor Queries in Fixed Dimensions. In Proceedings of the Fourth Annual ACMSIAM Symposium on Discrete Algorithms (Austin, Texas, USA) (SODA ’93). Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 271-280. http://dl.acm.org/citation.cfm?id=313559.313768 Martin Aumiiller, Erik Bernhardsson, and Alexander Faithfull. 2020. ANN-Benchmarks: A benchmarking tool for approximate nearest neighbor algorithms. Information Systems 87 (2020). http://www. sciencedirect.com/science/article/pii/S03064379 18303685 A. Babenko and V. Lempitsky. 2012. The inverted multi-index. In 2012 IEEE Conference on Computer Vision and Pattern Recognition. 30693076. Alina Beygelzimer, Sham Kakade, and John Langford. 2006. Cover Trees for Nearest Neighbor. In Proceedings of the 23rd International Conference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML Alina Beygelzimer, Sham Kakade, and John Langford. 2006. Cover Trees for Nearest Neighbor. In Proceedings of the 23rd International Conference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML ’06). Association for Computing Machinery, New York, NY, USA, 97-104. https://doi.org/10.1145/1143844.1143857 Leonid Boytsov. [n.d.]._https://github.com/nmslib/nmslib/issues/73 A. Camerra, E. Keogh, T. Palpanas, and J. Shieh. 2010. iSAX 2.0: Indexing and Mining One Billion Time Series. In 2013 IEEE 13th International Conference on Data Mining. IEEE Computer Society, Los Alamitos, CA, USA, 58-67. https://doi.org/10.1109/ICDM.2010.124 Kenneth L. Clarkson. 1994. An Algorithm for Approximate Closestpoint Queries. In Proceedings of the Tenth Annual Symposium on Computational Geometry (Stony Brook, New York, USA) (SCG 94). ACM, New York, NY, USA, 160-164. https://doi.org/10.1145/177424.177609 Kunal Dahiya, Deepak Saini, Anshul Mittal, Ankush Shaw, Kushal Dave, Akshay Soni, Himanshu Jain, Sumeet Agarwal, and Manik Varma. 2021. DeepXML: A Deep Extreme Multi-Label Learning Framework Applied to Short Text Documents. In Proceedings of the 14th International Conference on Web Search and Data Mining (Jerusalem, Israel) (WSDM 21). Association for Computing Machinery, New York, NY, USA, 8. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. CoRR abs/1810.04805 (2018). arXiv:1810.04805 http://arxiv.org/abs/1810.04805 Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, and Houda Benbrahim. 2019. Return of the Lernaean Hydra: Experimental Evaluation of Data Series Approximate Similarity Search. Proc. VLDB Endow. 13, 3 (2019), 403-420. https://doi.org/10.14778/3368289.3368303 Evelyn Fix and J. L. Hodges. 1989. Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties. International Statistical Review / Revue Internationale de Statistique 57, 3 (1989), 238-247. http://www.jstor.org/stable/1403797 Cong Fu and Deng Cai. [n.d.]. https://github.com/ZJULearning/efanna Cong Fu, Chao Xiang, Changxu Wang, and Deng Cai. 2019. Fast Approximate Nearest Neighbor Search With The Navigating Spreadingout Graphs. PVLDB 12, 5 (2019), 461 474. https://doi.org/10.14778/ 3303753.3303754 Maurice Herlihy and Nir Shavit. 2012. The Art of Multiprocessor Programming, Revised Reprint (1st ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. Piotr Indyk and Rajeev Motwani. 1998. Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. In Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing (Dallas, Texas, USA) (STOC ’98). ACM, New York, NY, USA, 604-613. M Iwasaki. [n.d.]. _https://github.com/yahoojapan/NGT/wiki Masajiro Iwasaki and Daisuke Miyazaki. 2018. Optimization of Indexing Based on k-Nearest Neighbor Graph for Proximity Search in High-dimensional Data. Herve Jegou, Romain Tavenard, Matthijs Douze, and Laurent Amsaleg. 2011. Searching in one billion vectors: Re-rank with source coding. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2011, May 22-27, 2011, Prague Congress Center, Prague, Czech Republic. 861-864. https: //doi.org/10.1109/ICASSP.2011.5946540 Qing-Yuan Jiang and Wu-Jun Li. 2015. Scalable Graph Hashing with Feature Transformation. In Proceedings of the 24th International Conference on Artificial Intelligence (Buenos Aires, Argentina) (IJCAI’15). AAAI Press, 2248-2254. Header only C++/python library for fast approximate nearest neighbors. [n.d.]._ https://github.com/nmslib/hnswlib Yongjoo Park, Michael Cafarella, and Barzan Mozafari. 2015. NeighborSensitive Hashing. Proc. VLDB Endow. 9, 3 (Nov. 2015), 144-155. https: //doi.org/10.14778/2850583.2850589 Suhas Jayaram Subramanya, Fnu Dewvrit, Rohan Kadekodi, Ravishankar Krishnawamy, and Harsha Vardhan Simhadri. 2019. DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada, Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett (Eds.). 1374813758. _ http://papers.nips.cc/paper/9527-rand-nsg-fast-accuratebillionpoint-nearest-neighbor-search-on-a-single-node Mengzhao Wang, Xiaoliang Xu, Qiang Yue, and Yuxiang Wang. 2021. A Comprehensive Survey and Experimental Comparison of GraphBased Approximate Nearest Neighbor Search. CoRR abs/2101.12631 (2021). arXiv:2101.12631 https://arxiv.org/abs/2101.12631 Roger Weber, Hans-Jérg Schek, and Stephen Blott. 1998. A Quantitative Analysis and Performance Study for Similarity-Search Methods in High-Dimensional Spaces. In Proceedings of the 24rd International Conference on Very Large Data Bases (VLDB ’98). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 194-205. http: //dl.acm.org/citation.cfm?id=645924.671192 Figure 9. Search 5-recall@5 after each cycle of 12K insertions and 10K deletions to FreshVamana, ramping up from 100K to 1M points. Horizontal lines indicate recall of the corresponding batch built Vamana index. 100 — 100 9 | “49 ——= © 98 98 = 97 97 5 96 96 + 4 © 95 /7 95 | 94 |94 93 ! ! ! 93 ! ! 0 20 40 60 0 20 40 #cycles #cycles L60 L150 L 220 L55 L100 L200 Figure 10. Search recall FreshVamana on SIFT100M while (left) ramping up from 1 point; and (right) ramping up starting from 30M points, and steady-state after 45 cycles. Horizontal lines indicate recall of the Vamana index with the same build time. n Table 1 we compare the build time of Vamana and FreshVamana for the same build parameters. The trade-off for this speed-up comes in the form of increased search latency for the same k-recall@k. In Figure 11, we show that using FreshVamana to make updates to the index takes only a fraction of the time to rebuild it from scratch using Vamana. We show a similar comparison of DiskANN and FreshDiskANN in Table 2. Despite using more than double the resources, uilding a 800M index from scratch using DiskANN takes more than 7x the time that FreshDiskANN takes to reflect the same changes into the index. To determine the optimal value of a, we perform the FreshVamana steady-state experiments with different values of a. In the plots in Figure 3, we use the same value of a for 5This is true of any index a larger index over data from the same distribution will provide lower recall with the search parameter/complexity. Figure 11. Time taken to merge delete and re-insert of 5%, 10%, and 50% of index size into a FreshVamana index, expressed relative to index rebuild time for Vamana. building the intial Vamana index and for updating it. Other build and update parameters are same for each plot (R = 64, L = 75). We compare the evolution of search recall in the 95% range and average degree with different a. Finally we compare search recall versus latency for static indices built with different a to choose the best candidate. For all a > 1, average degree increases over the course of the experiments and recall stabilises around the initial value. For static indices, latency at the same recall value improves from 1 to 1.2 after which further increasing a shows now noticeable improvement as evidenced by recall-vs-latency plots for Vamana indices in Figure 13. Since we want to minimise the memory footprint of our index, we choose the a value with best search performance and lowest average degree, which in this case is 1.2. E.1.1 Search Latency vs Recall. In Figures 15 to 17, we compare the search latencies for Vamana and build timenormalized FreshVamana (build parameters adjusted to match the build time of Vamana) for various k-recall@k. For 1recall@1 and 10-recall@10, we compare latencies for 95%, 98% and 99% recall. For 100-recall@100, we compare over 98% and 99% recall because the lowest search list parameter L value gives 98% recall. E.1.2 Recall stability of FreshVamana. In Figure 18, we demonstrate k-recall@k stability of FreshVamana for commonly used k values. We show the post-insertion recall trends for 1-recall@1, 10-recall@10 and 100-recall@100. For k = 1, we show how the 95% and 99.9% recall are stable. For k = 10, we show that 95% and 99% recall are stable. For k = 100, the lowest valid search list parameter L value is 100 and this gives 98% recall. So we show the stability of 98% and 99% recall. E.2.1 Search latencies over one merge cycle. In ? ?? ?, we present the evolution of mean search latency for 100recall@100 and 10-recall@10 over the course of one merge cycle in a 800M FreshDiskANN steady-state experiment. Figure 15. Query latency for Vamana and build-time normalized FreshVamana 1-recall@1 at 95%, 98%, and 99%. Figure 16. Query latency for Vamana and build-time normalized FreshVamana 10-recall@10 at 95%, 98%, and 99%. Figure 17. Query latency for Vamana and build-time normalized FreshVamana 100-recall@100 at 98%, and 99%. Figure 18. Post-insertion search k-recall@k for k = 1, 10, 100 of FreshVamana index over 50 cycles of deletion and re-insertion of 5%, 10% and 50% (rows 1, 2 and 3 respectively) of SIFT1M index with varying search list size parameter L. We run the merge on SIFT800M index with different thread allocations to understand the effect of merge on search latency. In Figure 8, we plot a smoothed curve of mean search latencies when merge uses 20 and 40 threads. Merge with 40 threads takes approximately half the time as that with 20, so there are two x axes adjusted to roughly align their Delete, Insert and Patch phases. As evident from the figure, search',\n",
              " 'hnsw': 'Constantly growing amount of the available information resources has led to high demand in scalable and efficient similarity search data structures. One of the generally used approaches for information search is the K-Nearest Neighbor Search (K-NNS). The K-NNS assumes you have a defined distance function between the data elements and aims at finding the K elements from the dataset which minimize the distance to a given query. Such algorithms are used in many applications, such as non-parametric machine learning algorithms, image features matching in large scale databases  and semantic document retrieval . A naive approach to K-NNS is to compute the distances between the query and every element in the dataset and select the elements with minimal distance. Unfortunately, the complexity of the naive approach scales linearly with the number of stored elements making it infeasible for large-scale datasets. This has led to a high interest in development of fast and scalable KNNS algorithms. Exact solutions for K-NNS [3-5] may offer a substantial search speedup only in case of relatively low dimensional data due to “curse of dimensionality”. To overcome this problem a concept of Approximate Nearest Neighbors Search (K-ANNS) was proposed, which relaxes the condition of the exact search by allowing a small number of errors. The quality of an inexact search (the recall) is defined as the ratio between the number of found true nearest neighbors and K. The most popular K-ANNS solutions are based on approximated versions of tree algorithms , locality-sensitive hashing (LSH)  and product quantization (PQ) [10-17]. Proximity graph KANNS algorithms [10, 18-26] have recently gained popularity offering a better performance on high dimensional datasets. However, the power-law scaling of the proximity graph routing causes extreme performance degradation in case of low dimensional or clustered data. In this paper we propose the Hierarchical Navigable Small World (Hierarchical NSW, HNSW), a new fully graph based incremental K-ANNS structure, which can offer a much better logarithmic complexity scaling. The main contributions are: explicit selection of the graph’s enter-point node, separation of links by different scales and use of an advanced heuristic to select the neighbors. Alternatively, Hierarchical NSW algorithm can be seen as an extension of the probabilistic skip list structure  with proximity graphs instead of the linked lists. Performance evaluation has demonstrated that the proposed general metric space method is able to strongly outperform previous opensource state-of-the-art approaches suitable only for vector spaces. In the vast majority of studied graph algorithms searching takes a form of greedy routing in k-Nearest Neighbor (k-NN) graphs [10, 18-26]. For a given proximity graph, we start the search at some enter point (it can be random or supplied by a separate algorithm) and iteratively traverse the graph. At each step of the traversal the algorithm examines the distances from a query to the neighbors of a current base node and then selects as the next base node the adjacent node that minimizes the distance, while constantly keeping track of the best discovered neighbors. The search is terminated when some stopping condition is met (e.g. the number of distance calculations). Links to the closest neighbors in a k-NN graph serve as a simple approximation of the Delaunay graph  (a graph which guranties that the result of a basic greedy graph traversal is always the nearest neighbor). Unfortunately, Delaunay graph cannot be efficiently constructed without prior information about the structure of a space , but its approximation by the nearest neighbors can be done by using only distances between the stored elements. It was shown that proximity graph approaches with such approximation perform competitive to other k-ANNS thechniques, such as kd-trees or LSH [18-26]. In  authors proposed a proximity graph K-ANNS algorithm called Navigable Small World (NSW, also known as Metricized Small World, MSW), which utilized navigable graphs, i.e. graphs with logarithmic or olylogarithmic scaling of the number of hops during the greedy traversal with the respect of the network size . The NSW graph is constructed via consecutive insertion of elements in random order by bidirectionally connecting them to the M closest neighbors from the reviously inserted elements. The closest neighbors are ound using the structure’s search procedure (a variant of a greedy search from multiple random enter nodes). Links to the closest neighbors of the elements inserted in the beginning of the construction later become bridges between the network hubs that keep the overall graph connectivity and allow the logarithmic scaling of the number of hops during greedy routing. Construction phase of the NSW structure can be efficiently parallelized without global synchronization and without mesuarable effect on accuracy , being a good choice for distributed search systems. The NSW approach delivered the state-of-the-art performance on some datasets , however, due to the overall polylogarithmic complexity scaling, the algorithm was still prone to severe performance degradation on low dimensional datasets (on which NSW could lose to tree-based algorithms by several orders of magnitude ). Networks with logarithmic or polylogarithmic scaling of the greedy graph routing are known as the navigable small world networks . Such networks are an important topic of complex network theory aiming at understanding of underlying mechanisms of real-life networks formation in order to apply them for applications of scalable routing  and distributed similarity search [25, 26, 30, 37-40]. The first works to consider spatial models of navigable networks were done by J. Kleinberg  as social network models for the famous Milgram experiment . Kleinberg studied a variant of random Watts-Strogatz networks , using a regular lattice graph in ddimensional vector space together with augmentation of long-range links following a specific long link length distribution r*. For a=d the number of hops to get to the target by greedy routing scales polylogarithmically (instead of a power law for any other value of a). This idea has inspired development of many K-NNS and K-ANNS algorithms based on the navigation effect [37-40]. But even though the Kleinberg’s navigability criterion in principle can be extended for more general spaces, in order to build such a navigable network one has to know the data distribution beforehand. In addition, greedy routing in Kleinberg’s graphs suffers from polylogarithmic complexity scalability at best. Another well-known class of navigable networks are the scale-free models , which can reproduce several features of real-life networks and advertised for routing applications . However, networks produced by such models have even worse power law complexity scaling of the greedy search  and, just like the Kleinberg’s model, scale-free models require global knowledge of the data distribution, making them unusable for search applications. The above-described NSW algorithm uses a simpler, reviously unknown model of navigable networks, alowing decentralized graph construction and suitable for data in arbitrary spaces. It was suggested  that the NSW network formation mechanism may be responsible or navigability of large-scale biological neural networks (presence of which is disputable): similar models were able to describe growth of small brain networks, while the model predicts several high-level features observed in arge scale neural networks. However, the NSW model also suffers from the polylogarithmic search complexity of the routing process. from a low degree node and traverses the graph simultaneously increasing the node’s degree until the characteristic radius of the node links length reaches the scale of the distance to the query. Before the latter happens, the average degree of a node can stay relatively small, which leads to an increased probability of being stuck in a distant false local minimum. One can avoid the described problem in NSW by starting the search from a node with the maximum degree (good candidates are the first nodes inserted in the NSW structure ), directly going to the “zoom-in” phase of the search. Tests show that setting hubs as starting points substantially increases probability of successful routing in the structure and provides significantly better performance at low dimensional data. However, it still has only a polylogarithmic complexity scalability of a single greedy search at best, and performs worse on high dimensional data compared to Hierarchical NSW. The reason for the polylogarithmic complexity scaling of a single greedy search in NSW is that the overall number of distance computations is roughly proportional to a product of the average number of greedy algorithm hops by the average degree of the nodes on the greedy path. The average number of hops scales logarithmically , while the average degree of the nodes on the greedy path also scales logarithmically due to the facts that: 1) the greedy search tends to go through the same hubs as the network grows ; 2) the average number of hub connections grows logarithmically with an increase of the network size. Thus we get an overall polylogarithmic dependence of the resulting complexity. The idea of Hierarchical NSW algorithm is to separate the links according to their length scale into different layers and then search in a multilayer graph. In this case we can evaluate only a needed fixed portion of the connections for each element independently of the networks size, thus allowing a logarithmic scalability. In such structure the search starts from the upper layer which has only the longest links (the “zoom-in” phase). The algorithm greedily traverses through the elements from the upper layer until a local minimum is reached (see Fig. 1 for illustration). After that, the search switches to the lower layer (which has shorter links), restarts from the element which was the local minimum in the previous layer and the process repeats. The maximum number of connections per element in all layers can be made constant, thus allowing a logarithmic complexity scaling of routing in a navigable small world network. One way to form such a layered structure is to explicitly set links with different length scales by introducing layers. For every element we select an integer level / which defines the maximum layer for which the element belongs to. For all elements in a layer a proximity graph (i.e. graph containing only “short” links that approximate Delaunay graph) is built incrementally. If we set an exponentially decaying probability of / (i.e. following a geometric distribution) we get a logarithmic scaling of the expected number of layers in the structure. The search procedure is an iterative greedy search starting from the top layer and finishing at the zero layer. In case we merge connections from all layers, the structure becomes similar to the NSW graph (in this case the / can be put in correspondence to the node degree in NSW). In contrast to NSW, Hierarchical NSW construction algorithm does not require the elements to be shuffled before the insertion the stochasticity is achieved by using level randomization, thus allowing truly incremental indexing even in case of temporarily alterating data distribution (though changing the order of the insertion slightly alters the performace due to only partially determenistic construction procedure). Fig. 2. Illustration of the heuristic used to select the graph neighbors for two isolated clusters. A new element is inserted on the boundary of Cluster 1. All of the closest neighbors of the element belong to the Cluster 1, thus missing the edges of Delaunay graph between the clusters. The heuristic, however, selects element e2 from Cluster 2, thus, maintaining the global connectivity in case the inserted element is the closest to ez compared to any other element from Cluster 1. For the selection of the proximity graph connections during the element insertion we utilize a heuristic that takes into account the distances between the candidate elements to create diverse connections (a similar algorithm was utilized in the spatial approximation tree  to select the tree children) instead of just selecting the closest neighbors. The heuristic examines the candidates starting from the nearest (with respect to the inserted element) and creates a connection to a candidate only if it is closer to the base (inserted) element compared to any of the already connected candidates (see Section 4 for the details). When the number of candidates is large enough the heuristic allows getting the exact relative neighborhood graph  as a subgraph, a minimal subgraph of the Delaunay graph deducible by using only the distances between the nodes. The relative neighborhood graph allows easily keeping the global connected component, even in case of highly clustered data (see Fig. 2 for illustration). Note that the heuristic creates extra edges compared to the exact relative neighborhood graphs, allowing controlling the number of the connections which is important for search performance. For the case of 1D data the heuristic allows getting the exact Delaunay subgraph (which in this case coincides with the relative neighborhood graph) by using only information about the distances between the elements, thus making a direct transition from Hierarchical NSW to the 1D probabilistic skip list algorithm. Base variant of the Hierarchical NSW _ proximity graphs was also used in ref.  (called ‘sparse neighborhood graphs’) for proximity graph searching. Similar heuristic was also a focus of the FANNG algorithm  Input: multilayer graph hnsw, new element q, number of established connections M, maximum number of connections for each element per layer Mmax, size of the dynamic candidate list efConstruction, normalization factor for level generation mi Network construction algorithm (alg. 1) is organized via consecutive insertions of the stored elements into the graph structure. For every inserted element an integer maximum layer / is randomly selected with an exponentially decaying probability distribution (normalized by the m, parameter, see line 4 in alg. 1). The first phase of the insertion process starts from the top layer by greedily traversing the graph in order to find the ef closest neighbors to the inserted element gq in the layer. After that, the algorithm continues the search from the next layer using the found closest neighbors from the previous layer as enter points, and the process repeats. Closest neighbors at each layer are found by a variant of the greedy search algorithm described in alg. 2, which is an updated version of the algorithm from . To obtain the approximate ef nearest neighbors in some layer 1, a dynamic list W of ef closest found elements (initially filled with enter points) is kept during the search. The list is updated at each step by evaluating the neighborhood of the closest previously non-evaluated element in the list until the neighborhood of every element from the list is evaluated. Compared to limiting the number of distance calculations, Hierarchical NSW stop condition has an advantage it allows discarding candidates for evalution that are further from the query than the furthest element in the list, thus avoiding bloating of search structures. As in NSW, the list is emulated via two priority queues for better performance. The distinctions from NSW (along with some queue optimizations) are: 1) the enter point is a fixed parameter; 2) instead of changing the number of multi-searches, the quality of the search is controlled by a different parameter ef (which was set to K in NSW ). Input: query element q, enter points ep, number of nearest to q elements to return ef, layer number Ic During the first phase of the search the efparameter is set to 1 (simple greedy search) to avoid introduction of additional parameters. Two methods for the selection of Mneighbors from the candidates were considered: simple connection to the closest elements (alg. 3) and the heuristic that accounts for the distances between the candidate elements to create connections in diverse directions (alg. 4), described in the Section 3. The heuristic has two additional parameters: extendCandidates (set to false by default) which extends the candidate set and useful only for extremely clustered data, and keepPrunedConnections which allows getting fixed number of connection per element. The maximum number of connections that an element can have per layer is defined by the parameter M,,,, for every layer higher than zero (a special parameter M,,.9 is used for the ground layer separately). If a node is already full at the moment of making of a new connection, then its extended connection list gets shrunk by the same algorithm that used for the neighbors selection (algs. 3 or 4). The insertion procedure terminates when the connections of the inserted elements are established on the zero layer. The K-ANNS search algorithm used in Hierarchical NSW is presented in alg. 5. It is roughly equivalent to the insertion algorithm for an item with layer 40. The difference is that the closest neighbors found at the ground layer which are used as candidates for the connections are now returned as the search result. Algorithm 4 SELECT-NEIGHBORS-HEURISTIC(q, C, M, Ic, extendCandidates, keepPrunedConnections) Input: base element q, candidate elements C, number of neighbors to return M, layer number I:, flag indicating whether or not to extend candidate list extendCandidates, flag indicating whether or not to add discarded elements keepPrunedConnections Output: M elements selected by the heuristic 1R<@ 2 W<C // working queue for the candidates 3 if extendCandidates // extend candidates by their neighbors 4 foreacheeC 5 for each eas € neighbourhood(e) at layer lc 6 if eaaj € W 7 W<—WUeaaj 8 Wi<@ // queue for the discarded candidates 9 while |W| >0and |R|<M 10 e<extract nearest element from W to q 11 if eis closer to q compared to any element from R 12 R-RUe 13 else 144. Wie WiUe 15 if keepPrunedConnections // add some of the discarded // connections from Wa 16 while |W:|>Oand |R|<M 17. RR U extract nearest element from Wa to q 18 return R Algorithm construction parameters m, and M,,,,9 are responsible for maintaining the small world navigability in the constructed graphs. Setting m, to zero (this corresponds to a single layer in the graph) and M,,,.9 to M leads to production of directed k-NN graphs with a power-law search complexity well studied before  (assuming using the alg. 3 for neighbor selection). Setting m, to zero and M,,,,9 to infinity leads to production of NSW graphs with polylogarithmic complexity . Finally, setting m, to some non-zero value leads to emergence of controllable hierarchy graphs which allow logarithmic search complexity by introduction of layers (see the Section 3). To achieve the optimum performance advantage of the controllable hierarchy, the overlap between neighbors on different layers (i.e. percent of element neighbors that are also belong to other layers) has to be small. In order to decrease the overlap we need to decrease the m,. However, at the same time, decreasing m, leads to an increase of average hop number during a greedy search on each layer, which negatively affects the performance. This leads to existence of the optimal value for the m, parameter. A simple choice for the optimal m, is 1/In(W), this corresponds to the skip list parameter p=1/M with an average single element overlap between the layers. Simulations done on an Intel Core i7 5930K CPU show that the proposed selection of m, is a reasonable choice (see Fig. 3 for data on 10M random d=4 vectors). In addition, the plot demonstrates a massive speedup on low dimensional data when increasing the m, from zero and the effect of using the heuristic for selection of the graph connections. It is hard to expect the same behavior for high dimensional data since in this case the k-NN graph already has Fig. 3. Plots for query time vs m. parameter for 10M random vectors with d=4. The autoselected value 1/In(M) for m, is shown by very short greedy algorithm paths . Surprisingly, increasing the m, from zero leads to a measurable increase in speed on very high dimensional data (100k dense random d=1024 vectors, see plot in Fig. 4), and does not introduce any penalty for the Hierarchical NSW approach. For real data such as SIFT vectors  (which have complex mixed structure), the performance improvement by increasing the m, is higher, but less prominent at current settings compared to improvement from the heuristic (see Fig. 5 for 1-NN search performance on 5 million 128dimensional SIFT vectors from the learning set of BIGANN ). Selection of the M,,,,) (the maximum number of connections that an element can have in the zero layer) also has a strong influence on the search performance, especially in case of high quality (high recall) search. Simulations show that setting M,,,,9 to (this corresponds to kNN graphs on each layer if the neighbors selection heuristic is not used) leads to a very strong performance penalty at high recall. Simulations also suggest that 2.:Mis a good choice for M,,.¢ setting the parameter higher leads to performance degradation and excessive memory usage. In Fig. 6 there are presented results of search performance for the 5M SIFT learn dataset depending on the M,,,,9 parameter (done on an Intel Core i5 2400 CPU). The suggested value gives performance close to optimal at different recalls. Fig. 4. Plots for query time vs m. parameter for 100k random vectors with d=1024. The autoselected value 1/In(M) for m, is naive connection to the nearest neighbors (alg. 3). The effect is the most prominent for low dimensional data, at high recall for mid-dimensional data and for the case of highly clustered data (ideologically discontinuity can be regarded as a local low dimensional feature), see the omparison in Fig. 7 (Core i5 2400 CPU). When using the osest neighbors as connections for the proximity graph, the Hierarchical NSW algorithm fails to achieve a high recall for clustered data because the search stucks at the clusters boundaries. Contrary, when the heuristic is used (together with candidates’ extension, line 3 in Alg. 4), clustering leads to even higher performance. For uniform and very high dimensional data there is a little difference between the neighbors selecting methods (see Fig. 4), possibly due to the fact that in this case almost all of the nearest neighbors are selected by the heuristic. The only meaningful construction parameter left for the user is M. A reasonable range of M is from 5 to 48. Simulations show that smaller M generally produces better results for lower recalls and/or lower dimensional data, while bigger Mis better for high recall and/or high dimensional data (see Fig. 8 for illustration, Core i5 2400 CPU). The parameter also defines the memory consumption of the algorithm (which is proportional to M), so it should be selected with care. Selection of the efConstruction parameter is straightforward. As it was suggested in  it has to be large enough to produce K-ANNS recall close to unity during the construction process (0.95 is enough for the most usecases). And just like in , this parameter can possibly Fig. 6. Plots for query time vs Mmnaxo parameter for 5M SIFT learn dataset. The autoselected value 2-M for Mmaxo is shown by an arrow. Fig. 7. Effect of the method of neighbor selections (baseline corresponds to alg. 3, heuristic to alg. 4) on clustered (100 random isolated clusters) and non-clustered d=10 random vector data. Fig. 8. Plots for recall error vs query time for different parameters of M for Hierarchical NSW on 5M SIFT learn dataset. Build time, minutes Fig. 10. Plots of the query time vs construction time tradeoff for Hierarchical NSW on The construction process can be easily and efficiently parallelized with only few synchronization points (as demonstrated in Fig. 9) and no measurable effect on index quality. Construction speed/index quality tradeoff is controlled via the efConstruction parameter. The tradeoff between the search time and the index construction time is presented in Fig. 10 for a 10M SIFT dataset and shows that a reasonable quality index can be constructed for efConstruction=100 on a 4X 2.4 GHz 10-core Xeon E54650 v2 CPU server in just 3 minutes. Further increase of the efConstruction leads to little extra performance but in exchange of significantly longer construction time. The complexity scaling of a single search can be strictly analyzed under the assumption that we build exact Delaunay graphs instead of the approximate ones. Suppose we have found the closest element on some layer (this is guaranteed by having the Delaunay graph) and then descended to the next layer. One can show that the average number of steps before we find the closest element in the layer is bounded by a constant. Indeed, the layers are not correlated with the spatial positions of the data elements and, thus, when we traverse the graph there is a fixed probability p=exp(-m,) that the next node belongs to the upper layer. However, the search on the layer always terminates before it reaches the element which belongs to the higher layer (otherwise the search on the upper layer would have stopped on a different element), so the probability of not reaching the target on s-th step is bounded by exp(-s:m,). Thus the expected number of steps in a layer is bounded by a sum of geometric progression S=1/(1-exp(-m,)), which is independent of the dataset size. If we assume that the average degree of a node in the Delaunay graph is capped by a constant C in the limit of the large dataset (this is the case for random Euclid data , but can be in principle violated in exotic spaces), then the overall average number of distance evaluations in a layer is bounded by a constant C: S, independently of the dataset size. by the construction scales as O(log()), the overall complexity scaling is O(log()), in agreement with the simulations on low dimensional datasets. The inital assumption of having the exact Delaunay graph violates in Hierarchical NSW due to usage of approximate edge selection heuristic with a fixed number of neighbors per element. Thus, to avoid stucking into a local minimum the greedy search algorithm employs a backtracking procedure on the zero layer. Simulations show that at least for low dimensional data (Fig. 11, d=4) the dependence of the required ef parameter (which determines the complexity via the minimal number of hops during the backtracking) to get a fixed recall saturates with the rise of the dataset size. The backtracking complexity is an additive term in respect to the final complexity, thus, as follows from the empirical data, inaccuracies of the Delaunay graph approximation do not alter the scaling. Such empirical investigation of the Delaunay graph approximation resilience requires having the average number of Delaunay graph edges independent of the dataset to evidence how well the edges are approximated with a constant number of connections in Hierarchical NSW. However, the average degree of Delaunay graph scales exponentially with the dimensionality ), thus for high dimensional data (e.g. d=128) the aforementioned condition requires having extremely large datasets, making such empricial investigation unfeasible. Further analitical evidence is required to confirm whether the resilience of Delaunay graph aproximations generalizes to higher dimensional spaces. 4.2.2 Construction complexity The construction is done by iterative insertions of all elements, while the insertion of an element is merely a sequence of K-ANN-searches at different layers with a subsequent use of heuristic (which has fixed complexity at fixed efConstruction). The average number of layers for an element to be added in is a constant that depends on m: The memory consumption of the Hierarchical NSW is mostly defined by the storage of graph connections. The number of connections per element is M,,,,9 for the zero layer and M,,,, for all other layers. Thus, the average memory consumption per element is (Maxot Mm, -M,,,,)-bytes_per_link. If we limit the maximum total number of elements by approximately four billions, we can use four-byte unsigned integers to store the connections. Tests suggest that typical close to optimal WM values usually lie in a range between 6 and 48. This means that the typical memory requirements for the index (excluding the size of the data) are about 60-450 bytes per object, which is in a good agreement with the simulations. The Hierarchical NSW algorithm was implemented in C++ on top of the Non Metric Space Library (nmslib) \\', which already had a functional NSW implementation (under name “sw-graph”). Due to several limitations posed by the library, to achieve a better performance, the Hierarchical NSW implementation uses custom distance functions together with C-style memory management, which avoids unnecessary implicit addressing and allows efficient hardware and software prefetching during the graph traversal. Comparing the performance of K-ANNS algorithms is a nontrivial task since the state-of-the-art is constantly changing as new algorithms and implementations are emerging. In this work we concentrated on comparison with the best algorithms in Euclid spaces that have open source implementations. An implementation of the Hierarchical NSW algorithm presented in this paper is also distributed as a part of the open source nmslib library’ together with an external C++ memory-efficient headeronly version with support for incremental index construction’. The comparison section consists of four parts: comparison to the baseline NSW (5.1), comparison to the state-ofthe-art algorithms in Euclid spaces (5.2), rerun of the sub- set of tests  in general metric spaces in which NSW failed (5.3) and comparison to state-of-the-art PQalgorithms on a large 200M SIFT dataset (5.4). For the baseline NSW algorithm implementation, we used the “sw-graph” from nmslib 1.1 (which is slightly updated compared to the implementation tested in ) to demonstrate the improvements in speed and algorithmic complexity (measured by the number of distance computations). Fig. 12(a) presents a comparison of Hierarchical NSW to the basic NSW algorithm for d=4 random hypercube data made on a Core i5 2400 CPU (10-NN search). Hierarchical NSW uses much less distance computations during a search on the dataset, especially at high recalls. The scalings of the algorithms on a d=8 random hypercube dataset for a 10-NN search with a fixed recall of 0.95 are presented in Fig. 12(b). It clearly demostrates that Hierarchical NSW has a complexity scaling for this setting not worse than logarithmic and outperforms NSW at any dataset size. The performance advantage in absolute time (Fig. 12(c)) is even higher due to improved algorithm implementaion. 5.2 Comparison in Euclid spaces The main part of the comparison was carried out on vector datasets with use of the popular K-ANNS benchmark ann-benchmark’ as a testbed. The testing system utilizes python bindings of the algorithms — it consequentially runs the K-ANN search for one thousand queries (randomly extracted from the initial dataset) with preset algorithm parameters producing an output containing recall and average time of a single search. The considered algorithms are: 1. Baseline NSW “sw-graph’). 2. FLANN 1.8.4 . A popular library‘ containing several algorithms, built-in in OpenCV>. We used the available auto-tuning procedure with several reruns to infer the best parameters. 3. Annoy®, 02.02.2016 build. A popular algorithm Fig. 12. Comparison between NSW and Hierarchical NSW: (a) distance calculation number vs accuracy tradeoff for a 10 million 4dimensional random vectors dataset; (b-c) performance scaling in terms of number of distance calculations (b) and raw query(c) time on nmslib 1.1. 5. FALCONN,, version 1.2. A new efficient LSH algorithm for cosine similarity data . The comparison was done on a 4X Xeon E5-4650 v2 Debian OS system with 128 Gb of RAM. For every algorithm we carefully chose the best results at every recall range to evaluate the best possible performance (with initial values from the testbed defaults). All tests were done in a single thread regime. Hierarchical NSW was compiled using the GCC 5.3 with -Ofast optimization flag. A recent comparison of algorithms  in general spaces (i.e. non-symmetric or with violation of triangle inequality) showed that the baseline NSW algorithm has severe problems on low dimensional datasets. To test the performance of the Hierarchical NSW algorithm we have repeated a subset of tests from  on which NSW performed poorly or suboptimal. For that purpose we used a built-in nmslib testing system which had scripts to run tests from . The evaluated algorithms included the VP-tree, permutation techniques (NAPP and bruteforce filtering) [49, 55-57], the basic NSW algorithm and NNDescent-produced proximity graphs  (both in pair with the NSW graph search algorithm). As in the original tests, for every dataset the test includes the results of ei- memory management were used in this case for Hierarchical NSW leading to some performance loss. The datasets are summarized in Table 2. Further details of the datasets, spaces and algorithm parameter selection can be found in the original work . The bruteorce (BF) time is measured by the nmslib library. The results are presented in Fig. 14. Hierarchical NSW significantly improves the performance of NSW and is a leader for any of the tested datasets. The strongest enhancement over NSW, almost by 3 orders of magnitude is observed for the dataset with the lowest dimensionality, the wiki-8 with JS-divergence. This is an important result that demonstrates the robustness of Hierarchical NSW, as or the original NSW this dataset was a stumbling block. Note that for the wiki-8 to nullify the effect of implementation results are presented for the distance computations number instead of the CPU time. against PQ algorithms we used the facebook Faiss library® as the baseline (a new library with state-of-the-art PQ algorithms  implementations, released after the current manuscript was submitted) compiled with the OpenBLAS backend. The tests where done for a 200M subset of 1B SIFT dataset  on a 4X Xeon E5-4650 v2 server with 128Gb of RAM. The ann-benchmark testbed was not feasible for these experiments because of its reliance on 32-bit floating point format (requiring more than 100 Gb just to store the data). To get the results for Faiss PQ algorithms we have utilized built-in scripts with the parameters from Faiss wiki’. For the Hierarchical NSW algorithm we used a special build outside of the nmslib with a small memory footprint, simple non-vectorized The results are presented in Fig. 15 with summarization of the parameters in Table 3. The peak memory consumption was measured by using linux “time —v” tool in separate test runs after index construction for both of the algorithms. Even though Hierarchical NSW requires significantly more RAM, it can achieve much higher accuracy, while offering a massive advance in search speed and much faster index construction. By using structure decomposition of navigable small world graphs together with the smart neighbor selection heuristic the proposed Hierarchical NSW approach overcomes several important problems of the basic NSW structure advancing the state-of-the-art in K-ANN search. Hierarchical NSW offers an excellent performance and is a clear leader on a large variety of the datasets, surpassing the opensource rivals by a large margin in case of high dimensional data. Even for the datasets where the previous algorithm (NSW) has lost by orders of magnitude, Hierarchical NSW was able to come first. Hierarchical NSW supports continuous incremental indexing and can also be used as an efficient method for getting approximations of the k-NN and relative neighborhood graphs, which are byproducts of the index construction. Robustness of the approach is a strong feature which makes it very attractive for practical applications. The algorithm is applicable in generalized metric spaces performing the best on any of the datasets tested in this paper, and thus eliminating the need for complicated selection of the best algorithm for a specific problem. We stress the importance of the algorithm’s robustness since the data may have a complex structure with different effective dimensionality across the scales. For instance, a dataset can consist of points lying on a curve that randomly fills a high dimensional cube, thus being high dimensional at large scale and low dimensional at small scale. In order to perform efficient search in such datasets an approximate nearest neighbor algorithm has to work well for both cases of high and low dimensionality. There are several ways to further increase the efficiency and applicability of the Hierarchical NSW approach. There is still one meaningful parameter left which strongly affects the construction of the index — the number of added connections per layer M. Potentially, this parameter can be inferred directly by using different heuristics . It would also be interesting to compare Hierarchical NSW on the full 1B SIFT and 1B DEEP datasets [10-14] and add support for element updates and removal. proach compared to the basic NSW is the loss of the possibility of distributed search. The search in the Hierarchical NSW structure always starts from the top layer, thus the structure cannot be made distributed by using the same techniques as described in  due to cognestion of the higher layer elements. Simple workarounds can be used to distribute the structure, such as partitioning the data across cluster nodes studied in , however in this case, the total parallel throughput of the system does not scale well with the number of computer nodes. Still, there are other possible known ways to make this particular structure distributed. Hierarchical NSW is idelogically very similar to the well-known oneimensional exact search probabilistic skip list structure, nd thus can use the same techniques to make the strucure distributed . Potentially this can lead to even beter distributed performance compared to the base NSW ue to logarithmic scalability and ideally uniform load on e nodes. 4] G. Navarro, \"Searching in metric spaces by spatial approximation,\" The VLDB Journal, vol. 11, no. 1, pp. 28-46, 2002. 6] M. Muja and D. G. Lowe, \"Scalable nearest neighbor algorithms for high dimensional data,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 36, no. 11, pp. 2227-2240, 2014. 7] M.E. Houle and M. Nett, \"Rank-based similarity search: Reducing the dimensional dependence,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 37, no. 1, pp. 136-150, 2015. J. Wang, J. Wang, G. Zeng, R. Gan, S. Li, and B. Guo, \"Fast neighborhood graph search using cartesian concatenation,” in Multimedia Data Mining and Analytics: Springer, 2015, pp. 397417. A. Babenko and V. Lempitsky, \"The inverted multi-index,\" in Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Con‘ference on, 2012, pp. 3069-3076: IEEE. H. Jegou, M. Douze, and C. Schmid, \"Product quantization for nearest neighbor search,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 33, no. 1, pp. 117-128, 2011. A. Babenko and V. Lempitsky, \"Efficient indexing of billionscale datasets of deep descriptors,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 2055-2063. Y. Kalantidis and Y. Avrithis, \"Locally optimized product quantization for approximate nearest neighbor search,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 2321-2328. S. Arya and D. M. Mount, \"Approximate Nearest Neighbor Queries in Fixed Dimensions,\" in SODA, 1993, vol. 93, pp. 271280. J. Wang and S. Li, \"Query-driven iterated neighborhood graph search for large scale indexing,\" in Proceedings of the 20th ACM international conference on Multimedia, 2012, pp. 179-188: ACM. Z. Jiang, L. Xie, X. Deng, W. Xu, and J. Wang, \"Fast Nearest Neighbor Search in the Hamming Space,\" in MultiMedia Modeling, 2016, pp. 325-336: Springer. E. Chavez and E. S. Tellez, \"Navigating k-nearest neighbor graphs to solve nearest neighbor searches,\" in Advances in Pattern Recognition: Springer, 2010, pp. 270-280. K. Aoyama, K. Saito, H. Sawada, and N. Ueda, \"Fast approximate similarity search based on degree-reduced neighborhood. graphs,\" in Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, 2011, pp. 10551063: ACM. G. Ruiz, E. Chavez, M. Graff, and E. S. Téllez, \"Finding Near Neighbors Through Local Search,\" in Similarity Search and Applications: Springer, 2015, pp. 103-109. Y. Malkov, A. Ponomarenko, A. Logvinov, and V. Krylov, \"Scalable distributed algorithm for approximate nearest neighbor search problem in high dimensional general metric spaces,\" in Similarity Search and Applications: Springer Berlin Heidelberg, 2012, pp. 132-147. Y. Malkov, A. Ponomarenko, A. Logvinov, and V. Krylov, \"Approximate nearest neighbor algorithm based on navigable small world graphs,\" Information Systems, vol. 45, pp. 61-68, 2014. W. Dong, C. Moses, and K. Li, \"Efficient k-nearest neighbor graph construction for generic similarity measures,\" in Proceedings of the 20th international conference on World wide web, 2011, pp. 577-586: ACM. A. Ponomarenko, Y. Malkov, A. Logvinov, and V. Krylov, \"Approximate Nearest Neighbor Search Small World Approach,” in International Conference on Information and Communication Technologies & Applications, Orlando, Florida, USA, 2011. M. Boguna, D. Krioukov, and K. C. Claffy, \"Navigability of complex networks,\" Nature Physics, vol. 5, no. 1, pp. 74-80, 2009. A. Ponomarenko, N. Avrelin, B. Naidan, and L. Boytsov, \"Comparative Analysis of Data Structures for Approximate Nearest Neighbor Search,\" In Proceedings of The Third International Conference on Data Analytics, 2014. B. Naidan, L. Boytsov, and E. Nyberg, \"Permutation search methods are efficient, yet faster search is possible,\" VLDB Procedings, vol. 8, no. 12, pp. 1618-1629, 2015. Y. Lifshits and S. Zhang, \"Combinatorial algorithms for nearest neighbors, near-duplicates and small-world design,\" in Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms, 2009, pp. 318-326: Society for Industrial and Applied Mathematics. O. Beaumont, A.-M. Kermarrec, and E. Riviere, \"Peer to peer multidimensional overlays: Approximating complex structures,\" in Principles of Distributed Systems: Springer, 2007, pp. 315-328. O. Beaumont, A.-M. Kermarrec, L. Marchal, and E. Riviére, \"VoroNet: A scalable object network based on Voronoi tessellations,\" in Parallel and Distributed Processing Symposium, 2007. IPDPS 2007. IEEE International, 2007, pp. 1-10: IEEE. J. Kleinberg, \"The small-world phenomenon: An algorithmic perspective,\" in Proceedings of the thirty-second annual ACM symposium on Theory of computing, 2000, pp. 163-170: ACM. D. J. Watts and S. H. Strogatz, \"Collective dynamics of ‘smallworld’networks,\" Nature, vol. 393, no. 6684, pp. 440-442, 1998. Y. A. Malkov and A. Ponomarenko, \"Growing homophilic networks are natural navigable small worlds,\" PloS one, p. e0158162, 2016. M. T. Goodrich, M. J. Nelson, and J. Z. Sun, \"The rainbow skip graph: a fault-tolerant constant-degree distributed data structure,\" in Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm, 2006, pp. 384-393: Society for Industrial and Applied Mathematics. E. C. Gonzalez, K. Figueroa, and G. Navarro, \"Effective proximity retrieval by ordering permutations,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 30, no. 9, pp. 1647-1658, 2008. E. S. Tellez, E. Chavez, and G. Navarro, \"Succinct nearest neighbor search,” Information Systems, vol. 38, no. 7, pp. 10191030, 2013. C. Beecks, \"Distance-based similarity models for content-based multimedia _retrieval,\". Hochschulbibliothek der RheinischWestfalischen Technischen Hochschule Aachen, 2013. author of 20+ papers on physics and computer science. Yury currently occupies a position of a Project Leader in Samsung Al Center in Moscow. His current research interests include deep learning, scalable similarity search, biological and Dmitry A. Yashunin received a Master\\'s degree in physics from Nizhny Novgorod State University in 2009, and a PhD degree in laser physics from the Institute of Applied Physics RAS in 2015. From 2008 to 2012 he was working in Mera Networks. He is author of 10+ papers on physics. Dmitry currently woks at Intelli-Vision in the posi-',\n",
              " 'ivfpq': 'Article in IEEE Transactions on Pattern Analysis and Machine Intelligence January 2011 Abstract— This paper introduces a product quantization based approach for approximate nearest neighbor search. The idea is to decomposes the space into a Cartesian product of low dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices. The Euclidean distance between two vectors can be efficiently estimated from their codes. An asymmetric version increases precision, as it computes the approximate distance between a vector and a code. Experimental results show that our approach searches for nearest neighbors efficiently, in particular in combination with an inverted file system. Results for SIFT and GIST image descriptors show excellent search accuracy outperforming three state-of-the-art approaches. The scalability of our approach is validated on a dataset of two billion vectors. Index Terms— High-dimensional indexing, image indexing, very large databases, approximate search. Computing Euclidean distances between high dimensional vectors is a fundamental requirement in many applications. It is used, in particular, for nearest neighbor (NN) search. Nearest neighbor search is inherently expensive due to the curse of dimensionality , . Focusing on the D-dimensional Euclidean space R?, the problem is to find the element NN(z), in a finite set Y C R® of n vectors, minimizing the distance to the query vector « € R? : Several multi-dimensional indexing methods, such as the popular KD-tree  or other branch and bound techniques, have been proposed to reduce the search time. However, for high dimensions it turns out  that such approaches are not more efficient than the bruteforce exhaustive distance calculation, whose complexity is O(nD). There is a large body of literature , ,  on algorithms that overcome this issue by performing approximate nearest neighbor (ANN) search. The key idea This work was partly realized as part of the Quaero Programme, funded by OSEO, French State agency for innovation. It was originally published as a technical report  in August 2009. It is also related to the work  on source coding for nearest neighbor search. shared by these algorithms is to find the NN with high probability “only”, instead of probability 1. Most of the effort has been devoted to the Euclidean distance, though recent generalizations have been proposed for other metrics . In this paper, we consider the Euclidean distance, which is relevant for many applications. In this case, one of the most popular ANN algorithms is the Euclidean Locality-Sensitive Hashing (E2LSH) , , which provides theoretical guarantees on the search quality with limited assumptions. It has been successfully used for local descriptors  and 3D object indexing , . However, for real data, LSH is outperformed by heuristic methods, which exploit the distribution of the vectors. These methods include randomized KD-trees  and hierarchical k-means , both of which are implemented in the FLANN selection algorithm . ANN algorithms are typically compared based on the trade-off between search quality and efficiency. However, this trade-off does not take into account the memory requirements of the indexing structure. In the case of E2LSH, the memory usage may even be higher than that of the original vectors. Moreover, both E2LSH and FLANN need to perform a final re-ranking step based on exact L2 distances, which requires the indexed vectors to be stored in main memory if access speed is important. This constraint seriously limits the number of vectors that can be handled by these algorithms. Only recently, researchers came up with methods limiting the memory usage. This is a key criterion for problems involving large amounts of data , ie., in large-scale scene recognition , where millions to billions of images have to be indexed. In , Torralba et al. represent an image by a single global GIST descriptor  which is mapped to a short binary code. When no supervision is used, this mapping is learned such that the neighborhood in the embedded space defined by the Hamming distance reflects the neighborhood in the Euclidean space of the original features. The search of the Euclidean nearest neighbors is then approximated by the search of the nearest neighbors in terms of Hamming distances between codes. In , spectral hashing (SH) is shown to outperform the binary codes generated by the restricted Boltzmann machine , boosting and LSH. In this paper, we construct short codes using quantization. The goal is to estimate distances using vectorto-centroid distances, i.e., the query vector is not quantized, codes are assigned to the database vectors only. This reduces the quantization noise and subsequently improves the search quality. To obtain precise distances, the quantization error must be limited. Therefore, the total number k of centroids should be sufficiently large, eg. k= 2%4 for 64-bit codes. This raises several issues on how to learn the codebook and assign a vector. First, the number of samples required to learn the quantizer is huge, i.e., several times k. Second, the complexity of the algorithm itself is prohibitive. Finally, the amount of computer memory available on Earth is not sufficient to store the floating point values representing the centroids. The hierarchical k-means see (HKM) improves the efficiency of the learning stage and of the corresponding assignment procedure . However, the aforementioned limitations still apply, in particular with respect to memory usage and size of the learning set. Another possibility are scalar quantizers, but they offer poor quantization error properties in terms of the trade-off between memory and reconstruction error. Lattice quantizers offer better quantization properties for uniform vector distributions, but this condition is rarely satisfied by real world vectors. In practice, these quantizers perform significantly worse than k-means in indexing tasks . In this paper, we focus on product quantizers. To our knowledge, such a semi-structured quantizer has never been considered in any nearest neighbor search method. The advantages of our method are twofold. First, the number of possible distances is significantly higher than for competing Hamming embedding methods , , , as the Hamming space used in these techniques allows for a few distinct distances only. Second, as a byproduct of the method, we get an estimation of the expected squared distance, which is required for e-radius search or for using Lowe’s distance ratio criterion . The motivation of using the Hamming space in , ,  is to compute distances efficiently. Note, however, that one of the fastest ways to compute Hamming distances consists in using table lookups. Our method uses a similar number of table lookups, resulting in comparable efficiency. Our paper is organized as follows. Section II introduces the notations for quantization as well as the product quantizer used by our method. Section III presents our approach for NN search and Section IV introduces the structure used to avoid exhaustive search. An evaluation of the parameters of our approach and a comparison with the state of the art is given in Section V. Quantization is a destructive process which has been extensively studied in information theory . Its purpose is to reduce the cardinality of the representation space, in particular when the input data is real-valued. Formally, a quantizer is a function g mapping a Ddimensional vector « € R? to a vector q(x) € C = {ci;i © Z}, where the index set Z is from now on assumed to be finite: Z = 0... — 1. The reproduction values c; are called centroids. The set of reproduction values C is the codebook of size k. The Lloyd quantizer, which corresponds to the kmeans clustering algorithm, finds a near-optimal codebook by iteratively assigning the vectors of a training set to centroids and re-estimating these centroids from the assigned vectors. In the following, we assume that the two Lloyd conditions hold, as we learn the quantizer using k-means. Note, however, that k-means does only find a local optimum in terms of quantization error. cae) =— [ daaa)) rade. i Sy, Note that the MSE can be obtained from these quantities as MSE(q) = )> pi €(;¢)1) ieL The memory cost of storing the index value, without any further processing (entropy coding), is [log, k] bits. Therefore, it is convenient to use a power of two for k, as the code produced by the quantizer is stored in a binary memory. the SIFT descriptor . A quantizer producing 64bits codes, i.e., “only” 0.5 bit per component, contains Storing the codebook C explicitly is not efficient. Instead, we store the m x k* centroids of all the subquantizers, i.e., mD* k* = k* D floating points values. Quantizing an element requires k*D floating point operations. Table I summarizes the resource requirements associated with k-means, HKM and product k-means. The product quantizer is clearly the the only one that can be indexed in memory for large values of k. In order to provide good quantization properties when choosing a constant value of k*, each subvector should have, on average, a comparable energy. One way to ensure this property is to multiply the vector by a random orthogonal matrix prior to quantization. However, for most vector types this is not required and not recommended, as consecutive components are often correlated by construction and are better quantized together with the same subquantizer. As the subspaces are orthogonal, the squared distortion associated with the product quantizer is where MSE(q;) is the distortion associated with quantizer q;. Figure 1 shows the MSE as a function of the code length for different (m,k*) tuples, where the code length is 1 = mlog,k*, if k* is a power of two. The curves are obtained for a set of 128-dimensional SIFT descriptors, see section V for details. One can observe that for a fixed number of bits, it is better to use a small number of subquantizers with many centroids than having many subquantizers with few bits. At the extreme when m = 1, the product quantizer becomes a regular k-means codebook. 0.3 T T T m=1 —+— m=2 ---x--0.25 + m=4 --o-J m=8 --4 i= m=16 ---&-OG 02 4 < fe} 2 3 0.15 4 3 2 S$ O17 4 B 0.05 + aoe 4 > a . 1 y 0 16 32 64 96 128 160 Fig. 2. Illustration of the symmetric and asymmetric distance computation. The distance d(x, y) is estimated with either the distance d(q(x),q(y)) (left) or the distance d(x,q(y)) (right). The mean squared error on the distance is on average bounded by the quantization error. Nearest neighbor search depends on the distances between the query vector and the database vectors, or equivalently the squared distances. The method introduced in this section compares the vectors based on their quantization indices, in the spirit of source coding techniques. We first explain how the product quantizer properties are used to compute the distances. Then we provide a statistical bound on the distance estimation error, and propose a refined estimator for the squared Euclidean distance. Symmetric distance computation (SDC): both the vectors x and y are represented by their respective centroids q(x) and q(y). The distance d(x, y) is approximated by the distance d(x, y) * d(q(x),q(y)) which is efficiently obtained using a product quantizer As shown later in this subsection, using the estimations d or d leads to underestimate, on average, the distance between descriptors. Figure 3 shows the distances obtained when querying a SIFT descriptor in a dataset of 1000 SIFT vectors. It compares the true distance against the estimates computed with Equations 12 and 13. One can clearly see the bias on these distance estimators. Unsurprisingly, the symmetric version is more sensitive to this bias. Discussion: Figure 4 illustrates the probability distribution function of the difference between the true distance and the ones estimated by Equations 13 and 25. It has been measured on a large set of SIFT descriptors. The bias of the distance estimation by Equation 13 is significantly reduced in the corrected version. However, we observe that correcting the bias leads, in this case, to a higher variance of the estimator, which is a common phenomenon in statistics. Moreover, for the nearest neighbors, the correcting term is likely to be higher 0 Ts. L -0.3 -0.2 -0.1 0 0.1 0.2 0.3 difference: estimator d(x,y) In our experiments, we observe that the correction returns inferior results on average. Therefore, we advocate the use of Equation 13 for the nearest neighbor search. The corrected version is useful only if we are interested in the distances themselves. Approximate nearest neighbor search with product quantizers is fast (only m additions are required per distance calculation) and reduces significantly the memory requirements for storing the descriptors. Nevertheless, the search is exhaustive. The method remains scalable in the context of a global image description , . However, if each image is described by a set of local descriptors, an exhaustive search is prohibitive, as we need to index billions of descriptors and to perform multiple queries . To avoid exhaustive search we combine an inverted file system  with the asymmetric distance computation (IVFADC). An inverted file quantizes the descriptors and stores image indices in the corresponding lists, see the step “coarse quantizer” in Figure 5. This allows rapid access to a small fraction of image indices and was shown successful for very large scale search . Instead of storing an image index only, we add a small code for each descriptor, as first done in . Here, we encode the difference between the vector and its Similar to the “Video-Google” approach , a codebook is learned using k-means, producing a quantizer qc, referred to as the coarse quantizer in the following. For SIFT descriptors, the number k’ of centroids associated with gq typically ranges from k’ = 1000 to k’ = 1000 000. It is therefore small compared to that of the product quantizers used in Section III. G > ac(y) + aly — aely))9) Denoting by 9p; the 7\" subquantizer, we use the following decomposition to compute this estimator efficiently: ; G1) Similar to the ADC strategy, for each subquantizer pj the distances between the partial residual vector uj (a qe(y)) and all the centroids c;,; of Gp, are preliminarily computed and stored. address this problem, we use the multiple assignment strategy of . The query x is assigned to w indexes instead of only one, which correspond to the w nearest neighbors of x in the codebook of qc. All the corresponding inverted lists are scanned. Multiple assignment is not applied to database vectors, as this would increase the memory usage. 4) add a new entry to the inverted list corresponding to g-(y). It contains the vector (or image) identifier and the binary code (the product quantizer’s indexes). Searching the nearest neighbor(s) of a query x consists of 1) quantize x to its w nearest neighbors in the codebook q; with these w assignments. The two steps are applied to all w assignments. 4) select the K nearest neighbors of x based on the estimated distances. This is implemented efficiently by maintaining a Maxheap structure of fixed capacity, that stores the AK smallest values seen so far. After each distance calculation, the point identifier is added to the structure only if its distance is below the largest distance in the Maxheap. Only Step 3 depends on the database size. Compared with ADC, the additional step of quantizing x to g-(x) consists in computing k’ distances between Ddimensional vectors. Assuming that the inverted lists are balanced, about n x w/k’ entries have to be parsed. Therefore, the search is significantly faster than ADC, as shown in the next section. In this section, we first present the datasets used for the evaluation’. We then analyze the impact of the parameters for SDC, ADC and IVFADC. Our approach is compared to three state-of-the-art methods: spectral hashing , Hamming embedding  and FLANN . Finally, we evaluate the complexity and speed of our approach. The search quality is measured with recall@ R, ie., the proportion of query vectors for which the nearest neighbor is ranked in the first R positions. This measure indicates the fraction of queries for which the nearest neighbor is retrieved correctly, if a short-list of R vectors is verified using Euclidean distances. Furthermore, the curve obtained by varying R corresponds to the distribution function of the ranks, and the point R=1 corresponds to the “precision” measure used in  to evaluate ANN methods. As expected, the asymmetric estimator ADC significantly outperforms SDC. For m=8 we obtain the same accuracy for ADC and k*=64 as for SDC and k*=256. Given that the efficiency of the two approaches is equivalent, we advocate not to quantize the query when possible, but only the database elements. 1 ; — 0.8 + 6 4 S o6F xo 4 5 bid 8 o4b x JKet6 | i¢ 1! m=1 —+— O2x! no J fs m=16 —--— 0 \\\\ L L L n 0 16 32 64 96 128 160 code length (bits) Fig. 6. SDC and ADC estimators evaluated on the SIFT dataset: recall@100 as a function of the memory usage (code length=m x log, k*) for different parameters (k*=16,64,256,...,4096 and m=1,2,4,8,16). The missing point (m=16,k*=4096) gives recall@100=1 for both SDC and ADC. 0.20 L 1 L 0 16 32 64 96 128 code length (bits) This approach is significantly more efficient than SDC and ADC on large datasets, as it only compares the query to a small fraction of the database vectors. The proportion of the dataset to visit is roughly linear in w/k’. For a fixed proportion, it is worth using higher values of k’, as this increases the accuracy, as shown by comparing, for the tuple (m,w), the parameters (1024, 1) against (8192, 8) and (1024, 8) against (8192, 64). The natural order corresponds to grouping consecutive components, as proposed in Equation 8. For the SIFT descriptor, this means that histograms of neighboring grid cells are quantized together. GIST descriptors are composed of three 320-dimension blocks, one per color channel. The product quantizer splits these blocks into parts. The “structured” order consists in grouping together dimensions that are related. For the m = 4 SIFT quantizer, this means that the 4x 4 patch cells that make up the descriptor  are grouped into 4 2 x 2 blocks. For the other two, it groups together dimensions that have have the same index modulo 8. The orientation histograms of SIFT and most of GIST’s have 8 bins, so this ordering quantizes together bins corresponding to the same orientation. On SIFT descriptors, this is a slightly less efficient structure, probably because the natural order corresponds to spatially related components. On GIST, this choice significantly improves the performance. Therefore, we use this ordering in the following experiments. Discussion: A method that automatically groups the components could further improve the results. This seems particularly important if we have no prior knowledge about the relationship between the components as in the case of bag-of-features. A possible solution is the minimum sum-squared residue co-clustering  algorithm. Comparison with Hamming embedding methods: We compare our approach to spectral hashing (SH) , which maps vectors to binary signatures. The search consists in comparing the Hamming distances between the database signatures and the query vector signature. This approach was shown to outperform the restricted Boltzmann machine of . We have used the publicly available code. We also compare to the Hamming embedding (HE) method of , which also maps vectors to binary signatures. Similar to IVFADC, HE uses an inverted file, which avoids comparing to all the database elements. . — —— oor = 0.8 4 xc 06 5 © @ § 2 04 sDC —— 4 ADC ---x--IVFADC w=1 ° 0.2 IVFADC w=16 ~~ J . HE w=1 ---&-HE w=16 . 0 f j f spectral hashing, 1 10 100 1k 10k 100k 1M R Fig. 8. | SIFT dataset: recall@R for varying values of R. Com- 1 === 0.8 4 c 06 4 g g 2 04 4 sDC —— ADC ---x--02 IVFADC w=1 ---0--. IVFADC w=8 © IVFADC w=64 ---&-0 ke spectral hashing ate, aieeal 1 10 100 1k 10k 100k 1M Fig. 9. GIST dataset: recall@R for varying values of R. Comparison of the different approaches SDC, ADC, IVFADC and spectral hashing . We have used m=8, k*=256 for SDC/ADC and k’ = 1024 for IVFADC. Comparison with FLANN: The approximate nearestneighbor search technique of Muja & Lowe  is based on hierarchical structures (KD-trees and hierarchical kmeans trees). The software package FLANN automatically selects the best algorithm and parameters for a given dataset. In contrast with our method and spectral hashing, all vectors need to remain in RAM as the method includes a re-ranking stage that computes the real distances for the candidate nearest neighbors. For the sake of comparison with FLANN, we added a verification stage to our IVFADC method: IVFADC queries return a shortlist of R candidate nearest neighbors using the distance estimation. The vectors in the shortlist are re-ordered using the real distance, as done in , , and the closest one is returned. Note that, in this experimental setup, all the vectors are stored in main memory. This requirement seriously limits the scale on which re-ordering can be used. The IVFADC and FLANN methods are both evaluated at different operating points with respect to precision and search time. For FLANN, the different operating points are obtained with parameters generated automatically for various target precisions. For IVFADC, they are obtained by varying the number k’ of coarse centroids, the number w of assignments and the short-list size R. The product quantizer is generated using k*=256 and m=8, ie., 64bit codes. This choice is probably not optimal for all operating points. Table V reports the search time of our methods. For reference, we report the results obtained with the spectral hashing algorithm of  on the same dataset and machine (using only one core). Since we use a separate learning set, we use the out-of-sample evaluation of this algorithm. Note that for SH we have reimplemented the Hamming distance computation in C 100 F FLANN ‘ \"74 IVFADC, R=10— + IVFADC, R=100 x IVFADC, R=1000—* 16/128 % > 16/1024] cS 16/128 o £ a 16/1024 = 10f eo * 2 ——— 4/128 oO 3 4/1024 +4/1024 1 L 1 1 L 1 1 L 06 #065 O7 O75 O08 085 09 0.95 1 1-recall at 1 Fig. 10. IVFADC vs FLANN: trade-offs between search quality To evaluate the search efficiency of the product quantizer method on larger datasets we extracted about 2 billion SIFT descriptors from one million images. Search is performed with 30000 query descriptors from ten images. We compared the IVFADC and HE methods with similar parameters. In particular, the amount of memory that is scanned for each method and the cost of the coarse quantization are the same. The query times per descriptor are shown on Figure 11. The cost of the extra quantization step required by IVFADC appears clearly for small database sizes. For larger scales, the distance computation with the database vectors become preponderant. The processing that is applied to each element of the inverted lists is 3.5 T 0.8 T T HE —+— x IVF+HE 64 bits —+ 3 IVFADC ---x--f 0.754 IVFADC 64 bits (m=8) ---<--] _ r é 7 . IVF+HE 32 bits ---*--5 IVFADC 32 bits (m=4) 5 So 25h 4 Orr 8 . s 0.65 ey | & os E 15> q E S 0.55 o If 4 nw 0.5 i 0.5 | 0.45 + 7 0 : 0.4 : ; 10M 100M 1G 1k 10k 100k 1M database size database size (number of images) Fig. 11. Search times for SIFT descriptors in datasets of increasing Fig. 12. Comparison of IVFADC and the Hamming Embedding We have evaluated our method within an image search system based on local descriptors. For this evaluation, we compare our method with the HE method of  on the INRIA Holidays dataset, using the pre-processed set of descriptors available online. The comparison is focused on large scale indexing, i.e., we do not consider the impact of a post-verification step ,  or geometrical We have introduced product quantization for approximate nearest neighbor search. Our compact coding scheme provides an accurate approximation of the Euclidean distance. Moreover, it is combined with an inverted file system to avoid exhaustive search, resulting in high efficiency. Our approach significantly outperforms the state of the art in terms of the trade-off between search quality and memory usage. Experimental results for SIFT and GIST image descriptors are excellent and show that grouping the components based on our prior knowledge of the descriptor design further improves the results. The scalability of our approach is validated on a dataset of two billion vectors. H. Jégou, M. Douze, and C. Schmid, “Searching with quantization: approximate nearest neighbor search using short codes and distance estimators,” Tech. Rep. RR-7020, INRIA, August 2009. C. Béhm, S. Berchtold, and D. Keim, “Searching in highdimensional spaces: Index structures for improving the performance of multimedia databases,” ACM Computing Surveys, vol. 33, pp. 322-373, October 2001. J. Friedman, J. L. Bentley, and R. A. Finkel, “An algorithm for finding best matches in logarithmic expected time,” ACM Transaction on Mathematical Software, vol. 3, no. 3, pp. 209226, 1977. R. Weber, H.-J. Schek, and S. Blott, “A quantitative analysis and performance study for similarity-search methods in highdimensional spaces,” in Proceedings of the International Conference on Very Large DataBases, pp. 194-205, 1998. M. Datar, N. Immorlica, P. Indyk, and V. Mirrokni, “Localitysensitive hashing scheme based on p-stable distributions,” in Proceedings of the Symposium on Computational Geometry, pp. 253-262, 2004. B. Kulis and K. Grauman, “Kernelized locality-sensitive hashing for scalable image search,” in Proceedings of the International Conference on Computer Vision, October 2009. Y. Ke, R. Sukthankar, and L. Huston, “Efficient near-duplicate detection and sub-image retrieval,” in ACM International conference on Multimedia, pp. 869-876, 2004. B. Matei, Y. Shan, H. Sawhney, Y. Tan, R. Kumar, D. Huber, and M. Hebert, “Rapid object indexing using locality sensitive hashing and joint 3D-signature space estimation,’ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, pp. 1111 — 1126, July 2006. C. Silpa-Anan and R. Hartley, “Optimized kd-trees for fast image descriptor matching,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2008. D. Nistér and H. Stewénius, “Scalable recognition with a vocabulary tree,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2161-2168, 2006. A. Torralba, R. Fergus, and W. T. Freeman, “80 million tiny images: a large database for non-parametric object and scene recognition,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, pp. 1958-1970, November 2008. A. Torralba, R. Fergus, and Y. Weiss, “Small codes and large databases for recognition,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2008. D. Lowe, “Distinctive image features from scale-invariant keypoints,” International Journal of Computer Vision, vol. 60, no. 2, pp. 91-110, 2004. R. M. Gray and D. L. Neuhoff, “Quantization,” IEEE Transactions on Information Theory, vol. 44, pp. 2325-2384, Oct. 1998. H. Jégou, H. Harzallah, and C. Schmid, “A contextual dissimilarity measure for accurate and efficient image search,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2007. H. Cho, I. Dhillon, Y. Guan, and S. Sra, “Minimum sumsquared residue co-clustering of gene expression data,” in SIAM International Conference on Data Mining, pp. 114-125, April 2004. J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman, “Object retrieval with large vocabularies and fast spatial matching,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2007.'}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partitioned_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63780cff-5390-41a4-b53d-81772bcb800f",
      "metadata": {
        "id": "63780cff-5390-41a4-b53d-81772bcb800f"
      },
      "outputs": [],
      "source": [
        "# Let's save our cleaned files to a new variable that makes more sense w/the current state\n",
        "\n",
        "cleaned_files = partitioned_files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36bc4e5e-aa4d-42bc-9bb3-d47bb46a1a1e",
      "metadata": {
        "id": "36bc4e5e-aa4d-42bc-9bb3-d47bb46a1a1e"
      },
      "source": [
        "# Chunking our PDF content\n",
        "\n",
        "Chunking is integral to achieving great relevance with vector search, whether that's sparse vector search, dense vector search, or hybrid vector search.\n",
        "\n",
        "From our [chunking strategy post](https://www.pinecone.io/learn/chunking-strategies/):\n",
        "\n",
        "> The main reason for chunking is to ensure we’re embedding a piece of content with as little noise as possible that is still semantically relevant . . . For example, in semantic search, we index a corpus of documents, with each document containing valuable information on a specific topic. By applying an effective chunking strategy, we can ensure our search results accurately capture the essence of the user’s query. If our chunks are too small or too large, it may lead to imprecise search results or missed opportunities to surface relevant content. As a rule of thumb, if the chunk of text makes sense without the surrounding context to a human, it will make sense to the language model as well. Therefore, finding the optimal chunk size for the documents in the corpus is crucial to ensuring that the search results are accurate and relevant.\n",
        "\n",
        "We need to chunk our PDFs' (text) data into sizable chunks that are semantically coherent and dense with contextual information.\n",
        "\n",
        "We'll use LangChain's `RecusiveCharacterTextSplitter` since it's a super easy utility that makes chunking quick and customizable. You should experiment with different chunk sizes and overlap values to see how the resulting chunks differ. You want each chunk to make a reasonable amount of sense as a stand-alone data object. After some experimentation on our end, we will choose a `chunk_size` of `512` and a `chunk_overlap` of `35` (characters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b8f24e-0052-41e7-9a23-8db8a6e829bb",
      "metadata": {
        "id": "d1b8f24e-0052-41e7-9a23-8db8a6e829bb"
      },
      "outputs": [],
      "source": [
        "def generate_chunks(doc: str, chunk_size: int = 512, chunk_overlap: int = 35) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Generate chunks of a certain size and token overlap.\n",
        "\n",
        "    :param doc: Document we want to turn into chunks.\n",
        "    :param chunk_size: Desired size of our chunks, in tokens (words).\n",
        "    :param chunk_overlap: Desired # of tokens (words) that will overlap across chunks.\n",
        "\n",
        "    :return: Chunks representations of the given document.\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size = chunk_size,\n",
        "        chunk_overlap = chunk_overlap\n",
        "    )\n",
        "\n",
        "    return splitter.create_documents([doc])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "667392aa-ba7b-4f3a-8fb9-2b63e6066b95",
      "metadata": {
        "id": "667392aa-ba7b-4f3a-8fb9-2b63e6066b95"
      },
      "outputs": [],
      "source": [
        "def chunk_documents(docs: Dict[str, List[Text]],  chunk_size: int = 512, chunk_overlap: int = 35) -> None:\n",
        "    \"\"\"\n",
        "    Iterate over documents and chunk each one.\n",
        "\n",
        "    :parameter docs: The documents we want to chunk.\n",
        "    :param chunk_size: Desired size of our chunks, in tokens (words).\n",
        "    :param chunk_overlap: Desired # of tokens (words) that will overlap across chunks.\n",
        "    \"\"\"\n",
        "    for key, value in docs.items():\n",
        "        chunks = generate_chunks(value)\n",
        "        docs[key] = [c.page_content for c in chunks]  # Grab the text representation of the chunks via the `page_content` attribute\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a912cf2-4e14-47c5-a074-bcfd983056d9",
      "metadata": {
        "id": "1a912cf2-4e14-47c5-a074-bcfd983056d9"
      },
      "outputs": [],
      "source": [
        "chunk_documents(cleaned_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94320c93-1993-40ee-850e-687a71fe3da4",
      "metadata": {
        "id": "94320c93-1993-40ee-850e-687a71fe3da4"
      },
      "outputs": [],
      "source": [
        "chunked_files = cleaned_files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c646c92-3c4e-401a-a6e7-0481501ada96",
      "metadata": {
        "id": "5c646c92-3c4e-401a-a6e7-0481501ada96"
      },
      "source": [
        "Check out our chunks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ceb3744-e564-472d-a800-e50ee355681a",
      "metadata": {
        "id": "8ceb3744-e564-472d-a800-e50ee355681a",
        "outputId": "0c18d740-10ae-459b-af64-06c6aee5983f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'freshdisk': ['Approximate nearest neighbor search (ANNS) is a fundamental building block in information retrieval with graphbased indices being the current state-of-the-art  and widely used in the industry. Recent advances  in graph-based indices have made it possible to index and search billion-point datasets with high recall and millisecond-level latency on a single commodity machine with an SSD. In this paper, we present the first graph-based ANNS index that reflects corpus updates into the index in real-time without',\n",
              "  'the index in real-time without compromising on search performance. Using update tules for this index, we design FreshDiskANN, a system that can index over a billion points on a workstation with an SSD and limited memory, and support thousands of concurrent real-time inserts, deletes and searches per second each, while retaining > 95% 5-recall@5. This represents a 5-10x reduction in the cost of maintaining freshness in indices when compared to existing methods. In the Nearest Neighbor Search problem, we are',\n",
              "  'Neighbor Search problem, we are given a dataset P of points along with a pairwise distance function. The goal is to design a data structure that, given a target k and a query point q, efficiently retrieves the k closest neighbors for q in the dataset P according to the given distance function. This fundamental problem is well studied in the research community  and is a critical component for diverse applications in computer vision , data mining , information retrieval , classification , and recommendation',\n",
              "  ', and recommendation systems , to name a few. As advances in deep learning have made embeddingbased approaches the state-of-the-art in these applications, there has been renewed interest in the problem at scale. Several open-source inverted-index based search engines now support NNS , and new search engines based on Since it is impossible to retrieve the exact nearest neighbors without a cost linear in the size of the dataset in the general case (see ) due to a phenomenon known as the curse of',\n",
              "  'a phenomenon known as the curse of dimensionality , one aims to find the approximate nearest neighbors (ANN) where the goal is to retrieve k neighbors that are close to being optimal. The quality of an ANN algorithm is judged by the trade-off it provides between accuracy and the hardware resources such as compute, memory and I/O consumed for the search. Even though this abstraction of ANN search is widely studied, it does not capture many important real-world scenarios where user interactions with a system',\n",
              "  'user interactions with a system creates and destroys data, and results in updates to P (especially in the literature on graph-based ANNS indices ). For example, consider an enterprise-search scenario where the system indexes sentences in documents generated by users across an enterprise. Changes to sentences in a document would correspond to a set of new points inserted and previous points deleted. Another scenario is an email server where arrival and deletion of emails correspond to insertion and deletion',\n",
              "  'to insertion and deletion of points into an ANNS index. ANNS systems for such applications would need to host indices containing trillions of points with real-time updates that can reflect changes to the corpus in user searches, ideally in real-time. Motivated by such scenarios, we are interested in solving the fresh-ANNS problem, where the goal is to support ANNS on a continually changing set of points. Formally, we define the fresh-ANNS problem thus: given a time varying dataset P (with state P; at time',\n",
              "  'dataset P (with state P; at time t), the goal is to maintain a dynamic index that computes the approximate nearest neighbors for any query q issued at time t only on the active dataset P;. Such a system must support three operations (a) insert a new point, (b) delete an existing point, and (c) search for the nearest neighbors given a query point. The overall quality of a fresh-ANNS system is measured by: Goal. Motivated by real-world scenarios, we seek to build the most cost-effective system for the',\n",
              "  'most cost-effective system for the fresh-ANNS problem which can maintain a billion-point index using commodity machines with 128GB RAM and a 2TB SSD? and support thousands of real-time inserts and deletes per second, and also thousands of searches per second with high accuracy of 95+% 5-recall@5. Indeed, the current state-of-art system for fresh-ANNS which can support comparable update and search performance on a billion-point dataset is based on the classical LSH algorithm , and requires a hundred',\n",
              "  'algorithm , and requires a hundred machines of 32GB RAM (translating to around 25 machines of our stated configuration). In this work, we seek to reduce this deployment cost down to a single machine per billion points. To handle trillion-point indices (as in web-search scenarios), one can employ a simple distributed approach wherein thousand machines host a billion points each — queries are broadcast and results aggregates while updates are routed to the appropriate nodes. Of all the algorithms for',\n",
              "  'nodes. Of all the algorithms for static-ANNS, the ones most easily capable of supporting streaming support are the ones based on simple hashing algorithms such as LSH (locality sensitive hashing). However, these algorithms suffer from either being too memory intensive, needing to store hundreds of hash functions in main memory, or become extremely slow for query processing when the index is stored on secondary storage. For example, the state-of-art system for streaming similarity search (or fresh-ANNS),',\n",
              "  'similarity search (or fresh-ANNS), PLSH , is a parallel and distributed LSH-based mechanism. While it offers comparable update throughput and search performance as our system, it ends up needing 25X more machines due to the high RAM consumption. A similar issue can be seen with PM-LSH, another state-of-art system based on LSH , where the memory footprint is a bit lower than PLSH (due to the system using fewer LSH tables), but the query latencies are an order of magnitude slower than our system and PLSH.',\n",
              "  'slower than our system and PLSH. Alternately, disk-based LSH indices such as SRS  can host a billion-point index on a single machine, but the query latencies are extremely slow with the system fetching around 15% of the total index (running into GBs per query) from the disk to provide good accuracy. Another recent algorithm HD-Index  can serve a billion-point index with just a few megabytes of RAM footprint, but it suffers from search latencies of a few seconds to get accuracy of around 30%. Moreover, the',\n",
              "  'of around 30%. Moreover, the algorithm only handles insertions, and simply performs a variant of blacklisting for deletions, and hence would need periodic rebuilding. Finally, there are other classes of ANNS algorithms such as kd-Tree , Cover Trees  which support reasonably efficient update policies, but these algorithms work well only when the data dimensionality is moderately small (under 20); their performance drops when the data dimensionality is 100 or more which is typical for points generated by',\n",
              "  'is typical for points generated by deep-learning models.. At the other end of the spectrum of ANNS indices are graph-based indexing algorithms . Several comparative studies  of ANNS algorithms have concluded that they significantly out-perform other techniques in terms of search throughput on a range of realworld static datasets. These algorithms are also widely used in the industry at scale. However, all known graph indices are static and do not support updates, especially delete requests , possibly due',\n",
              "  'delete requests , possibly due to the fact that simple graph modification rules for insertions and deletions do not retain the same graph quality over a stream of insertions and deletions. As a result, the current practice in industry is to periodically re-build such indices from scratch  to manifest recent changes to the underlying dataset. However, this is a very expensive operation. It would take about 1.5-2 hours on a dedicated high-end 48-core machine to build a good quality HNSW index  over 100M',\n",
              "  'good quality HNSW index  over 100M points. So we would need three dedicated machines for constantly rebuilding indices to maintain even six-hourly freshness guarantee over a billionpoint index. This is apart from the cost of actually serving the indices, which would again be anywhere between one for DRAM-SSD hybrid indices  to four for in-memory indices  depending on the exact algorithm being deployed. This paper aims to serve and update an index over a billion points with real-time freshness using just',\n",
              "  'real-time freshness using just one machine. This represents a significant cost advantage for web and enterprise-scale search platforms that need to serve indices spanning trillions of points. 1. We demonstrate how simple graph update rules result in degradation of index quality over a stream of insertions and deletions for popular graph-based algorithms such as HNSW  and NSG . 3. In order to enable scale, our system stores the bulk of the graph-index on an SSD, with only the most recent updates stored in',\n",
              "  'the most recent updates stored in memory. To support this, we design a novel two-pass StreamingMerge algorithm which makes merges the in-memory index with the SSD-index in a very write-efficient manner (crucial since burdening the SSD would lead to worse search performance as well). Notably, the time and space complexity of the merge procedure is proportional to the change set, thereby making it possible to update large billion-point indices on a machine with limited RAM using an order of magnitude less',\n",
              "  'using an order of magnitude less compute and memory than re-building the large index from scratch. 4. Using these ideas, we design the FreshDiskANN system to consist of a long-term SSD-resident index over the majority of the points, and a short-term in-memory index to aggregate recent updates. Periodically, unbeknownst to the end user, FreshDiskANN consolidates the short-term index into the long-term index using our StreamingMerge process in the background to bound the memory footprint of the short-term',\n",
              "  'memory footprint of the short-term index, and hence the overall system. Trees. Some of the early research on ANNS focused on low-dimensional points (say, d < 20). For such points, spatial partitioning ideas such as R*-trees , kd-trees  and Cover Trees  work well, but these typically do not scale well for high-dimensional data owing to the curse of dimensionality. There have been some recent advances in maintaining several trees and combining them with new ideas to develop good algorithms such as FLANN  and',\n",
              "  'good algorithms such as FLANN  and Annoy . However, they are built for static indices, and moreover, even here, the graph-based algorithms outperform them  on most datasets. Hashing. In a breakthrough result, Indyk and Motwani  show that a class of algorithms, known as locality sensitive hashing can yield provably approximate solutions to the ANNS problem with a polynomially-sized index and sublinear query time. Subsequent to this work, there has been a plethora of different LSH-based algorithms ,',\n",
              "  'different LSH-based algorithms , including those which depend on the data , use spectral methods , distributed LSH , etc. While the advantage of the simpler data-independent hashing methods are that updates are almost trivial, the indices are often entirely resident in DRAM and hence do not scale very well. Implementations which make use of auxiliary storage such as SRS  typically have several orders of magnitude slower query latencies compared to the graph-based algorithms. Other hashing-based methods',\n",
              "  'Other hashing-based methods  learn an optimal hash family by exploiting the neighborhood graph. Updates to an index would require a full re-computation of the family and hashes for every database point, making them impractical for fresh-ANNS. Data quantization and Inverted indices based algorithms have seen success w.r.t the goal of scaling to large datasets with low memory footprint. These algorithms effectively reduce the dimensionality of the ANNS problem by quantizing vectors into a compressed',\n",
              "  'vectors into a compressed representation so that they may be stored using smaller amount of DRAM. Some choices of quantizers  can support GPU-accelerated search on billion-scale datasets. Popular methods like IV- memory-footprint indices with reasonable search performance when querying for a large number of neighbors. While most methods minimize the vector reconstruction error ||x — x‘ ||?, where x is a database vector and x? is its reconstruction from the quantized representation, Anisotropic Vector',\n",
              "  'representation, Anisotropic Vector Quantization  optimizes for error for maximum inner-product search. Some of these systems such as FAISS  support insert and delete operations on an existing index under reasonable conditions like stationary data distributions. However, due to the irreversible loss due to the compression/quantization, these methods fail to achieve even moderate values of 1-recall@1, sometimes plateauing at 50% recall. These methods offer good guarantees on weaker notions such as',\n",
              "  'on weaker notions such as 1-recall@100, which is the likelihood that the true nearest neighbor for a query appears in a list of 100 candidates output by the algorithm. Hence they are not the methods of choice for high-recall high-throughput scenarios. A recent work, ADBV , proposes a hybrid model for supporting streaming inserts and deletes. New points are inserted into an in-memory HNSW  index while the main on-disk index utilises a new PQ-based indexing algorithm called VGPQ. In order to mitigate the',\n",
              "  'VGPQ. In order to mitigate the accuracy loss due to PQ, VGPQ search performs a large number of distance computations and incurs high search latencies. As distributed system over several powerful nodes, the model has low search throughput even when no inserts and deletes are going on. Hence, such a system cannot be used in high-throughput scenarios. In this section, we recap how most state-of-the-art graphbased indices work for static-ANNS and also highlight the issues they face with supporting deletions.',\n",
              "  'face with supporting deletions. graph, we let Nout(p) and Nin(p) denote the set of outand in-edges of p. We denote the number of points by n = |P|. Finally, we let xp denote the database vector corresponding to p, and let d(p, q) = ||xp — Xq|| denote the f distance between two points p and q. We now describe how graph-based ANNS indices are built and used for search. Roughly speaking, navigability of a directed graph is the property that ensures that the index can be queried for nearest neighbors using a',\n",
              "  'for nearest neighbors using a greedy search algorithm. The greedy search algorithm traverses the graph starting at a designated navigating or start node s € P. The search iterates by greedily walking from the current node u to a node v € Nout(u) that minimizes the distance to the query, and terminates when it reaches a locally-optimal node, say p*, that has the property d(p*,q) < d(p,q) Vp € Nou(p*). Greedy search cannot improve distance to the query point by navigating out of p* and returns it as the',\n",
              "  'out of p* and returns it as the candidate nearest neighbor for query q. Algorithm 1 describes a variant of this greedy search algorithm that returns k nearest neighbor candidates. Index Build consists of constructing a navigable graph. The graph is typically built to achieve two contrasting objectives to minimize search complexity: (i) make the greedy search algorithm applied to each base point p € P in the vertex set converge to p in the fewest iterations (intuitively, this would ensure that Algorithm 1',\n",
              "  'this would ensure that Algorithm 1 converges to p when searching for a query Xq if p is the nearest-neighbor for xq), and (ii) have a maximum out-degree of at most R for all p € P, a parameter typically between 16 — 128. While graph-indices offer state-of-the-art search performance, all known algorithms apply for the static-ANNS problem. In particular, deletions pose a big challenge for all these algorithms — e.g., see this discussion  on HNSW supporting delete requests by adding them to a blacklist and',\n",
              "  'by adding them to a blacklist and omitting from search results. Arguably, this is due to the lack of methods which modify the navigable graphs while retaining the original search quality. To further examine this phenomenon, we considered three popular static-ANNS algorithms, namely HNSW, NSG, and Vamana and tried the following natural update policies when faced with insertions and deletions. Insertion Policy. For insertion of a new point p, we run the candidate generation algorithm as used by the',\n",
              "  'algorithm as used by the respective algorithms and add the chosen inand out-edges, and if necessary, whenever the degree of any vertex exceeds the budget, run the corresponding pruning procedure. Delete Policy A. When a point p is deleted, we simply remove all inand out-edges incident to p, without adding any newer edges to compensate for potential loss of navigability. Indeed, note that p might have been on several navigating paths to other points in the graph. Delete Policy B. When a point p is deleted,',\n",
              "  'B. When a point p is deleted, we remove all inand out-edges incident to p, and add edges in the local neighborhood of p as follows: for any pair of directed edges (pin, p) and (p, Pout) in the graph, add the edge (pin, Pout) in the updated graph. If the degree bound of any vertex is violated, we run the pruning procedure associated with the respective algorithm to control the degrees. Figure 1 shows that both of these delete policies are not effective. In this experiment, we consider the SIFT1M dataset',\n",
              "  'we consider the SIFT1M dataset  comprising of a million points in 128 dimensions, and start with the static-ANNS index for each of the algorithms. We then compose an update stream by selecting 5% of the points at random and deleting them, followed by presenting them again as insertions. We then repeat this process over multiple Figure 1. Search recall over 20 cycles of deleting and reinserting 5% of SIFT1M dataset with statically built HNSW, Vamana, and NSG indices with L; = 44, 20, 27, respectively. A new',\n",
              "  '= 44, 20, 27, respectively. A new point x, is inserted into a FreshVamana index using Algorithm 2. Intuitively, it queries the current index for nearest neighbors of p to obtain the visited set V, generates candidate out-neighbors for xp using pruning procedure in Algorithm 3 on VV, and adds bi-directed edges between p and the pruned candidates. If out-degree of any vertex exceeds R, Algorithm 3 can be used to prune it to R. Our deletion algorithm Algorithm 4 is along the lines of Delete Policy B in',\n",
              "  'the lines of Delete Policy B in Section 3.3, with the crucial feature being using the relaxed a-pruning algorithm to retain density of the modified graph. Specifically, if p is deleted, we add edges (p’,p’’) whenever (p’, p) and (p, p’”) are directed edges in the current graph. In this process, if |Nout(p’)| exceeds the maximum out-degree R, we prune it using Algorithm 3, preserving the a—RNG property. However, since this operation involves editing the neighborhood for all the in-neighbors of p, it could',\n",
              "  'the in-neighbors of p, it could result be expensive to do eagerly, i.e., processing deletes as they arrive. FreshVamana employs a lazy deletion strategy when a point p is deleted, we add p to a DeleteList without changing the graph. DeleteList contains all the points that have been deleted but are still present in the graph. At search time, a modified Algorithm 1 uses nodes in the DeleteList for navigation, but filters them out from the result set. Delete Consolidation. After accumulating a non-trivial',\n",
              "  'After accumulating a non-trivial number of deletions (say 1-10% of the the index size), we batch-update the graph using Algorithm 4 to update the neighborhoods of points with out-edges to these deleted nodes. This operation is trivially parallelized using prefix sums to consolidate the vertex list, and a parallel map operation to locally update the graph around the deleted nodes. We now demonstrate how using our insert and delete algorithms (along with a choice of a > 1) ensures that the resulting index is',\n",
              "  'that the resulting index is stable over a long stream of updates. 5% Index Size 10% Index Size 50% Index Size 100 100 100 3 99 99 7 99 | ——  SIFTIM © 98 98 | | 98 4 ——  DeepiM a 97 97|| 97 4 2 96 96 96 by Sydieoeatd ——  GISTIM fe 95 95 Saeeeoceaell 95 “ah —— SIFT100M 94 94 ; ; 94 ; ; 0 20 40 20 40 Cycles Cycles SIFT1M Deep1M 98 to ® 96 ‘Ss 94 # ite) 92 90 20 40 0 20 40 Cycles (5% index size) a=1 a=1.1 a=1.2 a=13 scale to a billion-points per machine due to the large memory footprint of storing the graph',\n",
              "  'footprint of storing the graph and data in RAM. The main idea of overall system FreshDiskANN is to store a bulk of the graph-index on an SSD, and store only the recent changes in RAMTo further reduce the memory footprint, we can simply store compressed vector representation (using an idea such as Product Quantization (PQ) ) of all the data vectors. In fact, these ideas of using a-RNG graphs and storing only compressed vectors formed the crux of the SSD-based DiskANN static-ANNS index . 3.As FreshVamana',\n",
              "  'index . 3.As FreshVamana graphs are constructed using the a-RNG property (Section 4), the number of steps that the greedy search algorithm takes to converge to a locally optima is much smaller than other graph algorithms. Hence the total search latency to fetch the graph neighborhoods from SSD is small. So the a-RNG property helps us with both ensuring recall stability as well as obtaining tolerable search latencies for SSD-based indices. The overall system maintains two types of indices: one LongTerm',\n",
              "  'two types of indices: one LongTerm Index (aka LTI) and one or more instances of Temporary Index (a.k.a TempIndex), along with a DeleteList. ROand RW-Templndex: To aid with crash recovery, FreshDiskANN uses two types of TempIndex. At all times, (called RW-TempIndex) which can accept insert requests. We periodically convert the RW-TempIndex into a read-only in-memory index called RO-TempIndex, and also snapshot it to persistent storage. We then create a new empty RWTemp!ndex to ingest new points. Finally, to',\n",
              "  'to ingest new points. Finally, to complete the system design, we now present details of the StreamingMerge procedure. Whenever the total memory footprint of the various RO-TempIndex exceeds a pre-specified threshold, the system invokes a background merge procedure serves to change the SSD-resident LTI to reflect the inserts from the various instances of the ROTempIndex and also the deletes from the DeleteList. To this end, for notational convenience, let dataset P reflect the points in the LTI, and N',\n",
              "  'the points in the LTI, and N denote points currently staged in the different RO-TempIndex instances, and D denote the points marked for deletion in DeleteList. Then the desired end-result of the StreamingMerge is an SSD-resident LTI over the dataset (P U N) \\\\ D. Following the successful completion of the merge process, the system clears out the ROTempIndex instances thereby keeping the total memory footprint under control. There are two important constraints that the procedure must follow: At a high level,',\n",
              "  'must follow: At a high level, StreamingMerge first runs Algorithm 4 to process the deletes from D to obtain an intermediate-LTI index over the points P\\\\ D. Then StreamingMerge runs Algorithm 2 to insert each of the points in N into the intermediateLTI to obtain the resultant LTI. However, Algorithms 2 and 4 assume that both the LTI graph, as well as the full-precision vectors all the datapoints are stored in memory. The crucial challenges in StreamingMerge is to simulate these algorithm invocations in a',\n",
              "  'these algorithm invocations in a memory and SSD-efficient manner. This is done in three phases outlined below. 1. Delete Phase: This phase works on the input LTI instance and produces an intermediate-LT| by running Algorithm 4 to process the deletions D. To do this in a memoryefficient manner, we load the points in LTI and their neighborhoods in the LT! block-by-block from the SSD, and execute Algorithm 4 for the nodes in the block using multiple threads, and write the modified block back to SSD on the',\n",
              "  'modified block back to SSD on the intermediate-LTI. Furthermore, whenever Algorithm 4 or Algorithm 3 make any distance comparisons, we use the compressed PQ vectors which are already stored on behalf of the LTI to calculate the approximate distances. Note that this idea of replacing any exact distance computations with approximate distances using the compressed vectors will be used in the subsequent phases of the StreamingMerge also. 2. Insert Phase: This phase adds all the new points in N to the',\n",
              "  'all the new points in N to the intermediate-LTI by trying to simulate Algorithm 2. As a first step, we run the GreedySearch(s, p, 1, L) on the SSDresident intermediate-LTI to get the set V of vertices visited on the search path. Since the graph is stored on the SSD, any requested neighborhood Nou(p’) by the search algorithm is fetched from the SSD. The a-RNG property ensures that the number of such neighborhood requests is small, and hence the overall latency per point is bounded. We then run the',\n",
              "  'point is bounded. We then run the RobustPrune(p, V, a, R) procedure to determine the candidate set of neighbors for p. However, unlike Algorithm 2, we do not immediately attempt to insert p into Nour(p’) for P’ © Nout(p) (the backward edges) since this could result in an impractical number of random reads and writes to 3. Patch Phase: After processing all the inserts, we patch the A data-structure into the output SSD-resident LTI index. For this, we fetch all points p in the intermediate-LTI blockby-block',\n",
              "  'the intermediate-LTI blockby-block from the SSD, add the relevant out-edges for each node p from A, and check the new degree | Nou (p) UA(p)| exceeds R. If so, prune the neighborhood by setting Nour(p) = RobustPrune(p, Nour (p) U A(p), «, +). Within each block read from the SSD, this operation can be applied to each vertex in a data-parallel manner. Subsequently, the updated block is written back to SSD before loading a new block. 1/0 cost. The procedure does exactly two sequential passes over the',\n",
              "  'two sequential passes over the SSD-resident data structure in the Delete and Patch Phases. Due to the a-RNG property of the intermediateLTI, the insertion algorithm performs a small number of random 4KB reads per inserted point (about 100 disk reads, a little more than the candidate list size parameter, which we typically set to 75). Note that this number would be much larger without the a-RNG property due to the possibility of very long navigation paths. Memory footprint: Throughout the StreamingMerge',\n",
              "  'Throughout the StreamingMerge process, A data structure has size O(|N|R) where R is the max-degree parameter of the index which is typically a small constant. For example, if |N| = 30M and R = 64, this footprint will be ~7GB. In addition, for approximate distances, recall that we keep a copy of PQ coordinates for all points in the index (~ 32GB for a billion-point index). While we have already demonstrated that our update algorithms Algorithms 2 and 4 ensure recall stability over long streams of updates in',\n",
              "  'over long streams of updates in Section 4.3, the actual form in which these algorithms are implemented in our StreamingMerge procedure is different, especially with the use of approximate compressed vectors for distance computations. Indeed, as we process more cycles of the StreamingMerge procedure, we expect the initial graph to be replaced by a graph entirely built based on approximate distances. Hence, we expect a In the experiment in Figure 4, we start with a statically built SSD-index built on 80M',\n",
              "  'built SSD-index built on 80M points randomly sampled from the SIFT100M dataset. Then, in each cycle, we update the index to reflect 8M deletions and an equal number of insertions from the spare pool of 20M points using StreamingMerge. We run this experiment for a total of 40 cycles and trace recall for the index after each cycle in Figure 4. Note that the index stabilizes at a lower recall value compared to the static index it starts out with, due to the use of approximate distances in the StreamingMerge',\n",
              "  'distances in the StreamingMerge process. We observe recall stabilization after ~ 20 cycles of deletion and insertion of 10% of the index size, at which point we expect most of the graph to be determined using approximate distances. Figure 4 (right) shows a similar plot for the 800M point subset of SIFT1B. We have thus empirically demonstrated that the FreshDiskANN index has stable recall over a stream of updates at steady-state. The frequency at which RW-TempIndex is snapshotted to a RO-TempIndex depends',\n",
              "  'to a RO-TempIndex depends on the intended recovery time. More frequent snapshots lead to small reconstruction times for RWTempIndex but create many instances of RO-TempIndex all of which have to be searched for each query. While searching a few additional small in-memory indices is not the rate limiting step for answering the query (searching the large LTI is), creating too many could can lead to inefficient search. A typical set up for a billion-point index would hold up to 30M points in the TempIndex',\n",
              "  'up to 30M points in the TempIndex between merges to the LTI. Limiting each in-memory index to 5M points results in at 6.1 Experimental Setup Hardware. All experiments are run on one of two machines: e (mem-mc) — a 64-vcore E64d_v4 Azure virtual machine instance used to measure latencies and recall for inmemory indices and the FreshVamana update rules. e (ssd-mc) — a bare-metal server with 2x Xeon 8160 CPUs (48 cores, 96 threads) and a 3.2TB Samsung PM1725a PCle SSD to evaluate SSD-based indices and the',\n",
              "  'evaluate SSD-based indices and the overall FreshDiskANN system. We now study the complete FreshDiskANN system in a realistic scenario — maintaining a large scale billion-scale index on the ssd machine and serving thousands of inserts, deletes and searches per second concurrently over multiple days. For this experiment, we use the SIFT1B dataset, but limit the size of our indices to around 800M points, so that we have a sufficiently big spare pool of 200M points for insertions at all times. Our experiment',\n",
              "  'at all times. Our experiment can be divided into two phases: in the first phase, starting with a statically built index on a random 100M subset of SIFT1B, we define our update stream to comprise only of inserts until the total number of points in the index reaches around 800M points. We call this the ramp-up phase. We then transition into what we call a steady-state phase, where we update the index by deleting and inserting points at the same rate. We delete existing points and insert points from the spare',\n",
              "  'and insert points from the spare pool of 200M points from the SIFT1B dataset. We then continue this for several days and observe the behaviour of the system in terms of latencies and recall. How fast can we feed inserts into the system in these phases, i.e., how many threads can we use to concurrently insert into the FreshDiskANN system? If we use too many threads for insertion, the TempIndex will reach the limit M of 30M points before the StreamingMerge process has completed. This would result in a',\n",
              "  'completed. This would result in a backlog of inserts not consolidate to LT] on SSD. With the benefit of some prior experiments (of how long each cycle of the StreamingMerge takes), we arrive at the number of threads which concurrently feed inserts into the FreshDiskANN system in each of the phases and describe them below. Figure 5. Search latencies for Ls = 100 (always > 92% 5recall@5) over the course of ramping up an index to size 800M. Each point is mean latency over a 10000-query batch. Stage 2: Steady',\n",
              "  '10000-query batch. Stage 2: Steady State. In the second stage of the experiment, we maintain an index size of around 800M while supporting a large number of equal inserts and deletes. Externally, 2 threads insert points into the index, 1 thread issues deletes, and 10 threads concurrently search it. Since the deletes happen near instantly, we added a sleep timer between the delete requests to ensure that the rate of deletions is similar to that of insertions. Note that we reduced the number of insert',\n",
              "  'we reduced the number of insert threads from 3 to 2 to slow down the insertion rate to accommodate the longer merge times compared to the ramp-up experiment — the StreamingMerge process now processes 30M deletes in addition to 30M inserts. We present userperceived latencies for search and insertions in Figure 6. think is likely due to head-of-line blocking by the large sequential read and write operations that copy the LTI index to and from the main memory. Update Throughput of System. While FreshDiskANN',\n",
              "  'of System. While FreshDiskANN provides latencies of about 1ms for insert (Figure 6) and 0.1: for delete (since they are simply added to a DeleteList), in practice they need to be throttled so that the in-memory TempIndex do not grow too large before the ongoing background merge completes. As a result, the speed of the merge operation dictates the update rates the system can sustain over long periods of time. The threads allocation described above helps us control the rate of external insert and delete',\n",
              "  'rate of external insert and delete operations to what the StreamingMerge procedure can complete before the TempIndex grows to 30M points. To better understand the thread allocation, we record the time taken for the StreamingMerge process to merge 30M inserts into an index of size roughly 800M using T = 40 threads. This takes around 8400s per cycle. To prevent the TempIndex from growing too much while the merge procedure is running, we throttle the inserts to around 3500 inserts per second, so that the',\n",
              "  'inserts per second, so that the TempIndex accumulates under 30M newly inserted points in one merge cycle. Since the insertion latencies into in-memory FreshVamana indices is around 1ms (Figure 6), we allocated a total of 3 threads concurrently feeding into the system. This ensured that the system never backlogged throughout the ramp-up experiment. Trade-off of Varying Number of Merge Threads T. If we increase the merge threads T, the merges happen faster, which means we can ingest insertions and deletions',\n",
              "  'ingest insertions and deletions into the system at a faster throughput (without the TempIndex size growing too large). On the other hand, if T is large, the SSDbandwidth used by the StreamingMerge process increases and this adversely affects the search throughput. We examine the merge times with varying threads in Figure 7 (left) and the search latencies when different numbers of threads are performing background merge in Figure 8. 70 30 1.6 PARAL @ 60 B95 ~ £ 50 & a 1.4} jth Ea > ZS fs 520 = th ——s0 & 40',\n",
              "  'jth Ea > ZS fs 520 = th ——s0 & 40 3 g 1.27 5) £45 5 goth = 30 3 1} = = 19 Sipe] £ 20 9 3 § v 0. 8 = | HB 10 a» 1) eo 1 i 4 0 i | fi Ll Lo Lo 0.6 Ap nneteernne| 0 2-105 4-10° 6-10° 5,000 10,000 15,000 0 10 20 30 40 Time elapsed since start of experiment (seconds) Time since merge start (sec) #Batches Figure 6. Mean latency‘measurements for the week-long steady-state experiment with an 800M FreshDiskANN index The Cost of StreamingMerge. The StreamingMerge procedure with 40 threads takes around 16000 seconds',\n",
              "  'threads takes around 16000 seconds to merge 30M inserts and deletes into a 800M point LTI (a 7.5% change), which is 8.5% of the ~ 190000 seconds it would take to rebuild the index from scratch with a similar thread-count. We conclude that the merge process is significantly more cost-effective than periodically rebuilding the indices, which is the current choice of system design for graph indices. Further, StreamingMerge scales near linearly with the number of threads (see Figure 7). While the Delete phase',\n",
              "  'Figure 7). While the Delete phase scales linearly, the Patch and Insert phases scale sub-linearly due to intensive SSD I/O. Using fewer threads also results in more predictable search latencies (esp. 99% latency) due to the reduced SSD contention. This allows us to set the number of threads StreamingMerge uses to meet the desired update rate — 3600 updates/sec require 40 threads, but if we were only required to support 1000 updates/sec, we could choose to run StreamingMerge with 10 threads, and take',\n",
              "  'with 10 threads, and take advantage of higher search throughput and predictable latencies. In this paper, we develop FreshVamana, the first graphbased fresh-ANNS algorithm capable of reflecting updates to an existing index using compute proportional to the size of updates, while ensuring the index quality is similar to one rebuilt from scratch on the updated dataset. Using update rules from FreshVamana, we design a novel two-pass StreamingMerge procedure which reflects these updates into an SSD-resident',\n",
              "  'these updates into an SSD-resident index with minimal write amplification. Using FreshVamana and StreamingMerge, we develop and rigorously evaluate FreshDiskANN, a highly-scalable freshANNS system that can maintain a dynamic index of a billion points on a commodity machine while concurrently supporting inserts, deletes, and search operations at millisecondscale latencies. Rakesh Agrawal, Christos Faloutsos, and Arun Swami. 1993. Efficient similarity search in sequence databases. In Foundations of Data',\n",
              "  'databases. In Foundations of Data Organization and Algorithms, David B. Lomet (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 69-84. Alexandr Andoni and Piotr Indyk. 2008. Near-optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions. Commun. ACM 51, 1 (Jan. 2008), 117-122. https://doi.org/10.1145/ 1327452.1327494 Alexandr Andoni and Ilya Razenshteyn. 2015. Optimal DataDependent Hashing for Approximate Near Neighbors. In Proceedings of the Forty-seventh Annual ACM Symposium on',\n",
              "  'Annual ACM Symposium on Theory of Computing (Portland, Oregon, USA) (STOC ’15). ACM, New York, NY, USA, 793-801. https://doi.org/10.1145/2746539.2746553 Akhil Arora, Sakshi Sinha, Piyush Kumar, and Arnab Bhattacharya. 2018. HD-Index: Pushing the Scalability-Accuracy Boundary for Approximate kNN Search in High-Dimensional Spaces. Proceedings of the VLDB Endowment 11 (04 2018). https://doi.org/10.14778/3204028. 3204034 Sunil Arya and David M. Mount. 1993. Approximate Nearest Neighbor Queries in Fixed',\n",
              "  'Nearest Neighbor Queries in Fixed Dimensions. In Proceedings of the Fourth Annual ACMSIAM Symposium on Discrete Algorithms (Austin, Texas, USA) (SODA ’93). Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 271-280. http://dl.acm.org/citation.cfm?id=313559.313768 Martin Aumiiller, Erik Bernhardsson, and Alexander Faithfull. 2020. ANN-Benchmarks: A benchmarking tool for approximate nearest neighbor algorithms. Information Systems 87 (2020). http://www.',\n",
              "  'Systems 87 (2020). http://www. sciencedirect.com/science/article/pii/S03064379 18303685 A. Babenko and V. Lempitsky. 2012. The inverted multi-index. In 2012 IEEE Conference on Computer Vision and Pattern Recognition. 30693076. Alina Beygelzimer, Sham Kakade, and John Langford. 2006. Cover Trees for Nearest Neighbor. In Proceedings of the 23rd International Conference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML Alina Beygelzimer, Sham Kakade, and John Langford. 2006. Cover Trees for Nearest',\n",
              "  '2006. Cover Trees for Nearest Neighbor. In Proceedings of the 23rd International Conference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML ’06). Association for Computing Machinery, New York, NY, USA, 97-104. https://doi.org/10.1145/1143844.1143857 Leonid Boytsov. [n.d.]._https://github.com/nmslib/nmslib/issues/73 A. Camerra, E. Keogh, T. Palpanas, and J. Shieh. 2010. iSAX 2.0: Indexing and Mining One Billion Time Series. In 2013 IEEE 13th International Conference on Data Mining. IEEE Computer',\n",
              "  'on Data Mining. IEEE Computer Society, Los Alamitos, CA, USA, 58-67. https://doi.org/10.1109/ICDM.2010.124 Kenneth L. Clarkson. 1994. An Algorithm for Approximate Closestpoint Queries. In Proceedings of the Tenth Annual Symposium on Computational Geometry (Stony Brook, New York, USA) (SCG 94). ACM, New York, NY, USA, 160-164. https://doi.org/10.1145/177424.177609 Kunal Dahiya, Deepak Saini, Anshul Mittal, Ankush Shaw, Kushal Dave, Akshay Soni, Himanshu Jain, Sumeet Agarwal, and Manik Varma. 2021. DeepXML:',\n",
              "  'and Manik Varma. 2021. DeepXML: A Deep Extreme Multi-Label Learning Framework Applied to Short Text Documents. In Proceedings of the 14th International Conference on Web Search and Data Mining (Jerusalem, Israel) (WSDM 21). Association for Computing Machinery, New York, NY, USA, 8. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. CoRR abs/1810.04805 (2018). arXiv:1810.04805',\n",
              "  '(2018). arXiv:1810.04805 http://arxiv.org/abs/1810.04805 Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, and Houda Benbrahim. 2019. Return of the Lernaean Hydra: Experimental Evaluation of Data Series Approximate Similarity Search. Proc. VLDB Endow. 13, 3 (2019), 403-420. https://doi.org/10.14778/3368289.3368303 Evelyn Fix and J. L. Hodges. 1989. Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties. International Statistical Review / Revue Internationale de Statistique 57, 3',\n",
              "  'de Statistique 57, 3 (1989), 238-247. http://www.jstor.org/stable/1403797 Cong Fu and Deng Cai. [n.d.]. https://github.com/ZJULearning/efanna Cong Fu, Chao Xiang, Changxu Wang, and Deng Cai. 2019. Fast Approximate Nearest Neighbor Search With The Navigating Spreadingout Graphs. PVLDB 12, 5 (2019), 461 474. https://doi.org/10.14778/ 3303753.3303754 Maurice Herlihy and Nir Shavit. 2012. The Art of Multiprocessor Programming, Revised Reprint (1st ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.',\n",
              "  'Inc., San Francisco, CA, USA. Piotr Indyk and Rajeev Motwani. 1998. Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. In Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing (Dallas, Texas, USA) (STOC ’98). ACM, New York, NY, USA, 604-613. M Iwasaki. [n.d.]. _https://github.com/yahoojapan/NGT/wiki Masajiro Iwasaki and Daisuke Miyazaki. 2018. Optimization of Indexing Based on k-Nearest Neighbor Graph for Proximity Search in High-dimensional Data. Herve Jegou,',\n",
              "  'Data. Herve Jegou, Romain Tavenard, Matthijs Douze, and Laurent Amsaleg. 2011. Searching in one billion vectors: Re-rank with source coding. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2011, May 22-27, 2011, Prague Congress Center, Prague, Czech Republic. 861-864. https: //doi.org/10.1109/ICASSP.2011.5946540 Qing-Yuan Jiang and Wu-Jun Li. 2015. Scalable Graph Hashing with Feature Transformation. In Proceedings of the 24th International Conference',\n",
              "  'the 24th International Conference on Artificial Intelligence (Buenos Aires, Argentina) (IJCAI’15). AAAI Press, 2248-2254. Header only C++/python library for fast approximate nearest neighbors. [n.d.]._ https://github.com/nmslib/hnswlib Yongjoo Park, Michael Cafarella, and Barzan Mozafari. 2015. NeighborSensitive Hashing. Proc. VLDB Endow. 9, 3 (Nov. 2015), 144-155. https: //doi.org/10.14778/2850583.2850589 Suhas Jayaram Subramanya, Fnu Dewvrit, Rohan Kadekodi, Ravishankar Krishnawamy, and Harsha Vardhan',\n",
              "  'Krishnawamy, and Harsha Vardhan Simhadri. 2019. DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada, Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett (Eds.). 1374813758. _',\n",
              "  'Garnett (Eds.). 1374813758. _ http://papers.nips.cc/paper/9527-rand-nsg-fast-accuratebillionpoint-nearest-neighbor-search-on-a-single-node Mengzhao Wang, Xiaoliang Xu, Qiang Yue, and Yuxiang Wang. 2021. A Comprehensive Survey and Experimental Comparison of GraphBased Approximate Nearest Neighbor Search. CoRR abs/2101.12631 (2021). arXiv:2101.12631 https://arxiv.org/abs/2101.12631 Roger Weber, Hans-Jérg Schek, and Stephen Blott. 1998. A Quantitative Analysis and Performance Study for Similarity-Search',\n",
              "  'Study for Similarity-Search Methods in High-Dimensional Spaces. In Proceedings of the 24rd International Conference on Very Large Data Bases (VLDB ’98). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 194-205. http: //dl.acm.org/citation.cfm?id=645924.671192 Figure 9. Search 5-recall@5 after each cycle of 12K insertions and 10K deletions to FreshVamana, ramping up from 100K to 1M points. Horizontal lines indicate recall of the corresponding batch built Vamana index. 100 — 100 9 | “49 ——= © 98 98 =',\n",
              "  '100 — 100 9 | “49 ——= © 98 98 = 97 97 5 96 96 + 4 © 95 /7 95 | 94 |94 93 ! ! ! 93 ! ! 0 20 40 60 0 20 40 #cycles #cycles L60 L150 L 220 L55 L100 L200 Figure 10. Search recall FreshVamana on SIFT100M while (left) ramping up from 1 point; and (right) ramping up starting from 30M points, and steady-state after 45 cycles. Horizontal lines indicate recall of the Vamana index with the same build time. n Table 1 we compare the build time of Vamana and FreshVamana for the same build parameters. The trade-off for',\n",
              "  'parameters. The trade-off for this speed-up comes in the form of increased search latency for the same k-recall@k. In Figure 11, we show that using FreshVamana to make updates to the index takes only a fraction of the time to rebuild it from scratch using Vamana. We show a similar comparison of DiskANN and FreshDiskANN in Table 2. Despite using more than double the resources, uilding a 800M index from scratch using DiskANN takes more than 7x the time that FreshDiskANN takes to reflect the same changes into',\n",
              "  'to reflect the same changes into the index. To determine the optimal value of a, we perform the FreshVamana steady-state experiments with different values of a. In the plots in Figure 3, we use the same value of a for 5This is true of any index a larger index over data from the same distribution will provide lower recall with the search parameter/complexity. Figure 11. Time taken to merge delete and re-insert of 5%, 10%, and 50% of index size into a FreshVamana index, expressed relative to index rebuild',\n",
              "  'relative to index rebuild time for Vamana. building the intial Vamana index and for updating it. Other build and update parameters are same for each plot (R = 64, L = 75). We compare the evolution of search recall in the 95% range and average degree with different a. Finally we compare search recall versus latency for static indices built with different a to choose the best candidate. For all a > 1, average degree increases over the course of the experiments and recall stabilises around the initial value.',\n",
              "  'around the initial value. For static indices, latency at the same recall value improves from 1 to 1.2 after which further increasing a shows now noticeable improvement as evidenced by recall-vs-latency plots for Vamana indices in Figure 13. Since we want to minimise the memory footprint of our index, we choose the a value with best search performance and lowest average degree, which in this case is 1.2. E.1.1 Search Latency vs Recall. In Figures 15 to 17, we compare the search latencies for Vamana and',\n",
              "  'search latencies for Vamana and build timenormalized FreshVamana (build parameters adjusted to match the build time of Vamana) for various k-recall@k. For 1recall@1 and 10-recall@10, we compare latencies for 95%, 98% and 99% recall. For 100-recall@100, we compare over 98% and 99% recall because the lowest search list parameter L value gives 98% recall. E.1.2 Recall stability of FreshVamana. In Figure 18, we demonstrate k-recall@k stability of FreshVamana for commonly used k values. We show the',\n",
              "  'used k values. We show the post-insertion recall trends for 1-recall@1, 10-recall@10 and 100-recall@100. For k = 1, we show how the 95% and 99.9% recall are stable. For k = 10, we show that 95% and 99% recall are stable. For k = 100, the lowest valid search list parameter L value is 100 and this gives 98% recall. So we show the stability of 98% and 99% recall. E.2.1 Search latencies over one merge cycle. In ? ?? ?, we present the evolution of mean search latency for 100recall@100 and 10-recall@10 over the',\n",
              "  'and 10-recall@10 over the course of one merge cycle in a 800M FreshDiskANN steady-state experiment. Figure 15. Query latency for Vamana and build-time normalized FreshVamana 1-recall@1 at 95%, 98%, and 99%. Figure 16. Query latency for Vamana and build-time normalized FreshVamana 10-recall@10 at 95%, 98%, and 99%. Figure 17. Query latency for Vamana and build-time normalized FreshVamana 100-recall@100 at 98%, and 99%. Figure 18. Post-insertion search k-recall@k for k = 1, 10, 100 of FreshVamana index over',\n",
              "  '10, 100 of FreshVamana index over 50 cycles of deletion and re-insertion of 5%, 10% and 50% (rows 1, 2 and 3 respectively) of SIFT1M index with varying search list size parameter L. We run the merge on SIFT800M index with different thread allocations to understand the effect of merge on search latency. In Figure 8, we plot a smoothed curve of mean search latencies when merge uses 20 and 40 threads. Merge with 40 threads takes approximately half the time as that with 20, so there are two x axes adjusted to',\n",
              "  'there are two x axes adjusted to roughly align their Delete, Insert and Patch phases. As evident from the figure, search'],\n",
              " 'hnsw': ['Constantly growing amount of the available information resources has led to high demand in scalable and efficient similarity search data structures. One of the generally used approaches for information search is the K-Nearest Neighbor Search (K-NNS). The K-NNS assumes you have a defined distance function between the data elements and aims at finding the K elements from the dataset which minimize the distance to a given query. Such algorithms are used in many applications, such as non-parametric machine',\n",
              "  'such as non-parametric machine learning algorithms, image features matching in large scale databases  and semantic document retrieval . A naive approach to K-NNS is to compute the distances between the query and every element in the dataset and select the elements with minimal distance. Unfortunately, the complexity of the naive approach scales linearly with the number of stored elements making it infeasible for large-scale datasets. This has led to a high interest in development of fast and scalable KNNS',\n",
              "  'of fast and scalable KNNS algorithms. Exact solutions for K-NNS [3-5] may offer a substantial search speedup only in case of relatively low dimensional data due to “curse of dimensionality”. To overcome this problem a concept of Approximate Nearest Neighbors Search (K-ANNS) was proposed, which relaxes the condition of the exact search by allowing a small number of errors. The quality of an inexact search (the recall) is defined as the ratio between the number of found true nearest neighbors and K. The most',\n",
              "  'nearest neighbors and K. The most popular K-ANNS solutions are based on approximated versions of tree algorithms , locality-sensitive hashing (LSH)  and product quantization (PQ) [10-17]. Proximity graph KANNS algorithms [10, 18-26] have recently gained popularity offering a better performance on high dimensional datasets. However, the power-law scaling of the proximity graph routing causes extreme performance degradation in case of low dimensional or clustered data. In this paper we propose the',\n",
              "  'data. In this paper we propose the Hierarchical Navigable Small World (Hierarchical NSW, HNSW), a new fully graph based incremental K-ANNS structure, which can offer a much better logarithmic complexity scaling. The main contributions are: explicit selection of the graph’s enter-point node, separation of links by different scales and use of an advanced heuristic to select the neighbors. Alternatively, Hierarchical NSW algorithm can be seen as an extension of the probabilistic skip list structure  with',\n",
              "  'skip list structure  with proximity graphs instead of the linked lists. Performance evaluation has demonstrated that the proposed general metric space method is able to strongly outperform previous opensource state-of-the-art approaches suitable only for vector spaces. In the vast majority of studied graph algorithms searching takes a form of greedy routing in k-Nearest Neighbor (k-NN) graphs [10, 18-26]. For a given proximity graph, we start the search at some enter point (it can be random or supplied by',\n",
              "  '(it can be random or supplied by a separate algorithm) and iteratively traverse the graph. At each step of the traversal the algorithm examines the distances from a query to the neighbors of a current base node and then selects as the next base node the adjacent node that minimizes the distance, while constantly keeping track of the best discovered neighbors. The search is terminated when some stopping condition is met (e.g. the number of distance calculations). Links to the closest neighbors in a k-NN',\n",
              "  'to the closest neighbors in a k-NN graph serve as a simple approximation of the Delaunay graph  (a graph which guranties that the result of a basic greedy graph traversal is always the nearest neighbor). Unfortunately, Delaunay graph cannot be efficiently constructed without prior information about the structure of a space , but its approximation by the nearest neighbors can be done by using only distances between the stored elements. It was shown that proximity graph approaches with such approximation',\n",
              "  'approaches with such approximation perform competitive to other k-ANNS thechniques, such as kd-trees or LSH [18-26]. In  authors proposed a proximity graph K-ANNS algorithm called Navigable Small World (NSW, also known as Metricized Small World, MSW), which utilized navigable graphs, i.e. graphs with logarithmic or olylogarithmic scaling of the number of hops during the greedy traversal with the respect of the network size . The NSW graph is constructed via consecutive insertion of elements in random order',\n",
              "  'of elements in random order by bidirectionally connecting them to the M closest neighbors from the reviously inserted elements. The closest neighbors are ound using the structure’s search procedure (a variant of a greedy search from multiple random enter nodes). Links to the closest neighbors of the elements inserted in the beginning of the construction later become bridges between the network hubs that keep the overall graph connectivity and allow the logarithmic scaling of the number of hops during',\n",
              "  'of the number of hops during greedy routing. Construction phase of the NSW structure can be efficiently parallelized without global synchronization and without mesuarable effect on accuracy , being a good choice for distributed search systems. The NSW approach delivered the state-of-the-art performance on some datasets , however, due to the overall polylogarithmic complexity scaling, the algorithm was still prone to severe performance degradation on low dimensional datasets (on which NSW could lose to',\n",
              "  '(on which NSW could lose to tree-based algorithms by several orders of magnitude ). Networks with logarithmic or polylogarithmic scaling of the greedy graph routing are known as the navigable small world networks . Such networks are an important topic of complex network theory aiming at understanding of underlying mechanisms of real-life networks formation in order to apply them for applications of scalable routing  and distributed similarity search [25, 26, 30, 37-40]. The first works to consider spatial',\n",
              "  'first works to consider spatial models of navigable networks were done by J. Kleinberg  as social network models for the famous Milgram experiment . Kleinberg studied a variant of random Watts-Strogatz networks , using a regular lattice graph in ddimensional vector space together with augmentation of long-range links following a specific long link length distribution r*. For a=d the number of hops to get to the target by greedy routing scales polylogarithmically (instead of a power law for any other value',\n",
              "  'of a power law for any other value of a). This idea has inspired development of many K-NNS and K-ANNS algorithms based on the navigation effect [37-40]. But even though the Kleinberg’s navigability criterion in principle can be extended for more general spaces, in order to build such a navigable network one has to know the data distribution beforehand. In addition, greedy routing in Kleinberg’s graphs suffers from polylogarithmic complexity scalability at best. Another well-known class of navigable',\n",
              "  'well-known class of navigable networks are the scale-free models , which can reproduce several features of real-life networks and advertised for routing applications . However, networks produced by such models have even worse power law complexity scaling of the greedy search  and, just like the Kleinberg’s model, scale-free models require global knowledge of the data distribution, making them unusable for search applications. The above-described NSW algorithm uses a simpler, reviously unknown model of',\n",
              "  'reviously unknown model of navigable networks, alowing decentralized graph construction and suitable for data in arbitrary spaces. It was suggested  that the NSW network formation mechanism may be responsible or navigability of large-scale biological neural networks (presence of which is disputable): similar models were able to describe growth of small brain networks, while the model predicts several high-level features observed in arge scale neural networks. However, the NSW model also suffers from the',\n",
              "  'NSW model also suffers from the polylogarithmic search complexity of the routing process. from a low degree node and traverses the graph simultaneously increasing the node’s degree until the characteristic radius of the node links length reaches the scale of the distance to the query. Before the latter happens, the average degree of a node can stay relatively small, which leads to an increased probability of being stuck in a distant false local minimum. One can avoid the described problem in NSW by',\n",
              "  'the described problem in NSW by starting the search from a node with the maximum degree (good candidates are the first nodes inserted in the NSW structure ), directly going to the “zoom-in” phase of the search. Tests show that setting hubs as starting points substantially increases probability of successful routing in the structure and provides significantly better performance at low dimensional data. However, it still has only a polylogarithmic complexity scalability of a single greedy search at best, and',\n",
              "  'single greedy search at best, and performs worse on high dimensional data compared to Hierarchical NSW. The reason for the polylogarithmic complexity scaling of a single greedy search in NSW is that the overall number of distance computations is roughly proportional to a product of the average number of greedy algorithm hops by the average degree of the nodes on the greedy path. The average number of hops scales logarithmically , while the average degree of the nodes on the greedy path also scales',\n",
              "  'on the greedy path also scales logarithmically due to the facts that: 1) the greedy search tends to go through the same hubs as the network grows ; 2) the average number of hub connections grows logarithmically with an increase of the network size. Thus we get an overall polylogarithmic dependence of the resulting complexity. The idea of Hierarchical NSW algorithm is to separate the links according to their length scale into different layers and then search in a multilayer graph. In this case we can',\n",
              "  'graph. In this case we can evaluate only a needed fixed portion of the connections for each element independently of the networks size, thus allowing a logarithmic scalability. In such structure the search starts from the upper layer which has only the longest links (the “zoom-in” phase). The algorithm greedily traverses through the elements from the upper layer until a local minimum is reached (see Fig. 1 for illustration). After that, the search switches to the lower layer (which has shorter links),',\n",
              "  'layer (which has shorter links), restarts from the element which was the local minimum in the previous layer and the process repeats. The maximum number of connections per element in all layers can be made constant, thus allowing a logarithmic complexity scaling of routing in a navigable small world network. One way to form such a layered structure is to explicitly set links with different length scales by introducing layers. For every element we select an integer level / which defines the maximum layer',\n",
              "  '/ which defines the maximum layer for which the element belongs to. For all elements in a layer a proximity graph (i.e. graph containing only “short” links that approximate Delaunay graph) is built incrementally. If we set an exponentially decaying probability of / (i.e. following a geometric distribution) we get a logarithmic scaling of the expected number of layers in the structure. The search procedure is an iterative greedy search starting from the top layer and finishing at the zero layer. In case we',\n",
              "  'at the zero layer. In case we merge connections from all layers, the structure becomes similar to the NSW graph (in this case the / can be put in correspondence to the node degree in NSW). In contrast to NSW, Hierarchical NSW construction algorithm does not require the elements to be shuffled before the insertion the stochasticity is achieved by using level randomization, thus allowing truly incremental indexing even in case of temporarily alterating data distribution (though changing the order of the',\n",
              "  '(though changing the order of the insertion slightly alters the performace due to only partially determenistic construction procedure). Fig. 2. Illustration of the heuristic used to select the graph neighbors for two isolated clusters. A new element is inserted on the boundary of Cluster 1. All of the closest neighbors of the element belong to the Cluster 1, thus missing the edges of Delaunay graph between the clusters. The heuristic, however, selects element e2 from Cluster 2, thus, maintaining the global',\n",
              "  '2, thus, maintaining the global connectivity in case the inserted element is the closest to ez compared to any other element from Cluster 1. For the selection of the proximity graph connections during the element insertion we utilize a heuristic that takes into account the distances between the candidate elements to create diverse connections (a similar algorithm was utilized in the spatial approximation tree  to select the tree children) instead of just selecting the closest neighbors. The heuristic',\n",
              "  'closest neighbors. The heuristic examines the candidates starting from the nearest (with respect to the inserted element) and creates a connection to a candidate only if it is closer to the base (inserted) element compared to any of the already connected candidates (see Section 4 for the details). When the number of candidates is large enough the heuristic allows getting the exact relative neighborhood graph  as a subgraph, a minimal subgraph of the Delaunay graph deducible by using only the distances',\n",
              "  'by using only the distances between the nodes. The relative neighborhood graph allows easily keeping the global connected component, even in case of highly clustered data (see Fig. 2 for illustration). Note that the heuristic creates extra edges compared to the exact relative neighborhood graphs, allowing controlling the number of the connections which is important for search performance. For the case of 1D data the heuristic allows getting the exact Delaunay subgraph (which in this case coincides with the',\n",
              "  'in this case coincides with the relative neighborhood graph) by using only information about the distances between the elements, thus making a direct transition from Hierarchical NSW to the 1D probabilistic skip list algorithm. Base variant of the Hierarchical NSW _ proximity graphs was also used in ref.  (called ‘sparse neighborhood graphs’) for proximity graph searching. Similar heuristic was also a focus of the FANNG algorithm  Input: multilayer graph hnsw, new element q, number of established',\n",
              "  'element q, number of established connections M, maximum number of connections for each element per layer Mmax, size of the dynamic candidate list efConstruction, normalization factor for level generation mi Network construction algorithm (alg. 1) is organized via consecutive insertions of the stored elements into the graph structure. For every inserted element an integer maximum layer / is randomly selected with an exponentially decaying probability distribution (normalized by the m, parameter, see line 4',\n",
              "  'by the m, parameter, see line 4 in alg. 1). The first phase of the insertion process starts from the top layer by greedily traversing the graph in order to find the ef closest neighbors to the inserted element gq in the layer. After that, the algorithm continues the search from the next layer using the found closest neighbors from the previous layer as enter points, and the process repeats. Closest neighbors at each layer are found by a variant of the greedy search algorithm described in alg. 2, which is',\n",
              "  'described in alg. 2, which is an updated version of the algorithm from . To obtain the approximate ef nearest neighbors in some layer 1, a dynamic list W of ef closest found elements (initially filled with enter points) is kept during the search. The list is updated at each step by evaluating the neighborhood of the closest previously non-evaluated element in the list until the neighborhood of every element from the list is evaluated. Compared to limiting the number of distance calculations, Hierarchical',\n",
              "  'calculations, Hierarchical NSW stop condition has an advantage it allows discarding candidates for evalution that are further from the query than the furthest element in the list, thus avoiding bloating of search structures. As in NSW, the list is emulated via two priority queues for better performance. The distinctions from NSW (along with some queue optimizations) are: 1) the enter point is a fixed parameter; 2) instead of changing the number of multi-searches, the quality of the search is controlled by',\n",
              "  'of the search is controlled by a different parameter ef (which was set to K in NSW ). Input: query element q, enter points ep, number of nearest to q elements to return ef, layer number Ic During the first phase of the search the efparameter is set to 1 (simple greedy search) to avoid introduction of additional parameters. Two methods for the selection of Mneighbors from the candidates were considered: simple connection to the closest elements (alg. 3) and the heuristic that accounts for the distances',\n",
              "  'that accounts for the distances between the candidate elements to create connections in diverse directions (alg. 4), described in the Section 3. The heuristic has two additional parameters: extendCandidates (set to false by default) which extends the candidate set and useful only for extremely clustered data, and keepPrunedConnections which allows getting fixed number of connection per element. The maximum number of connections that an element can have per layer is defined by the parameter M,,,, for every',\n",
              "  'by the parameter M,,,, for every layer higher than zero (a special parameter M,,.9 is used for the ground layer separately). If a node is already full at the moment of making of a new connection, then its extended connection list gets shrunk by the same algorithm that used for the neighbors selection (algs. 3 or 4). The insertion procedure terminates when the connections of the inserted elements are established on the zero layer. The K-ANNS search algorithm used in Hierarchical NSW is presented in alg. 5.',\n",
              "  'NSW is presented in alg. 5. It is roughly equivalent to the insertion algorithm for an item with layer 40. The difference is that the closest neighbors found at the ground layer which are used as candidates for the connections are now returned as the search result. Algorithm 4 SELECT-NEIGHBORS-HEURISTIC(q, C, M, Ic, extendCandidates, keepPrunedConnections) Input: base element q, candidate elements C, number of neighbors to return M, layer number I:, flag indicating whether or not to extend candidate list',\n",
              "  'or not to extend candidate list extendCandidates, flag indicating whether or not to add discarded elements keepPrunedConnections Output: M elements selected by the heuristic 1R<@ 2 W<C // working queue for the candidates 3 if extendCandidates // extend candidates by their neighbors 4 foreacheeC 5 for each eas € neighbourhood(e) at layer lc 6 if eaaj € W 7 W<—WUeaaj 8 Wi<@ // queue for the discarded candidates 9 while |W| >0and |R|<M 10 e<extract nearest element from W to q 11 if eis closer to q compared to',\n",
              "  '11 if eis closer to q compared to any element from R 12 R-RUe 13 else 144. Wie WiUe 15 if keepPrunedConnections // add some of the discarded // connections from Wa 16 while |W:|>Oand |R|<M 17. RR U extract nearest element from Wa to q 18 return R Algorithm construction parameters m, and M,,,,9 are responsible for maintaining the small world navigability in the constructed graphs. Setting m, to zero (this corresponds to a single layer in the graph) and M,,,.9 to M leads to production of directed k-NN graphs',\n",
              "  'production of directed k-NN graphs with a power-law search complexity well studied before  (assuming using the alg. 3 for neighbor selection). Setting m, to zero and M,,,,9 to infinity leads to production of NSW graphs with polylogarithmic complexity . Finally, setting m, to some non-zero value leads to emergence of controllable hierarchy graphs which allow logarithmic search complexity by introduction of layers (see the Section 3). To achieve the optimum performance advantage of the controllable',\n",
              "  'advantage of the controllable hierarchy, the overlap between neighbors on different layers (i.e. percent of element neighbors that are also belong to other layers) has to be small. In order to decrease the overlap we need to decrease the m,. However, at the same time, decreasing m, leads to an increase of average hop number during a greedy search on each layer, which negatively affects the performance. This leads to existence of the optimal value for the m, parameter. A simple choice for the optimal m, is',\n",
              "  'choice for the optimal m, is 1/In(W), this corresponds to the skip list parameter p=1/M with an average single element overlap between the layers. Simulations done on an Intel Core i7 5930K CPU show that the proposed selection of m, is a reasonable choice (see Fig. 3 for data on 10M random d=4 vectors). In addition, the plot demonstrates a massive speedup on low dimensional data when increasing the m, from zero and the effect of using the heuristic for selection of the graph connections. It is hard to',\n",
              "  'graph connections. It is hard to expect the same behavior for high dimensional data since in this case the k-NN graph already has Fig. 3. Plots for query time vs m. parameter for 10M random vectors with d=4. The autoselected value 1/In(M) for m, is shown by very short greedy algorithm paths . Surprisingly, increasing the m, from zero leads to a measurable increase in speed on very high dimensional data (100k dense random d=1024 vectors, see plot in Fig. 4), and does not introduce any penalty for the',\n",
              "  'not introduce any penalty for the Hierarchical NSW approach. For real data such as SIFT vectors  (which have complex mixed structure), the performance improvement by increasing the m, is higher, but less prominent at current settings compared to improvement from the heuristic (see Fig. 5 for 1-NN search performance on 5 million 128dimensional SIFT vectors from the learning set of BIGANN ). Selection of the M,,,,) (the maximum number of connections that an element can have in the zero layer) also has a',\n",
              "  'have in the zero layer) also has a strong influence on the search performance, especially in case of high quality (high recall) search. Simulations show that setting M,,,,9 to (this corresponds to kNN graphs on each layer if the neighbors selection heuristic is not used) leads to a very strong performance penalty at high recall. Simulations also suggest that 2.:Mis a good choice for M,,.¢ setting the parameter higher leads to performance degradation and excessive memory usage. In Fig. 6 there are presented',\n",
              "  'In Fig. 6 there are presented results of search performance for the 5M SIFT learn dataset depending on the M,,,,9 parameter (done on an Intel Core i5 2400 CPU). The suggested value gives performance close to optimal at different recalls. Fig. 4. Plots for query time vs m. parameter for 100k random vectors with d=1024. The autoselected value 1/In(M) for m, is naive connection to the nearest neighbors (alg. 3). The effect is the most prominent for low dimensional data, at high recall for mid-dimensional data',\n",
              "  'recall for mid-dimensional data and for the case of highly clustered data (ideologically discontinuity can be regarded as a local low dimensional feature), see the omparison in Fig. 7 (Core i5 2400 CPU). When using the osest neighbors as connections for the proximity graph, the Hierarchical NSW algorithm fails to achieve a high recall for clustered data because the search stucks at the clusters boundaries. Contrary, when the heuristic is used (together with candidates’ extension, line 3 in Alg. 4),',\n",
              "  'extension, line 3 in Alg. 4), clustering leads to even higher performance. For uniform and very high dimensional data there is a little difference between the neighbors selecting methods (see Fig. 4), possibly due to the fact that in this case almost all of the nearest neighbors are selected by the heuristic. The only meaningful construction parameter left for the user is M. A reasonable range of M is from 5 to 48. Simulations show that smaller M generally produces better results for lower recalls and/or',\n",
              "  'results for lower recalls and/or lower dimensional data, while bigger Mis better for high recall and/or high dimensional data (see Fig. 8 for illustration, Core i5 2400 CPU). The parameter also defines the memory consumption of the algorithm (which is proportional to M), so it should be selected with care. Selection of the efConstruction parameter is straightforward. As it was suggested in  it has to be large enough to produce K-ANNS recall close to unity during the construction process (0.95 is enough for',\n",
              "  'process (0.95 is enough for the most usecases). And just like in , this parameter can possibly Fig. 6. Plots for query time vs Mmnaxo parameter for 5M SIFT learn dataset. The autoselected value 2-M for Mmaxo is shown by an arrow. Fig. 7. Effect of the method of neighbor selections (baseline corresponds to alg. 3, heuristic to alg. 4) on clustered (100 random isolated clusters) and non-clustered d=10 random vector data. Fig. 8. Plots for recall error vs query time for different parameters of M for',\n",
              "  'for different parameters of M for Hierarchical NSW on 5M SIFT learn dataset. Build time, minutes Fig. 10. Plots of the query time vs construction time tradeoff for Hierarchical NSW on The construction process can be easily and efficiently parallelized with only few synchronization points (as demonstrated in Fig. 9) and no measurable effect on index quality. Construction speed/index quality tradeoff is controlled via the efConstruction parameter. The tradeoff between the search time and the index',\n",
              "  'the search time and the index construction time is presented in Fig. 10 for a 10M SIFT dataset and shows that a reasonable quality index can be constructed for efConstruction=100 on a 4X 2.4 GHz 10-core Xeon E54650 v2 CPU server in just 3 minutes. Further increase of the efConstruction leads to little extra performance but in exchange of significantly longer construction time. The complexity scaling of a single search can be strictly analyzed under the assumption that we build exact Delaunay graphs instead',\n",
              "  'exact Delaunay graphs instead of the approximate ones. Suppose we have found the closest element on some layer (this is guaranteed by having the Delaunay graph) and then descended to the next layer. One can show that the average number of steps before we find the closest element in the layer is bounded by a constant. Indeed, the layers are not correlated with the spatial positions of the data elements and, thus, when we traverse the graph there is a fixed probability p=exp(-m,) that the next node belongs',\n",
              "  'that the next node belongs to the upper layer. However, the search on the layer always terminates before it reaches the element which belongs to the higher layer (otherwise the search on the upper layer would have stopped on a different element), so the probability of not reaching the target on s-th step is bounded by exp(-s:m,). Thus the expected number of steps in a layer is bounded by a sum of geometric progression S=1/(1-exp(-m,)), which is independent of the dataset size. If we assume that the average',\n",
              "  'If we assume that the average degree of a node in the Delaunay graph is capped by a constant C in the limit of the large dataset (this is the case for random Euclid data , but can be in principle violated in exotic spaces), then the overall average number of distance evaluations in a layer is bounded by a constant C: S, independently of the dataset size. by the construction scales as O(log()), the overall complexity scaling is O(log()), in agreement with the simulations on low dimensional datasets. The',\n",
              "  'on low dimensional datasets. The inital assumption of having the exact Delaunay graph violates in Hierarchical NSW due to usage of approximate edge selection heuristic with a fixed number of neighbors per element. Thus, to avoid stucking into a local minimum the greedy search algorithm employs a backtracking procedure on the zero layer. Simulations show that at least for low dimensional data (Fig. 11, d=4) the dependence of the required ef parameter (which determines the complexity via the minimal number',\n",
              "  'complexity via the minimal number of hops during the backtracking) to get a fixed recall saturates with the rise of the dataset size. The backtracking complexity is an additive term in respect to the final complexity, thus, as follows from the empirical data, inaccuracies of the Delaunay graph approximation do not alter the scaling. Such empirical investigation of the Delaunay graph approximation resilience requires having the average number of Delaunay graph edges independent of the dataset to evidence',\n",
              "  'of the dataset to evidence how well the edges are approximated with a constant number of connections in Hierarchical NSW. However, the average degree of Delaunay graph scales exponentially with the dimensionality ), thus for high dimensional data (e.g. d=128) the aforementioned condition requires having extremely large datasets, making such empricial investigation unfeasible. Further analitical evidence is required to confirm whether the resilience of Delaunay graph aproximations generalizes to higher',\n",
              "  'generalizes to higher dimensional spaces. 4.2.2 Construction complexity The construction is done by iterative insertions of all elements, while the insertion of an element is merely a sequence of K-ANN-searches at different layers with a subsequent use of heuristic (which has fixed complexity at fixed efConstruction). The average number of layers for an element to be added in is a constant that depends on m: The memory consumption of the Hierarchical NSW is mostly defined by the storage of graph',\n",
              "  'defined by the storage of graph connections. The number of connections per element is M,,,,9 for the zero layer and M,,,, for all other layers. Thus, the average memory consumption per element is (Maxot Mm, -M,,,,)-bytes_per_link. If we limit the maximum total number of elements by approximately four billions, we can use four-byte unsigned integers to store the connections. Tests suggest that typical close to optimal WM values usually lie in a range between 6 and 48. This means that the typical memory',\n",
              "  \"This means that the typical memory requirements for the index (excluding the size of the data) are about 60-450 bytes per object, which is in a good agreement with the simulations. The Hierarchical NSW algorithm was implemented in C++ on top of the Non Metric Space Library (nmslib) ', which already had a functional NSW implementation (under name “sw-graph”). Due to several limitations posed by the library, to achieve a better performance, the Hierarchical NSW implementation uses custom distance functions\",\n",
              "  'uses custom distance functions together with C-style memory management, which avoids unnecessary implicit addressing and allows efficient hardware and software prefetching during the graph traversal. Comparing the performance of K-ANNS algorithms is a nontrivial task since the state-of-the-art is constantly changing as new algorithms and implementations are emerging. In this work we concentrated on comparison with the best algorithms in Euclid spaces that have open source implementations. An implementation',\n",
              "  'implementations. An implementation of the Hierarchical NSW algorithm presented in this paper is also distributed as a part of the open source nmslib library’ together with an external C++ memory-efficient headeronly version with support for incremental index construction’. The comparison section consists of four parts: comparison to the baseline NSW (5.1), comparison to the state-ofthe-art algorithms in Euclid spaces (5.2), rerun of the sub- set of tests  in general metric spaces in which NSW failed (5.3)',\n",
              "  'spaces in which NSW failed (5.3) and comparison to state-of-the-art PQalgorithms on a large 200M SIFT dataset (5.4). For the baseline NSW algorithm implementation, we used the “sw-graph” from nmslib 1.1 (which is slightly updated compared to the implementation tested in ) to demonstrate the improvements in speed and algorithmic complexity (measured by the number of distance computations). Fig. 12(a) presents a comparison of Hierarchical NSW to the basic NSW algorithm for d=4 random hypercube data made on a',\n",
              "  'random hypercube data made on a Core i5 2400 CPU (10-NN search). Hierarchical NSW uses much less distance computations during a search on the dataset, especially at high recalls. The scalings of the algorithms on a d=8 random hypercube dataset for a 10-NN search with a fixed recall of 0.95 are presented in Fig. 12(b). It clearly demostrates that Hierarchical NSW has a complexity scaling for this setting not worse than logarithmic and outperforms NSW at any dataset size. The performance advantage in',\n",
              "  'size. The performance advantage in absolute time (Fig. 12(c)) is even higher due to improved algorithm implementaion. 5.2 Comparison in Euclid spaces The main part of the comparison was carried out on vector datasets with use of the popular K-ANNS benchmark ann-benchmark’ as a testbed. The testing system utilizes python bindings of the algorithms — it consequentially runs the K-ANN search for one thousand queries (randomly extracted from the initial dataset) with preset algorithm parameters producing an',\n",
              "  'algorithm parameters producing an output containing recall and average time of a single search. The considered algorithms are: 1. Baseline NSW “sw-graph’). 2. FLANN 1.8.4 . A popular library‘ containing several algorithms, built-in in OpenCV>. We used the available auto-tuning procedure with several reruns to infer the best parameters. 3. Annoy®, 02.02.2016 build. A popular algorithm Fig. 12. Comparison between NSW and Hierarchical NSW: (a) distance calculation number vs accuracy tradeoff for a 10 million',\n",
              "  'accuracy tradeoff for a 10 million 4dimensional random vectors dataset; (b-c) performance scaling in terms of number of distance calculations (b) and raw query(c) time on nmslib 1.1. 5. FALCONN,, version 1.2. A new efficient LSH algorithm for cosine similarity data . The comparison was done on a 4X Xeon E5-4650 v2 Debian OS system with 128 Gb of RAM. For every algorithm we carefully chose the best results at every recall range to evaluate the best possible performance (with initial values from the testbed',\n",
              "  'initial values from the testbed defaults). All tests were done in a single thread regime. Hierarchical NSW was compiled using the GCC 5.3 with -Ofast optimization flag. A recent comparison of algorithms  in general spaces (i.e. non-symmetric or with violation of triangle inequality) showed that the baseline NSW algorithm has severe problems on low dimensional datasets. To test the performance of the Hierarchical NSW algorithm we have repeated a subset of tests from  on which NSW performed poorly or',\n",
              "  'on which NSW performed poorly or suboptimal. For that purpose we used a built-in nmslib testing system which had scripts to run tests from . The evaluated algorithms included the VP-tree, permutation techniques (NAPP and bruteforce filtering) [49, 55-57], the basic NSW algorithm and NNDescent-produced proximity graphs  (both in pair with the NSW graph search algorithm). As in the original tests, for every dataset the test includes the results of ei- memory management were used in this case for',\n",
              "  'were used in this case for Hierarchical NSW leading to some performance loss. The datasets are summarized in Table 2. Further details of the datasets, spaces and algorithm parameter selection can be found in the original work . The bruteorce (BF) time is measured by the nmslib library. The results are presented in Fig. 14. Hierarchical NSW significantly improves the performance of NSW and is a leader for any of the tested datasets. The strongest enhancement over NSW, almost by 3 orders of magnitude is',\n",
              "  'almost by 3 orders of magnitude is observed for the dataset with the lowest dimensionality, the wiki-8 with JS-divergence. This is an important result that demonstrates the robustness of Hierarchical NSW, as or the original NSW this dataset was a stumbling block. Note that for the wiki-8 to nullify the effect of implementation results are presented for the distance computations number instead of the CPU time. against PQ algorithms we used the facebook Faiss library® as the baseline (a new library with',\n",
              "  'the baseline (a new library with state-of-the-art PQ algorithms  implementations, released after the current manuscript was submitted) compiled with the OpenBLAS backend. The tests where done for a 200M subset of 1B SIFT dataset  on a 4X Xeon E5-4650 v2 server with 128Gb of RAM. The ann-benchmark testbed was not feasible for these experiments because of its reliance on 32-bit floating point format (requiring more than 100 Gb just to store the data). To get the results for Faiss PQ algorithms we have',\n",
              "  'for Faiss PQ algorithms we have utilized built-in scripts with the parameters from Faiss wiki’. For the Hierarchical NSW algorithm we used a special build outside of the nmslib with a small memory footprint, simple non-vectorized The results are presented in Fig. 15 with summarization of the parameters in Table 3. The peak memory consumption was measured by using linux “time —v” tool in separate test runs after index construction for both of the algorithms. Even though Hierarchical NSW requires',\n",
              "  'though Hierarchical NSW requires significantly more RAM, it can achieve much higher accuracy, while offering a massive advance in search speed and much faster index construction. By using structure decomposition of navigable small world graphs together with the smart neighbor selection heuristic the proposed Hierarchical NSW approach overcomes several important problems of the basic NSW structure advancing the state-of-the-art in K-ANN search. Hierarchical NSW offers an excellent performance and is a clear',\n",
              "  'performance and is a clear leader on a large variety of the datasets, surpassing the opensource rivals by a large margin in case of high dimensional data. Even for the datasets where the previous algorithm (NSW) has lost by orders of magnitude, Hierarchical NSW was able to come first. Hierarchical NSW supports continuous incremental indexing and can also be used as an efficient method for getting approximations of the k-NN and relative neighborhood graphs, which are byproducts of the index construction.',\n",
              "  'of the index construction. Robustness of the approach is a strong feature which makes it very attractive for practical applications. The algorithm is applicable in generalized metric spaces performing the best on any of the datasets tested in this paper, and thus eliminating the need for complicated selection of the best algorithm for a specific problem. We stress the importance of the algorithm’s robustness since the data may have a complex structure with different effective dimensionality across the',\n",
              "  'dimensionality across the scales. For instance, a dataset can consist of points lying on a curve that randomly fills a high dimensional cube, thus being high dimensional at large scale and low dimensional at small scale. In order to perform efficient search in such datasets an approximate nearest neighbor algorithm has to work well for both cases of high and low dimensionality. There are several ways to further increase the efficiency and applicability of the Hierarchical NSW approach. There is still one',\n",
              "  'NSW approach. There is still one meaningful parameter left which strongly affects the construction of the index — the number of added connections per layer M. Potentially, this parameter can be inferred directly by using different heuristics . It would also be interesting to compare Hierarchical NSW on the full 1B SIFT and 1B DEEP datasets [10-14] and add support for element updates and removal. proach compared to the basic NSW is the loss of the possibility of distributed search. The search in the',\n",
              "  'search. The search in the Hierarchical NSW structure always starts from the top layer, thus the structure cannot be made distributed by using the same techniques as described in  due to cognestion of the higher layer elements. Simple workarounds can be used to distribute the structure, such as partitioning the data across cluster nodes studied in , however in this case, the total parallel throughput of the system does not scale well with the number of computer nodes. Still, there are other possible known',\n",
              "  'there are other possible known ways to make this particular structure distributed. Hierarchical NSW is idelogically very similar to the well-known oneimensional exact search probabilistic skip list structure, nd thus can use the same techniques to make the strucure distributed . Potentially this can lead to even beter distributed performance compared to the base NSW ue to logarithmic scalability and ideally uniform load on e nodes. 4] G. Navarro, \"Searching in metric spaces by spatial approximation,\" The',\n",
              "  'by spatial approximation,\" The VLDB Journal, vol. 11, no. 1, pp. 28-46, 2002. 6] M. Muja and D. G. Lowe, \"Scalable nearest neighbor algorithms for high dimensional data,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 36, no. 11, pp. 2227-2240, 2014. 7] M.E. Houle and M. Nett, \"Rank-based similarity search: Reducing the dimensional dependence,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 37, no. 1, pp. 136-150, 2015. J. Wang, J. Wang, G. Zeng, R. Gan, S. Li,',\n",
              "  'J. Wang, G. Zeng, R. Gan, S. Li, and B. Guo, \"Fast neighborhood graph search using cartesian concatenation,” in Multimedia Data Mining and Analytics: Springer, 2015, pp. 397417. A. Babenko and V. Lempitsky, \"The inverted multi-index,\" in Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Con‘ference on, 2012, pp. 3069-3076: IEEE. H. Jegou, M. Douze, and C. Schmid, \"Product quantization for nearest neighbor search,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 33, no. 1, pp.',\n",
              "  'on, vol. 33, no. 1, pp. 117-128, 2011. A. Babenko and V. Lempitsky, \"Efficient indexing of billionscale datasets of deep descriptors,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 2055-2063. Y. Kalantidis and Y. Avrithis, \"Locally optimized product quantization for approximate nearest neighbor search,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 2321-2328. S. Arya and D. M. Mount, \"Approximate Nearest Neighbor',\n",
              "  '\"Approximate Nearest Neighbor Queries in Fixed Dimensions,\" in SODA, 1993, vol. 93, pp. 271280. J. Wang and S. Li, \"Query-driven iterated neighborhood graph search for large scale indexing,\" in Proceedings of the 20th ACM international conference on Multimedia, 2012, pp. 179-188: ACM. Z. Jiang, L. Xie, X. Deng, W. Xu, and J. Wang, \"Fast Nearest Neighbor Search in the Hamming Space,\" in MultiMedia Modeling, 2016, pp. 325-336: Springer. E. Chavez and E. S. Tellez, \"Navigating k-nearest neighbor graphs to',\n",
              "  'k-nearest neighbor graphs to solve nearest neighbor searches,\" in Advances in Pattern Recognition: Springer, 2010, pp. 270-280. K. Aoyama, K. Saito, H. Sawada, and N. Ueda, \"Fast approximate similarity search based on degree-reduced neighborhood. graphs,\" in Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, 2011, pp. 10551063: ACM. G. Ruiz, E. Chavez, M. Graff, and E. S. Téllez, \"Finding Near Neighbors Through Local Search,\" in Similarity Search and',\n",
              "  'Search,\" in Similarity Search and Applications: Springer, 2015, pp. 103-109. Y. Malkov, A. Ponomarenko, A. Logvinov, and V. Krylov, \"Scalable distributed algorithm for approximate nearest neighbor search problem in high dimensional general metric spaces,\" in Similarity Search and Applications: Springer Berlin Heidelberg, 2012, pp. 132-147. Y. Malkov, A. Ponomarenko, A. Logvinov, and V. Krylov, \"Approximate nearest neighbor algorithm based on navigable small world graphs,\" Information Systems, vol. 45, pp.',\n",
              "  'Information Systems, vol. 45, pp. 61-68, 2014. W. Dong, C. Moses, and K. Li, \"Efficient k-nearest neighbor graph construction for generic similarity measures,\" in Proceedings of the 20th international conference on World wide web, 2011, pp. 577-586: ACM. A. Ponomarenko, Y. Malkov, A. Logvinov, and V. Krylov, \"Approximate Nearest Neighbor Search Small World Approach,” in International Conference on Information and Communication Technologies & Applications, Orlando, Florida, USA, 2011. M. Boguna, D.',\n",
              "  'Florida, USA, 2011. M. Boguna, D. Krioukov, and K. C. Claffy, \"Navigability of complex networks,\" Nature Physics, vol. 5, no. 1, pp. 74-80, 2009. A. Ponomarenko, N. Avrelin, B. Naidan, and L. Boytsov, \"Comparative Analysis of Data Structures for Approximate Nearest Neighbor Search,\" In Proceedings of The Third International Conference on Data Analytics, 2014. B. Naidan, L. Boytsov, and E. Nyberg, \"Permutation search methods are efficient, yet faster search is possible,\" VLDB Procedings, vol. 8, no. 12, pp.',\n",
              "  'Procedings, vol. 8, no. 12, pp. 1618-1629, 2015. Y. Lifshits and S. Zhang, \"Combinatorial algorithms for nearest neighbors, near-duplicates and small-world design,\" in Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms, 2009, pp. 318-326: Society for Industrial and Applied Mathematics. O. Beaumont, A.-M. Kermarrec, and E. Riviere, \"Peer to peer multidimensional overlays: Approximating complex structures,\" in Principles of Distributed Systems: Springer, 2007, pp. 315-328. O.',\n",
              "  'Springer, 2007, pp. 315-328. O. Beaumont, A.-M. Kermarrec, L. Marchal, and E. Riviére, \"VoroNet: A scalable object network based on Voronoi tessellations,\" in Parallel and Distributed Processing Symposium, 2007. IPDPS 2007. IEEE International, 2007, pp. 1-10: IEEE. J. Kleinberg, \"The small-world phenomenon: An algorithmic perspective,\" in Proceedings of the thirty-second annual ACM symposium on Theory of computing, 2000, pp. 163-170: ACM. D. J. Watts and S. H. Strogatz, \"Collective dynamics of',\n",
              "  'Strogatz, \"Collective dynamics of ‘smallworld’networks,\" Nature, vol. 393, no. 6684, pp. 440-442, 1998. Y. A. Malkov and A. Ponomarenko, \"Growing homophilic networks are natural navigable small worlds,\" PloS one, p. e0158162, 2016. M. T. Goodrich, M. J. Nelson, and J. Z. Sun, \"The rainbow skip graph: a fault-tolerant constant-degree distributed data structure,\" in Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm, 2006, pp. 384-393: Society for Industrial and Applied',\n",
              "  'Society for Industrial and Applied Mathematics. E. C. Gonzalez, K. Figueroa, and G. Navarro, \"Effective proximity retrieval by ordering permutations,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 30, no. 9, pp. 1647-1658, 2008. E. S. Tellez, E. Chavez, and G. Navarro, \"Succinct nearest neighbor search,” Information Systems, vol. 38, no. 7, pp. 10191030, 2013. C. Beecks, \"Distance-based similarity models for content-based multimedia _retrieval,\". Hochschulbibliothek der',\n",
              "  \"Hochschulbibliothek der RheinischWestfalischen Technischen Hochschule Aachen, 2013. author of 20+ papers on physics and computer science. Yury currently occupies a position of a Project Leader in Samsung Al Center in Moscow. His current research interests include deep learning, scalable similarity search, biological and Dmitry A. Yashunin received a Master's degree in physics from Nizhny Novgorod State University in 2009, and a PhD degree in laser physics from the Institute of Applied Physics RAS in 2015.\",\n",
              "  'of Applied Physics RAS in 2015. From 2008 to 2012 he was working in Mera Networks. He is author of 10+ papers on physics. Dmitry currently woks at Intelli-Vision in the posi-'],\n",
              " 'ivfpq': ['Article in IEEE Transactions on Pattern Analysis and Machine Intelligence January 2011 Abstract— This paper introduces a product quantization based approach for approximate nearest neighbor search. The idea is to decomposes the space into a Cartesian product of low dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices. The Euclidean distance between two vectors can be efficiently estimated from their codes. An',\n",
              "  'estimated from their codes. An asymmetric version increases precision, as it computes the approximate distance between a vector and a code. Experimental results show that our approach searches for nearest neighbors efficiently, in particular in combination with an inverted file system. Results for SIFT and GIST image descriptors show excellent search accuracy outperforming three state-of-the-art approaches. The scalability of our approach is validated on a dataset of two billion vectors. Index Terms—',\n",
              "  'two billion vectors. Index Terms— High-dimensional indexing, image indexing, very large databases, approximate search. Computing Euclidean distances between high dimensional vectors is a fundamental requirement in many applications. It is used, in particular, for nearest neighbor (NN) search. Nearest neighbor search is inherently expensive due to the curse of dimensionality , . Focusing on the D-dimensional Euclidean space R?, the problem is to find the element NN(z), in a finite set Y C R® of n vectors,',\n",
              "  'a finite set Y C R® of n vectors, minimizing the distance to the query vector « € R? : Several multi-dimensional indexing methods, such as the popular KD-tree  or other branch and bound techniques, have been proposed to reduce the search time. However, for high dimensions it turns out  that such approaches are not more efficient than the bruteforce exhaustive distance calculation, whose complexity is O(nD). There is a large body of literature , ,  on algorithms that overcome this issue by performing',\n",
              "  'overcome this issue by performing approximate nearest neighbor (ANN) search. The key idea This work was partly realized as part of the Quaero Programme, funded by OSEO, French State agency for innovation. It was originally published as a technical report  in August 2009. It is also related to the work  on source coding for nearest neighbor search. shared by these algorithms is to find the NN with high probability “only”, instead of probability 1. Most of the effort has been devoted to the Euclidean',\n",
              "  'has been devoted to the Euclidean distance, though recent generalizations have been proposed for other metrics . In this paper, we consider the Euclidean distance, which is relevant for many applications. In this case, one of the most popular ANN algorithms is the Euclidean Locality-Sensitive Hashing (E2LSH) , , which provides theoretical guarantees on the search quality with limited assumptions. It has been successfully used for local descriptors  and 3D object indexing , . However, for real data, LSH is',\n",
              "  ', . However, for real data, LSH is outperformed by heuristic methods, which exploit the distribution of the vectors. These methods include randomized KD-trees  and hierarchical k-means , both of which are implemented in the FLANN selection algorithm . ANN algorithms are typically compared based on the trade-off between search quality and efficiency. However, this trade-off does not take into account the memory requirements of the indexing structure. In the case of E2LSH, the memory usage may even be higher',\n",
              "  'memory usage may even be higher than that of the original vectors. Moreover, both E2LSH and FLANN need to perform a final re-ranking step based on exact L2 distances, which requires the indexed vectors to be stored in main memory if access speed is important. This constraint seriously limits the number of vectors that can be handled by these algorithms. Only recently, researchers came up with methods limiting the memory usage. This is a key criterion for problems involving large amounts of data , ie., in',\n",
              "  'large amounts of data , ie., in large-scale scene recognition , where millions to billions of images have to be indexed. In , Torralba et al. represent an image by a single global GIST descriptor  which is mapped to a short binary code. When no supervision is used, this mapping is learned such that the neighborhood in the embedded space defined by the Hamming distance reflects the neighborhood in the Euclidean space of the original features. The search of the Euclidean nearest neighbors is then',\n",
              "  'nearest neighbors is then approximated by the search of the nearest neighbors in terms of Hamming distances between codes. In , spectral hashing (SH) is shown to outperform the binary codes generated by the restricted Boltzmann machine , boosting and LSH. In this paper, we construct short codes using quantization. The goal is to estimate distances using vectorto-centroid distances, i.e., the query vector is not quantized, codes are assigned to the database vectors only. This reduces the quantization noise',\n",
              "  'reduces the quantization noise and subsequently improves the search quality. To obtain precise distances, the quantization error must be limited. Therefore, the total number k of centroids should be sufficiently large, eg. k= 2%4 for 64-bit codes. This raises several issues on how to learn the codebook and assign a vector. First, the number of samples required to learn the quantizer is huge, i.e., several times k. Second, the complexity of the algorithm itself is prohibitive. Finally, the amount of',\n",
              "  'Finally, the amount of computer memory available on Earth is not sufficient to store the floating point values representing the centroids. The hierarchical k-means see (HKM) improves the efficiency of the learning stage and of the corresponding assignment procedure . However, the aforementioned limitations still apply, in particular with respect to memory usage and size of the learning set. Another possibility are scalar quantizers, but they offer poor quantization error properties in terms of the',\n",
              "  'error properties in terms of the trade-off between memory and reconstruction error. Lattice quantizers offer better quantization properties for uniform vector distributions, but this condition is rarely satisfied by real world vectors. In practice, these quantizers perform significantly worse than k-means in indexing tasks . In this paper, we focus on product quantizers. To our knowledge, such a semi-structured quantizer has never been considered in any nearest neighbor search method. The advantages of our',\n",
              "  'method. The advantages of our method are twofold. First, the number of possible distances is significantly higher than for competing Hamming embedding methods , , , as the Hamming space used in these techniques allows for a few distinct distances only. Second, as a byproduct of the method, we get an estimation of the expected squared distance, which is required for e-radius search or for using Lowe’s distance ratio criterion . The motivation of using the Hamming space in , ,  is to compute distances',\n",
              "  'in , ,  is to compute distances efficiently. Note, however, that one of the fastest ways to compute Hamming distances consists in using table lookups. Our method uses a similar number of table lookups, resulting in comparable efficiency. Our paper is organized as follows. Section II introduces the notations for quantization as well as the product quantizer used by our method. Section III presents our approach for NN search and Section IV introduces the structure used to avoid exhaustive search. An',\n",
              "  'to avoid exhaustive search. An evaluation of the parameters of our approach and a comparison with the state of the art is given in Section V. Quantization is a destructive process which has been extensively studied in information theory . Its purpose is to reduce the cardinality of the representation space, in particular when the input data is real-valued. Formally, a quantizer is a function g mapping a Ddimensional vector « € R? to a vector q(x) € C = {ci;i © Z}, where the index set Z is from now on',\n",
              "  'the index set Z is from now on assumed to be finite: Z = 0... — 1. The reproduction values c; are called centroids. The set of reproduction values C is the codebook of size k. The Lloyd quantizer, which corresponds to the kmeans clustering algorithm, finds a near-optimal codebook by iteratively assigning the vectors of a training set to centroids and re-estimating these centroids from the assigned vectors. In the following, we assume that the two Lloyd conditions hold, as we learn the quantizer using',\n",
              "  'as we learn the quantizer using k-means. Note, however, that k-means does only find a local optimum in terms of quantization error. cae) =— [ daaa)) rade. i Sy, Note that the MSE can be obtained from these quantities as MSE(q) = )> pi €(;¢)1) ieL The memory cost of storing the index value, without any further processing (entropy coding), is [log, k] bits. Therefore, it is convenient to use a power of two for k, as the code produced by the quantizer is stored in a binary memory. the SIFT descriptor . A',\n",
              "  'memory. the SIFT descriptor . A quantizer producing 64bits codes, i.e., “only” 0.5 bit per component, contains Storing the codebook C explicitly is not efficient. Instead, we store the m x k* centroids of all the subquantizers, i.e., mD* k* = k* D floating points values. Quantizing an element requires k*D floating point operations. Table I summarizes the resource requirements associated with k-means, HKM and product k-means. The product quantizer is clearly the the only one that can be indexed in memory',\n",
              "  'one that can be indexed in memory for large values of k. In order to provide good quantization properties when choosing a constant value of k*, each subvector should have, on average, a comparable energy. One way to ensure this property is to multiply the vector by a random orthogonal matrix prior to quantization. However, for most vector types this is not required and not recommended, as consecutive components are often correlated by construction and are better quantized together with the same',\n",
              "  'quantized together with the same subquantizer. As the subspaces are orthogonal, the squared distortion associated with the product quantizer is where MSE(q;) is the distortion associated with quantizer q;. Figure 1 shows the MSE as a function of the code length for different (m,k*) tuples, where the code length is 1 = mlog,k*, if k* is a power of two. The curves are obtained for a set of 128-dimensional SIFT descriptors, see section V for details. One can observe that for a fixed number of bits, it is',\n",
              "  'for a fixed number of bits, it is better to use a small number of subquantizers with many centroids than having many subquantizers with few bits. At the extreme when m = 1, the product quantizer becomes a regular k-means codebook. 0.3 T T T m=1 —+— m=2 ---x--0.25 + m=4 --o-J m=8 --4 i= m=16 ---&-OG 02 4 < fe} 2 3 0.15 4 3 2 S$ O17 4 B 0.05 + aoe 4 > a . 1 y 0 16 32 64 96 128 160 Fig. 2. Illustration of the symmetric and asymmetric distance computation. The distance d(x, y) is estimated with either the',\n",
              "  'y) is estimated with either the distance d(q(x),q(y)) (left) or the distance d(x,q(y)) (right). The mean squared error on the distance is on average bounded by the quantization error. Nearest neighbor search depends on the distances between the query vector and the database vectors, or equivalently the squared distances. The method introduced in this section compares the vectors based on their quantization indices, in the spirit of source coding techniques. We first explain how the product quantizer',\n",
              "  'explain how the product quantizer properties are used to compute the distances. Then we provide a statistical bound on the distance estimation error, and propose a refined estimator for the squared Euclidean distance. Symmetric distance computation (SDC): both the vectors x and y are represented by their respective centroids q(x) and q(y). The distance d(x, y) is approximated by the distance d(x, y) * d(q(x),q(y)) which is efficiently obtained using a product quantizer As shown later in this subsection,',\n",
              "  'As shown later in this subsection, using the estimations d or d leads to underestimate, on average, the distance between descriptors. Figure 3 shows the distances obtained when querying a SIFT descriptor in a dataset of 1000 SIFT vectors. It compares the true distance against the estimates computed with Equations 12 and 13. One can clearly see the bias on these distance estimators. Unsurprisingly, the symmetric version is more sensitive to this bias. Discussion: Figure 4 illustrates the probability',\n",
              "  '4 illustrates the probability distribution function of the difference between the true distance and the ones estimated by Equations 13 and 25. It has been measured on a large set of SIFT descriptors. The bias of the distance estimation by Equation 13 is significantly reduced in the corrected version. However, we observe that correcting the bias leads, in this case, to a higher variance of the estimator, which is a common phenomenon in statistics. Moreover, for the nearest neighbors, the correcting term is',\n",
              "  'neighbors, the correcting term is likely to be higher 0 Ts. L -0.3 -0.2 -0.1 0 0.1 0.2 0.3 difference: estimator d(x,y) In our experiments, we observe that the correction returns inferior results on average. Therefore, we advocate the use of Equation 13 for the nearest neighbor search. The corrected version is useful only if we are interested in the distances themselves. Approximate nearest neighbor search with product quantizers is fast (only m additions are required per distance calculation) and reduces',\n",
              "  'distance calculation) and reduces significantly the memory requirements for storing the descriptors. Nevertheless, the search is exhaustive. The method remains scalable in the context of a global image description , . However, if each image is described by a set of local descriptors, an exhaustive search is prohibitive, as we need to index billions of descriptors and to perform multiple queries . To avoid exhaustive search we combine an inverted file system  with the asymmetric distance computation',\n",
              "  'asymmetric distance computation (IVFADC). An inverted file quantizes the descriptors and stores image indices in the corresponding lists, see the step “coarse quantizer” in Figure 5. This allows rapid access to a small fraction of image indices and was shown successful for very large scale search . Instead of storing an image index only, we add a small code for each descriptor, as first done in . Here, we encode the difference between the vector and its Similar to the “Video-Google” approach , a codebook',\n",
              "  'approach , a codebook is learned using k-means, producing a quantizer qc, referred to as the coarse quantizer in the following. For SIFT descriptors, the number k’ of centroids associated with gq typically ranges from k’ = 1000 to k’ = 1000 000. It is therefore small compared to that of the product quantizers used in Section III. G > ac(y) + aly — aely))9) Denoting by 9p; the 7\" subquantizer, we use the following decomposition to compute this estimator efficiently: ; G1) Similar to the ADC strategy, for',\n",
              "  'Similar to the ADC strategy, for each subquantizer pj the distances between the partial residual vector uj (a qe(y)) and all the centroids c;,; of Gp, are preliminarily computed and stored. address this problem, we use the multiple assignment strategy of . The query x is assigned to w indexes instead of only one, which correspond to the w nearest neighbors of x in the codebook of qc. All the corresponding inverted lists are scanned. Multiple assignment is not applied to database vectors, as this would',\n",
              "  'to database vectors, as this would increase the memory usage. 4) add a new entry to the inverted list corresponding to g-(y). It contains the vector (or image) identifier and the binary code (the product quantizer’s indexes). Searching the nearest neighbor(s) of a query x consists of 1) quantize x to its w nearest neighbors in the codebook q; with these w assignments. The two steps are applied to all w assignments. 4) select the K nearest neighbors of x based on the estimated distances. This is implemented',\n",
              "  'distances. This is implemented efficiently by maintaining a Maxheap structure of fixed capacity, that stores the AK smallest values seen so far. After each distance calculation, the point identifier is added to the structure only if its distance is below the largest distance in the Maxheap. Only Step 3 depends on the database size. Compared with ADC, the additional step of quantizing x to g-(x) consists in computing k’ distances between Ddimensional vectors. Assuming that the inverted lists are balanced,',\n",
              "  'the inverted lists are balanced, about n x w/k’ entries have to be parsed. Therefore, the search is significantly faster than ADC, as shown in the next section. In this section, we first present the datasets used for the evaluation’. We then analyze the impact of the parameters for SDC, ADC and IVFADC. Our approach is compared to three state-of-the-art methods: spectral hashing , Hamming embedding  and FLANN . Finally, we evaluate the complexity and speed of our approach. The search quality is measured',\n",
              "  'The search quality is measured with recall@ R, ie., the proportion of query vectors for which the nearest neighbor is ranked in the first R positions. This measure indicates the fraction of queries for which the nearest neighbor is retrieved correctly, if a short-list of R vectors is verified using Euclidean distances. Furthermore, the curve obtained by varying R corresponds to the distribution function of the ranks, and the point R=1 corresponds to the “precision” measure used in  to evaluate ANN methods.',\n",
              "  'used in  to evaluate ANN methods. As expected, the asymmetric estimator ADC significantly outperforms SDC. For m=8 we obtain the same accuracy for ADC and k*=64 as for SDC and k*=256. Given that the efficiency of the two approaches is equivalent, we advocate not to quantize the query when possible, but only the database elements. 1 ; — 0.8 + 6 4 S o6F xo 4 5 bid 8 o4b x JKet6 | i¢ 1! m=1 —+— O2x! no J fs m=16 —--— 0 \\\\ L L L n 0 16 32 64 96 128 160 code length (bits) Fig. 6. SDC and ADC estimators evaluated',\n",
              "  'SDC and ADC estimators evaluated on the SIFT dataset: recall@100 as a function of the memory usage (code length=m x log, k*) for different parameters (k*=16,64,256,...,4096 and m=1,2,4,8,16). The missing point (m=16,k*=4096) gives recall@100=1 for both SDC and ADC. 0.20 L 1 L 0 16 32 64 96 128 code length (bits) This approach is significantly more efficient than SDC and ADC on large datasets, as it only compares the query to a small fraction of the database vectors. The proportion of the dataset to visit',\n",
              "  'proportion of the dataset to visit is roughly linear in w/k’. For a fixed proportion, it is worth using higher values of k’, as this increases the accuracy, as shown by comparing, for the tuple (m,w), the parameters (1024, 1) against (8192, 8) and (1024, 8) against (8192, 64). The natural order corresponds to grouping consecutive components, as proposed in Equation 8. For the SIFT descriptor, this means that histograms of neighboring grid cells are quantized together. GIST descriptors are composed of three',\n",
              "  'descriptors are composed of three 320-dimension blocks, one per color channel. The product quantizer splits these blocks into parts. The “structured” order consists in grouping together dimensions that are related. For the m = 4 SIFT quantizer, this means that the 4x 4 patch cells that make up the descriptor  are grouped into 4 2 x 2 blocks. For the other two, it groups together dimensions that have have the same index modulo 8. The orientation histograms of SIFT and most of GIST’s have 8 bins, so this',\n",
              "  'of GIST’s have 8 bins, so this ordering quantizes together bins corresponding to the same orientation. On SIFT descriptors, this is a slightly less efficient structure, probably because the natural order corresponds to spatially related components. On GIST, this choice significantly improves the performance. Therefore, we use this ordering in the following experiments. Discussion: A method that automatically groups the components could further improve the results. This seems particularly important if we',\n",
              "  'seems particularly important if we have no prior knowledge about the relationship between the components as in the case of bag-of-features. A possible solution is the minimum sum-squared residue co-clustering  algorithm. Comparison with Hamming embedding methods: We compare our approach to spectral hashing (SH) , which maps vectors to binary signatures. The search consists in comparing the Hamming distances between the database signatures and the query vector signature. This approach was shown to',\n",
              "  'This approach was shown to outperform the restricted Boltzmann machine of . We have used the publicly available code. We also compare to the Hamming embedding (HE) method of , which also maps vectors to binary signatures. Similar to IVFADC, HE uses an inverted file, which avoids comparing to all the database elements. . — —— oor = 0.8 4 xc 06 5 © @ § 2 04 sDC —— 4 ADC ---x--IVFADC w=1 ° 0.2 IVFADC w=16 ~~ J . HE w=1 ---&-HE w=16 . 0 f j f spectral hashing, 1 10 100 1k 10k 100k 1M R Fig. 8. | SIFT dataset:',\n",
              "  '100k 1M R Fig. 8. | SIFT dataset: recall@R for varying values of R. Com- 1 === 0.8 4 c 06 4 g g 2 04 4 sDC —— ADC ---x--02 IVFADC w=1 ---0--. IVFADC w=8 © IVFADC w=64 ---&-0 ke spectral hashing ate, aieeal 1 10 100 1k 10k 100k 1M Fig. 9. GIST dataset: recall@R for varying values of R. Comparison of the different approaches SDC, ADC, IVFADC and spectral hashing . We have used m=8, k*=256 for SDC/ADC and k’ = 1024 for IVFADC. Comparison with FLANN: The approximate nearestneighbor search technique of Muja &',\n",
              "  'search technique of Muja & Lowe  is based on hierarchical structures (KD-trees and hierarchical kmeans trees). The software package FLANN automatically selects the best algorithm and parameters for a given dataset. In contrast with our method and spectral hashing, all vectors need to remain in RAM as the method includes a re-ranking stage that computes the real distances for the candidate nearest neighbors. For the sake of comparison with FLANN, we added a verification stage to our IVFADC method: IVFADC',\n",
              "  'stage to our IVFADC method: IVFADC queries return a shortlist of R candidate nearest neighbors using the distance estimation. The vectors in the shortlist are re-ordered using the real distance, as done in , , and the closest one is returned. Note that, in this experimental setup, all the vectors are stored in main memory. This requirement seriously limits the scale on which re-ordering can be used. The IVFADC and FLANN methods are both evaluated at different operating points with respect to precision and',\n",
              "  'with respect to precision and search time. For FLANN, the different operating points are obtained with parameters generated automatically for various target precisions. For IVFADC, they are obtained by varying the number k’ of coarse centroids, the number w of assignments and the short-list size R. The product quantizer is generated using k*=256 and m=8, ie., 64bit codes. This choice is probably not optimal for all operating points. Table V reports the search time of our methods. For reference, we report',\n",
              "  'methods. For reference, we report the results obtained with the spectral hashing algorithm of  on the same dataset and machine (using only one core). Since we use a separate learning set, we use the out-of-sample evaluation of this algorithm. Note that for SH we have reimplemented the Hamming distance computation in C 100 F FLANN ‘ \"74 IVFADC, R=10— + IVFADC, R=100 x IVFADC, R=1000—* 16/128 % > 16/1024] cS 16/128 o £ a 16/1024 = 10f eo * 2 ——— 4/128 oO 3 4/1024 +4/1024 1 L 1 1 L 1 1 L 06 #065 O7 O75 O08',\n",
              "  '1 L 1 1 L 1 1 L 06 #065 O7 O75 O08 085 09 0.95 1 1-recall at 1 Fig. 10. IVFADC vs FLANN: trade-offs between search quality To evaluate the search efficiency of the product quantizer method on larger datasets we extracted about 2 billion SIFT descriptors from one million images. Search is performed with 30000 query descriptors from ten images. We compared the IVFADC and HE methods with similar parameters. In particular, the amount of memory that is scanned for each method and the cost of the coarse',\n",
              "  'method and the cost of the coarse quantization are the same. The query times per descriptor are shown on Figure 11. The cost of the extra quantization step required by IVFADC appears clearly for small database sizes. For larger scales, the distance computation with the database vectors become preponderant. The processing that is applied to each element of the inverted lists is 3.5 T 0.8 T T HE —+— x IVF+HE 64 bits —+ 3 IVFADC ---x--f 0.754 IVFADC 64 bits (m=8) ---<--] _ r é 7 . IVF+HE 32 bits ---*--5',\n",
              "  '_ r é 7 . IVF+HE 32 bits ---*--5 IVFADC 32 bits (m=4) 5 So 25h 4 Orr 8 . s 0.65 ey | & os E 15> q E S 0.55 o If 4 nw 0.5 i 0.5 | 0.45 + 7 0 : 0.4 : ; 10M 100M 1G 1k 10k 100k 1M database size database size (number of images) Fig. 11. Search times for SIFT descriptors in datasets of increasing Fig. 12. Comparison of IVFADC and the Hamming Embedding We have evaluated our method within an image search system based on local descriptors. For this evaluation, we compare our method with the HE method of  on the',\n",
              "  'with the HE method of  on the INRIA Holidays dataset, using the pre-processed set of descriptors available online. The comparison is focused on large scale indexing, i.e., we do not consider the impact of a post-verification step ,  or geometrical We have introduced product quantization for approximate nearest neighbor search. Our compact coding scheme provides an accurate approximation of the Euclidean distance. Moreover, it is combined with an inverted file system to avoid exhaustive search, resulting in',\n",
              "  'exhaustive search, resulting in high efficiency. Our approach significantly outperforms the state of the art in terms of the trade-off between search quality and memory usage. Experimental results for SIFT and GIST image descriptors are excellent and show that grouping the components based on our prior knowledge of the descriptor design further improves the results. The scalability of our approach is validated on a dataset of two billion vectors. H. Jégou, M. Douze, and C. Schmid, “Searching with',\n",
              "  'and C. Schmid, “Searching with quantization: approximate nearest neighbor search using short codes and distance estimators,” Tech. Rep. RR-7020, INRIA, August 2009. C. Béhm, S. Berchtold, and D. Keim, “Searching in highdimensional spaces: Index structures for improving the performance of multimedia databases,” ACM Computing Surveys, vol. 33, pp. 322-373, October 2001. J. Friedman, J. L. Bentley, and R. A. Finkel, “An algorithm for finding best matches in logarithmic expected time,” ACM Transaction on',\n",
              "  'expected time,” ACM Transaction on Mathematical Software, vol. 3, no. 3, pp. 209226, 1977. R. Weber, H.-J. Schek, and S. Blott, “A quantitative analysis and performance study for similarity-search methods in highdimensional spaces,” in Proceedings of the International Conference on Very Large DataBases, pp. 194-205, 1998. M. Datar, N. Immorlica, P. Indyk, and V. Mirrokni, “Localitysensitive hashing scheme based on p-stable distributions,” in Proceedings of the Symposium on Computational Geometry, pp.',\n",
              "  'on Computational Geometry, pp. 253-262, 2004. B. Kulis and K. Grauman, “Kernelized locality-sensitive hashing for scalable image search,” in Proceedings of the International Conference on Computer Vision, October 2009. Y. Ke, R. Sukthankar, and L. Huston, “Efficient near-duplicate detection and sub-image retrieval,” in ACM International conference on Multimedia, pp. 869-876, 2004. B. Matei, Y. Shan, H. Sawhney, Y. Tan, R. Kumar, D. Huber, and M. Hebert, “Rapid object indexing using locality sensitive',\n",
              "  'indexing using locality sensitive hashing and joint 3D-signature space estimation,’ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, pp. 1111 — 1126, July 2006. C. Silpa-Anan and R. Hartley, “Optimized kd-trees for fast image descriptor matching,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2008. D. Nistér and H. Stewénius, “Scalable recognition with a vocabulary tree,” in Proceedings of the IEEE Conference on Computer Vision and Pattern',\n",
              "  'on Computer Vision and Pattern Recognition, pp. 2161-2168, 2006. A. Torralba, R. Fergus, and W. T. Freeman, “80 million tiny images: a large database for non-parametric object and scene recognition,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, pp. 1958-1970, November 2008. A. Torralba, R. Fergus, and Y. Weiss, “Small codes and large databases for recognition,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2008. D. Lowe, “Distinctive image',\n",
              "  '2008. D. Lowe, “Distinctive image features from scale-invariant keypoints,” International Journal of Computer Vision, vol. 60, no. 2, pp. 91-110, 2004. R. M. Gray and D. L. Neuhoff, “Quantization,” IEEE Transactions on Information Theory, vol. 44, pp. 2325-2384, Oct. 1998. H. Jégou, H. Harzallah, and C. Schmid, “A contextual dissimilarity measure for accurate and efficient image search,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2007. H. Cho, I. Dhillon, Y. Guan, and',\n",
              "  'H. Cho, I. Dhillon, Y. Guan, and S. Sra, “Minimum sumsquared residue co-clustering of gene expression data,” in SIAM International Conference on Data Mining, pp. 114-125, April 2004. J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman, “Object retrieval with large vocabularies and fast spatial matching,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2007.']}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunked_files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e710a40-19b0-4957-89a6-30eaba4085d0",
      "metadata": {
        "id": "3e710a40-19b0-4957-89a6-30eaba4085d0"
      },
      "source": [
        "# Create Dense Embeddings of our Chunks\n",
        "\n",
        "Hybrid search needs both dense embeddings and sparse embeddings of the same content in order to work. Let's start with dense embeddings.\n",
        "\n",
        "We'll use the `'all-MiniLM-L12-v2'` [model](https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2) hosted by HuggingFace to create our dense embeddings. It's currently high on their [MTEB (Massive Text Embedding Benchmark) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) (Reranking section), so it's a pretty safe bet. This will output dense vectors of 384 dimensions.\n",
        "\n",
        "Note: if you're playing around with this notebook, make sure to save your chunks and embeddings (both sparse and dense) in `pkl` [files](https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict-or-any-other-python-object), so that you don't have to wait for the embeddings to generate again if you want to rerun any steps in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "079ab428-d7d5-4aab-8ed3-e05408a5bfe3",
      "metadata": {
        "id": "079ab428-d7d5-4aab-8ed3-e05408a5bfe3"
      },
      "source": [
        "We'll have to create a dense embedding of each of our PDFs' chunks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3984fa37-32e3-43f3-9b97-b0013497a88e",
      "metadata": {
        "id": "3984fa37-32e3-43f3-9b97-b0013497a88e"
      },
      "outputs": [],
      "source": [
        "def produce_embeddings(chunks: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Produce dense embeddings for each chunk.\n",
        "\n",
        "    :param chunks: The chunks we want to create dense embeddings of.\n",
        "\n",
        "    :return: Dense embeddings produced by our SentenceTransformer model `all-MiniLM-L12-v2`.\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "    embeddings = []\n",
        "    for c in chunks:\n",
        "        embedding = model.encode(c)\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836ae697-df61-435f-b6da-093b0151e7b1",
      "metadata": {
        "id": "836ae697-df61-435f-b6da-093b0151e7b1"
      },
      "outputs": [],
      "source": [
        "freshdisk_dembeddings = produce_embeddings(chunked_files.get('freshdisk'))  # these take ~30s min to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8bb67f-2b95-48f6-bbfa-ed3bd40a1574",
      "metadata": {
        "id": "7f8bb67f-2b95-48f6-bbfa-ed3bd40a1574"
      },
      "outputs": [],
      "source": [
        "hnsw_dembeddings = produce_embeddings(chunked_files.get('hnsw'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc992bc7-6c15-43e9-a88f-1f70412ea90c",
      "metadata": {
        "id": "fc992bc7-6c15-43e9-a88f-1f70412ea90c"
      },
      "outputs": [],
      "source": [
        "ivfpq_dembeddings = produce_embeddings(chunked_files.get('ivfpq'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe90755-9203-45e1-a47b-51bedff337e1",
      "metadata": {
        "id": "1fe90755-9203-45e1-a47b-51bedff337e1"
      },
      "outputs": [],
      "source": [
        "# We can confirm the shape of each our dense embeddings is 384:\n",
        "\n",
        "# Make binary lists to keep track of any shapes that are *not* 384\n",
        "freshdisk_assertion = [0 for i in freshdisk_dembeddings if i.shape == 384]\n",
        "hnsw_assertion = [0 for i in hnsw_dembeddings if i.shape == 384]\n",
        "ivfpq_assertion = [0 for i in ivfpq_dembeddings if i.shape == 384]\n",
        "\n",
        "# Sum up our lists. If there are any embeddings that are not of shape 384, these sums will be > 0\n",
        "assert sum(freshdisk_assertion) == 0\n",
        "assert sum(hnsw_assertion) == 0\n",
        "assert sum(ivfpq_assertion) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cffb7427-6db0-42c4-ba3e-b589edadd3e2",
      "metadata": {
        "id": "cffb7427-6db0-42c4-ba3e-b589edadd3e2"
      },
      "source": [
        "# Create Sparse Embeddings of our Chunks\n",
        "\n",
        "Now we can create our sparse embeddings. We will use the BM25 algorithm to create our sparse embeddings. The resulting vector will represent an inverted index of the tokens in our chunks, constrained by things like chunk length.\n",
        "\n",
        "Pinecone has an awesome [text library](https://github.com/pinecone-io/pinecone-text) that makes generating these vectors super easy. We also have [a great notebook](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/search/semantic-search/sparse/bm25/bm25-vector-generation.ipynb) all about BM25 encodings.\n",
        "\n",
        "Since we're using a ML-implemented version of BM25, we need to \"fit\" the model to our corpus. To do this, we'll combine all 3 of our PDFs together, so that the BM25 model can compute all the token frequencies etc correctly. We'll then encode each of our documents with our \"fitted\" model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa80a1a-bea3-4d49-90cc-33206e604899",
      "metadata": {
        "id": "2aa80a1a-bea3-4d49-90cc-33206e604899"
      },
      "outputs": [],
      "source": [
        "# Join the content of all our PDFs together into 1 large corpus\n",
        "\n",
        "corpus = \"\"\n",
        "\n",
        "for i, v in chunked_files.items():\n",
        "    corpus += ' '.join(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6c477c-df4a-4b78-b0a6-421527650000",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa6c477c-df4a-4b78-b0a6-421527650000",
        "outputId": "6440d46b-e6b8-40fe-b01f-b29e7f1398ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "127590"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(corpus)  # Awesome, we've got lots o' tokens here for our BM25 model to learn :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f124295c-9da5-4195-a57f-1a53f2feb842",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "46cb7f93a5b3418299de049a988f1ca1",
            "c0bdc65bb5ba4188a8d37bbf680c9a6b",
            "95d42387ac474e2ca20c324354e7278a",
            "ded84f36e8f448a288f9a6f66779dee1",
            "ffd326f46dd649ec90f2a3fcce8e861b",
            "2ede41088b81418b8f46393063355852",
            "869e80bfc8de4f4d8a7760e950fc8bb1",
            "1d8c818e1f544b54a4532b6e45dc558f",
            "7b3a4f088c864ca089a073e7226f9683",
            "e165b164b89a4f64868c5aef9f3d9a4c",
            "02581d3f611c4d6695fdc5e80a6a2aa5"
          ]
        },
        "id": "f124295c-9da5-4195-a57f-1a53f2feb842",
        "outputId": "63e8db06-c298-4544-ff46-016fbeae4da0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127590/127590 [00:21<00:00, 5937.15it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x7fdd4434fb20>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize BM25 and fit to our corpus\n",
        "\n",
        "bm25 = BM25Encoder()\n",
        "bm25.fit(corpus)  # takes ~30s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b2ca25-2ac4-4712-bd8d-77607ef9c852",
      "metadata": {
        "id": "73b2ca25-2ac4-4712-bd8d-77607ef9c852"
      },
      "outputs": [],
      "source": [
        "# Create embeddings for each chunk\n",
        "freshdisk_sembeddings = [bm25.encode_documents(i) for i in chunked_files.get('freshdisk')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b1c9f3-9192-4e46-afa2-6b4e93ebb6a0",
      "metadata": {
        "id": "e4b1c9f3-9192-4e46-afa2-6b4e93ebb6a0"
      },
      "outputs": [],
      "source": [
        "hnsw_sembeddings = [bm25.encode_documents(i) for i in chunked_files.get('hnsw')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87899d0e-2bcd-4fc5-8c47-f27672b8dcd9",
      "metadata": {
        "id": "87899d0e-2bcd-4fc5-8c47-f27672b8dcd9"
      },
      "outputs": [],
      "source": [
        "ivfpq_sembeddings = [bm25.encode_documents(i) for i in chunked_files.get('ivfpq')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f43b724-acdc-4c13-b321-5c63b4a3b907",
      "metadata": {
        "id": "5f43b724-acdc-4c13-b321-5c63b4a3b907"
      },
      "source": [
        "Let's look at the sparse embeddings for one of our PDFs.\n",
        "\n",
        "You'll see that each PDF's chunks has now transformed into a dictionary with `indices` and `values` keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a794f792-b1b5-458b-8f37-fd9e132cf907",
      "metadata": {
        "id": "a794f792-b1b5-458b-8f37-fd9e132cf907",
        "outputId": "97ffffc9-c7b7-44cb-ba5f-8b0547860250"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'indices': [270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   553238108,\n",
              "   891354358,\n",
              "   3429613387,\n",
              "   2087367745,\n",
              "   2691201840,\n",
              "   3647400625,\n",
              "   2455432819,\n",
              "   3850563250,\n",
              "   1563317370,\n",
              "   407983593,\n",
              "   2307803212,\n",
              "   2751533102,\n",
              "   640124220,\n",
              "   91759785,\n",
              "   569308866,\n",
              "   728487644,\n",
              "   414100959,\n",
              "   3452949137,\n",
              "   3927490055,\n",
              "   125777136,\n",
              "   3935005093,\n",
              "   3096200065,\n",
              "   1612531086,\n",
              "   385392376,\n",
              "   3453722252,\n",
              "   881664426,\n",
              "   1691351615,\n",
              "   536145832,\n",
              "   3066577729,\n",
              "   1564510983,\n",
              "   4183835765,\n",
              "   2165730276,\n",
              "   2851137560,\n",
              "   173740189,\n",
              "   1330873646,\n",
              "   4071218396,\n",
              "   1651775491,\n",
              "   1477105254],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [125777136,\n",
              "   1651775491,\n",
              "   1477105254,\n",
              "   794531107,\n",
              "   553238108,\n",
              "   150695120,\n",
              "   640124220,\n",
              "   4071218396,\n",
              "   1993352305,\n",
              "   1598346136,\n",
              "   2541144706,\n",
              "   2095749492,\n",
              "   1893044414,\n",
              "   648501015,\n",
              "   1819328719,\n",
              "   1564510983,\n",
              "   520409122,\n",
              "   2391722386,\n",
              "   3194111925,\n",
              "   2421602144,\n",
              "   624846797,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   330588669,\n",
              "   436751995,\n",
              "   113387672,\n",
              "   2025509876,\n",
              "   4185449961,\n",
              "   1394226660,\n",
              "   2815579477,\n",
              "   4030396428,\n",
              "   4189723371,\n",
              "   151069542,\n",
              "   339478471,\n",
              "   274844176,\n",
              "   1563317370,\n",
              "   2633291327,\n",
              "   3962831319,\n",
              "   989509788,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   2179962017],\n",
              "  'values': [0.06578947368421052,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [1196854555,\n",
              "   553238108,\n",
              "   2179962017,\n",
              "   930883039,\n",
              "   3096200065,\n",
              "   2557468570,\n",
              "   648501015,\n",
              "   3491502467,\n",
              "   2799483734,\n",
              "   3523328611,\n",
              "   1031134330,\n",
              "   3177874309,\n",
              "   1598346136,\n",
              "   989116115,\n",
              "   2989052340,\n",
              "   1982804121,\n",
              "   3485312465,\n",
              "   2301044897,\n",
              "   4286712296,\n",
              "   3380305552,\n",
              "   2455432819,\n",
              "   4060102936,\n",
              "   2293808668,\n",
              "   3429613387,\n",
              "   3476027533,\n",
              "   4144206424,\n",
              "   3525523449,\n",
              "   3357039338,\n",
              "   644716969,\n",
              "   933960751,\n",
              "   3534645922,\n",
              "   2660310214,\n",
              "   609543353,\n",
              "   3556558201,\n",
              "   1202643662,\n",
              "   3647400625,\n",
              "   2544441640,\n",
              "   3725872281],\n",
              "  'values': [0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.06097560975609757,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104]},\n",
              " {'indices': [3725872281,\n",
              "   2095749492,\n",
              "   3685696496,\n",
              "   728487644,\n",
              "   1707350732,\n",
              "   2650797237,\n",
              "   3452949137,\n",
              "   3779165875,\n",
              "   4102578029,\n",
              "   2307803212,\n",
              "   2660310214,\n",
              "   2375276840,\n",
              "   570245443,\n",
              "   2179962017,\n",
              "   1005783980,\n",
              "   3425584443,\n",
              "   2391315811,\n",
              "   498046697,\n",
              "   3284862352,\n",
              "   553238108,\n",
              "   3438886076,\n",
              "   3194111925,\n",
              "   1200281571,\n",
              "   422208903,\n",
              "   3420564022,\n",
              "   1840217641,\n",
              "   2455432819,\n",
              "   1277427225,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   1477105254,\n",
              "   151069542,\n",
              "   3063998852,\n",
              "   3985184762,\n",
              "   3096200065,\n",
              "   1026658409,\n",
              "   580887246,\n",
              "   4068491112,\n",
              "   1350333277,\n",
              "   4287741883,\n",
              "   3660156378,\n",
              "   982556856],\n",
              "  'values': [0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.04672897196261683,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555]},\n",
              " {'indices': [4287741883,\n",
              "   3660156378,\n",
              "   982556856,\n",
              "   1701701189,\n",
              "   2257684172,\n",
              "   1684747337,\n",
              "   166093682,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   891354358,\n",
              "   3177874309,\n",
              "   2455432819,\n",
              "   3485312465,\n",
              "   281464262,\n",
              "   3589965190,\n",
              "   795485492,\n",
              "   4006988776,\n",
              "   1688610233,\n",
              "   3971053758,\n",
              "   1563718956,\n",
              "   3076548668,\n",
              "   1090888193,\n",
              "   976863851,\n",
              "   609543353,\n",
              "   2391722386,\n",
              "   2773108416,\n",
              "   1407412762,\n",
              "   553238108,\n",
              "   2707362363,\n",
              "   3352697882,\n",
              "   4279915734,\n",
              "   2751533102,\n",
              "   4144206424,\n",
              "   3744277684,\n",
              "   65094886,\n",
              "   440359455,\n",
              "   3253279657,\n",
              "   3385369385,\n",
              "   2509520141,\n",
              "   2691996638,\n",
              "   2095749492],\n",
              "  'values': [0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.06711409395973154,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726]},\n",
              " {'indices': [2509520141,\n",
              "   2691996638,\n",
              "   2095749492,\n",
              "   958659146,\n",
              "   1846246980,\n",
              "   989116115,\n",
              "   442064690,\n",
              "   4071218396,\n",
              "   2557468570,\n",
              "   1319287133,\n",
              "   1366453392,\n",
              "   414100959,\n",
              "   891354358,\n",
              "   1563317370,\n",
              "   2035475614,\n",
              "   301705055,\n",
              "   1508205530,\n",
              "   3385369385,\n",
              "   125777136,\n",
              "   4214784085,\n",
              "   3368723024,\n",
              "   4051235863,\n",
              "   1432619228,\n",
              "   443772008,\n",
              "   3677720983,\n",
              "   3743430521,\n",
              "   737551030,\n",
              "   1590456296,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   1909934694,\n",
              "   262962171,\n",
              "   4158184310,\n",
              "   1875637301,\n",
              "   3737300892,\n",
              "   548955463,\n",
              "   1762032986],\n",
              "  'values': [0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.06451612903225806,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [1909934694,\n",
              "   4158184310,\n",
              "   648501015,\n",
              "   891354358,\n",
              "   125777136,\n",
              "   2095749492,\n",
              "   2660310214,\n",
              "   3743430521,\n",
              "   1491351846,\n",
              "   1156731182,\n",
              "   1563317370,\n",
              "   3919195202,\n",
              "   1493554831,\n",
              "   1651775491,\n",
              "   4071218396,\n",
              "   173740189,\n",
              "   3677720983,\n",
              "   1330873646,\n",
              "   2509520141,\n",
              "   553238108,\n",
              "   2766366083,\n",
              "   2764782922,\n",
              "   3385369385,\n",
              "   570245443,\n",
              "   930102859,\n",
              "   622902531,\n",
              "   2179962017,\n",
              "   3177874309,\n",
              "   3194111925,\n",
              "   2940655442,\n",
              "   1590456296,\n",
              "   3168814557,\n",
              "   1128198904,\n",
              "   3284422637,\n",
              "   930883039,\n",
              "   2236453805,\n",
              "   3729500624,\n",
              "   3096200065,\n",
              "   2557468570,\n",
              "   722829366],\n",
              "  'values': [0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.06211180124223603,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [3096200065,\n",
              "   2557468570,\n",
              "   722829366,\n",
              "   2236453805,\n",
              "   3177874309,\n",
              "   339478471,\n",
              "   2311206319,\n",
              "   125777136,\n",
              "   609543353,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   2301044897,\n",
              "   4286712296,\n",
              "   2566440236,\n",
              "   116350199,\n",
              "   2095749492,\n",
              "   3450118165,\n",
              "   3194111925,\n",
              "   1296924235,\n",
              "   100532018,\n",
              "   1909934694,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   2514386435,\n",
              "   4158184310,\n",
              "   3962831319,\n",
              "   3778205279,\n",
              "   553238108,\n",
              "   930883039,\n",
              "   3469675055,\n",
              "   795485492,\n",
              "   622902531,\n",
              "   2929822643,\n",
              "   2764782922,\n",
              "   3253279657,\n",
              "   3385369385,\n",
              "   2926051694,\n",
              "   2087367745,\n",
              "   4062668894],\n",
              "  'values': [0.04073319755600815,\n",
              "   0.059880239520958084,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.059880239520958084,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.059880239520958084,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788]},\n",
              " {'indices': [4062668894,\n",
              "   2095749492,\n",
              "   622902531,\n",
              "   2179962017,\n",
              "   339478471,\n",
              "   3935005093,\n",
              "   125777136,\n",
              "   640124220,\n",
              "   536145832,\n",
              "   3066577729,\n",
              "   2765150321,\n",
              "   2558003982,\n",
              "   1380081753,\n",
              "   1564510983,\n",
              "   3194111925,\n",
              "   2421602144,\n",
              "   1651775491,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   330588669,\n",
              "   436751995,\n",
              "   1706587157,\n",
              "   553238108,\n",
              "   1612531086,\n",
              "   3076548668,\n",
              "   3091934459,\n",
              "   4185449961,\n",
              "   1394226660,\n",
              "   1302889928,\n",
              "   407983593,\n",
              "   2970411460,\n",
              "   2633291327,\n",
              "   4071218396,\n",
              "   150695120,\n",
              "   3096200065,\n",
              "   3284862352,\n",
              "   2349888478,\n",
              "   2768784282,\n",
              "   4006988776,\n",
              "   3778852250,\n",
              "   2797948309],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [4006988776,\n",
              "   3778852250,\n",
              "   2797948309,\n",
              "   3066577729,\n",
              "   2854381695,\n",
              "   2558003982,\n",
              "   2314336923,\n",
              "   3631500069,\n",
              "   1246280156,\n",
              "   722829366,\n",
              "   262840313,\n",
              "   189262593,\n",
              "   2926051694,\n",
              "   1253056104,\n",
              "   2875043960,\n",
              "   151069542,\n",
              "   1691351615,\n",
              "   330588669,\n",
              "   1893044414,\n",
              "   648501015,\n",
              "   3588960392,\n",
              "   1829831100,\n",
              "   1563317370,\n",
              "   727980535,\n",
              "   3385369385,\n",
              "   2257684172,\n",
              "   2059779546,\n",
              "   2046658185,\n",
              "   2291919351,\n",
              "   4102578029,\n",
              "   863252565,\n",
              "   2421602144,\n",
              "   1156731182,\n",
              "   2695422133,\n",
              "   2301044897,\n",
              "   2848678735,\n",
              "   442064690,\n",
              "   3858994146,\n",
              "   4071218396,\n",
              "   2641398665,\n",
              "   1290213554,\n",
              "   4054825975],\n",
              "  'values': [0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.08421052631578947,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [4054825975,\n",
              "   4006988776,\n",
              "   3540324611,\n",
              "   2257684172,\n",
              "   4230269740,\n",
              "   2687174735,\n",
              "   3194111925,\n",
              "   771713658,\n",
              "   3284862352,\n",
              "   2046658185,\n",
              "   1455707387,\n",
              "   2768784282,\n",
              "   30662561,\n",
              "   2152401260,\n",
              "   3915229131,\n",
              "   325470615,\n",
              "   3299089655,\n",
              "   2391722386,\n",
              "   2443146540,\n",
              "   1491351846,\n",
              "   3748190670,\n",
              "   2797948309,\n",
              "   1031134330,\n",
              "   2910905616,\n",
              "   2821842010,\n",
              "   791735855,\n",
              "   446656910,\n",
              "   2301044897,\n",
              "   2876684594,\n",
              "   125777136,\n",
              "   3787978677,\n",
              "   1119423170,\n",
              "   2035475614,\n",
              "   2970411460,\n",
              "   2095749492,\n",
              "   3234527682,\n",
              "   553238108,\n",
              "   622902531],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [3234527682,\n",
              "   553238108,\n",
              "   622902531,\n",
              "   1596587599,\n",
              "   2210526334,\n",
              "   2291919351,\n",
              "   2429889109,\n",
              "   3087468851,\n",
              "   1401524087,\n",
              "   2633291327,\n",
              "   4071218396,\n",
              "   2957388266,\n",
              "   150695120,\n",
              "   2095749492,\n",
              "   939215365,\n",
              "   1491351846,\n",
              "   2174031719,\n",
              "   3066577729,\n",
              "   1350333277,\n",
              "   1612531086,\n",
              "   2558003982,\n",
              "   3662380772,\n",
              "   2566440236,\n",
              "   620220149,\n",
              "   3645483311,\n",
              "   1875637301,\n",
              "   2970411460,\n",
              "   3284862352,\n",
              "   2768784282,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   1960040400,\n",
              "   1559397529,\n",
              "   640124220,\n",
              "   1750676654,\n",
              "   245221680,\n",
              "   2301044897,\n",
              "   881664426,\n",
              "   2768410132,\n",
              "   4077204723,\n",
              "   3722213172],\n",
              "  'values': [0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.08113590263691683,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [3722213172,\n",
              "   2095749492,\n",
              "   1596587599,\n",
              "   1290543747,\n",
              "   4163441612,\n",
              "   2768784282,\n",
              "   1563317370,\n",
              "   1039287905,\n",
              "   1156731182,\n",
              "   3935005093,\n",
              "   125777136,\n",
              "   1691351615,\n",
              "   3066577729,\n",
              "   2301044897,\n",
              "   881664426,\n",
              "   791735855,\n",
              "   446656910,\n",
              "   1181726436,\n",
              "   3631500069,\n",
              "   3597663484,\n",
              "   1214258741,\n",
              "   4051061832,\n",
              "   3792604286,\n",
              "   330588669,\n",
              "   4123297836,\n",
              "   1563718956,\n",
              "   115441729,\n",
              "   3076548668,\n",
              "   1875637301,\n",
              "   569308866,\n",
              "   4006988776,\n",
              "   813560164,\n",
              "   4030957741,\n",
              "   3779139355,\n",
              "   2558003982,\n",
              "   647677686,\n",
              "   325470615,\n",
              "   553238108,\n",
              "   436751995,\n",
              "   997012898,\n",
              "   749129358,\n",
              "   3520027802],\n",
              "  'values': [0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [3631500069,\n",
              "   749129358,\n",
              "   3520027802,\n",
              "   4006988776,\n",
              "   3588960392,\n",
              "   1909934694,\n",
              "   963753705,\n",
              "   150695120,\n",
              "   3878672364,\n",
              "   1659620524,\n",
              "   4158184310,\n",
              "   1912107568,\n",
              "   3743430521,\n",
              "   1491351846,\n",
              "   2202014194,\n",
              "   2105217563,\n",
              "   2836570682,\n",
              "   4150915742,\n",
              "   891354358,\n",
              "   4260065773,\n",
              "   273066799,\n",
              "   696559717,\n",
              "   3194111925,\n",
              "   1704236722,\n",
              "   3380305552,\n",
              "   4071218396,\n",
              "   4091827966,\n",
              "   189262593,\n",
              "   3476027533,\n",
              "   989116115,\n",
              "   1701701189,\n",
              "   1155714481,\n",
              "   2557986934,\n",
              "   4131889752,\n",
              "   324964102,\n",
              "   3465648511,\n",
              "   3233814315,\n",
              "   648501015,\n",
              "   4051235863],\n",
              "  'values': [0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.06993006993006994,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.0477326968973747,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.0477326968973747,\n",
              "   0.0477326968973747,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125]},\n",
              " {'indices': [3233814315,\n",
              "   648501015,\n",
              "   4051235863,\n",
              "   468575305,\n",
              "   1172383616,\n",
              "   1283235079,\n",
              "   939215365,\n",
              "   1946772953,\n",
              "   891354358,\n",
              "   1563317370,\n",
              "   414100959,\n",
              "   125777136,\n",
              "   4006988776,\n",
              "   3425584443,\n",
              "   2633291327,\n",
              "   4144206424,\n",
              "   991601241,\n",
              "   590228230,\n",
              "   88480538,\n",
              "   2352766506,\n",
              "   3540170031,\n",
              "   553238108,\n",
              "   2957388266,\n",
              "   1807167981,\n",
              "   2401592642,\n",
              "   1733861963,\n",
              "   3096200065,\n",
              "   1706587157,\n",
              "   2751533102,\n",
              "   640124220,\n",
              "   91759785,\n",
              "   1005783980,\n",
              "   3915229131,\n",
              "   3660156378,\n",
              "   504851561,\n",
              "   3194111925,\n",
              "   4071218396,\n",
              "   1319287133,\n",
              "   4158184310,\n",
              "   2064885619,\n",
              "   3927490055,\n",
              "   1350333277],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [4158184310,\n",
              "   2064885619,\n",
              "   3927490055,\n",
              "   1350333277,\n",
              "   1745114270,\n",
              "   2046658185,\n",
              "   504851561,\n",
              "   2473729391,\n",
              "   2456699241,\n",
              "   1909934694,\n",
              "   113387672,\n",
              "   795485492,\n",
              "   771713658,\n",
              "   442064690,\n",
              "   407983593,\n",
              "   4291385346,\n",
              "   91759785,\n",
              "   2202014194,\n",
              "   2963592789,\n",
              "   1563317370,\n",
              "   3786633265,\n",
              "   3190305264,\n",
              "   569308866,\n",
              "   3677720983,\n",
              "   1226779138,\n",
              "   3096200065,\n",
              "   3915229131,\n",
              "   1655132647,\n",
              "   100532018,\n",
              "   3743430521,\n",
              "   4146668087,\n",
              "   2281582299,\n",
              "   446617493,\n",
              "   3853375228,\n",
              "   30209722,\n",
              "   217934597,\n",
              "   3066577729,\n",
              "   2087367745,\n",
              "   115441729,\n",
              "   1769338146,\n",
              "   125777136,\n",
              "   3854588405],\n",
              "  'values': [0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [115441729,\n",
              "   795485492,\n",
              "   1769338146,\n",
              "   125777136,\n",
              "   3854588405,\n",
              "   648501015,\n",
              "   3743430521,\n",
              "   1491351846,\n",
              "   1296924235,\n",
              "   3853375228,\n",
              "   3066577729,\n",
              "   1322743076,\n",
              "   2105217563,\n",
              "   1563317370,\n",
              "   339478471,\n",
              "   2707362363,\n",
              "   1918578280,\n",
              "   274844176,\n",
              "   2877471145,\n",
              "   960916294,\n",
              "   195470179,\n",
              "   151069542,\n",
              "   3741174264,\n",
              "   4030957741,\n",
              "   677219869,\n",
              "   2257684172,\n",
              "   284536586,\n",
              "   1041526299,\n",
              "   1308276157,\n",
              "   1053941712,\n",
              "   983281070,\n",
              "   1277427225,\n",
              "   4006988776,\n",
              "   2875043960,\n",
              "   4183835765,\n",
              "   1684747337,\n",
              "   4071218396,\n",
              "   1893044414,\n",
              "   1651775491,\n",
              "   640124220],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.08264462809917356,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [1651775491,\n",
              "   274844176,\n",
              "   640124220,\n",
              "   2257684172,\n",
              "   3066577729,\n",
              "   2815579477,\n",
              "   590228230,\n",
              "   151069542,\n",
              "   1583132830,\n",
              "   481329573,\n",
              "   3922797336,\n",
              "   553238108,\n",
              "   3959618709,\n",
              "   1491351846,\n",
              "   4030957741,\n",
              "   1563317370,\n",
              "   610868587,\n",
              "   1493554831,\n",
              "   648501015,\n",
              "   2484513939,\n",
              "   2231220596,\n",
              "   2046658185,\n",
              "   504851561,\n",
              "   4071218396,\n",
              "   2456699241,\n",
              "   442064690,\n",
              "   660681034,\n",
              "   125777136,\n",
              "   795485492,\n",
              "   771713658,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   452255852,\n",
              "   414100959,\n",
              "   4006988776,\n",
              "   1769338146,\n",
              "   4241220812,\n",
              "   264741300,\n",
              "   2768410132,\n",
              "   647928480,\n",
              "   1005783980,\n",
              "   2095749492,\n",
              "   3748190670,\n",
              "   2368482328,\n",
              "   276260029,\n",
              "   1564510983,\n",
              "   569308866],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [569308866,\n",
              "   4071218396,\n",
              "   3748190670,\n",
              "   2391722386,\n",
              "   3194111925,\n",
              "   1598346136,\n",
              "   3476796706,\n",
              "   2059378300,\n",
              "   4086277996,\n",
              "   4006988776,\n",
              "   3377905009,\n",
              "   1774861213,\n",
              "   1053941712,\n",
              "   125777136,\n",
              "   87532744,\n",
              "   4115714078,\n",
              "   895820998,\n",
              "   1070064657,\n",
              "   3420564022,\n",
              "   2884037986,\n",
              "   1564510983,\n",
              "   3743430521,\n",
              "   3881069374,\n",
              "   3714011142,\n",
              "   553238108,\n",
              "   150695120,\n",
              "   3476027533,\n",
              "   323763881,\n",
              "   2236453805,\n",
              "   2263326288,\n",
              "   1538063088,\n",
              "   2141082694,\n",
              "   1246395387,\n",
              "   3677720983,\n",
              "   1590456296,\n",
              "   2395176886,\n",
              "   3927490055,\n",
              "   2177509083,\n",
              "   3935005093,\n",
              "   1563317370,\n",
              "   3066577729,\n",
              "   520409122,\n",
              "   2558003982,\n",
              "   640124220,\n",
              "   2768410132,\n",
              "   4077204723,\n",
              "   997052087],\n",
              "  'values': [0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [640124220,\n",
              "   2768410132,\n",
              "   4077204723,\n",
              "   997052087,\n",
              "   609543353,\n",
              "   2391722386,\n",
              "   2963592789,\n",
              "   2177509083,\n",
              "   125777136,\n",
              "   3786633265,\n",
              "   3778137224,\n",
              "   2032101475,\n",
              "   1598346136,\n",
              "   2541144706,\n",
              "   2095749492,\n",
              "   496830140,\n",
              "   3168302377,\n",
              "   700799762,\n",
              "   1044312602,\n",
              "   648501015,\n",
              "   4202456299,\n",
              "   1053941712,\n",
              "   3858994146,\n",
              "   569308866,\n",
              "   4071218396,\n",
              "   2202014194,\n",
              "   2825862146,\n",
              "   939215365,\n",
              "   2509520141,\n",
              "   2501256772,\n",
              "   4086277996,\n",
              "   2876684594,\n",
              "   3792961156,\n",
              "   1564465246,\n",
              "   647677686],\n",
              "  'values': [0.06711409395973154,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.10706638115631692,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.06711409395973154,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726]},\n",
              " {'indices': [2391722386,\n",
              "   647677686,\n",
              "   4202456299,\n",
              "   125777136,\n",
              "   1912107568,\n",
              "   3469675055,\n",
              "   2095749492,\n",
              "   696559717,\n",
              "   2570541023,\n",
              "   3525523449,\n",
              "   891354358,\n",
              "   876558472,\n",
              "   1630857607,\n",
              "   648501015,\n",
              "   2044745418,\n",
              "   4131889752,\n",
              "   2202706442,\n",
              "   2900000648,\n",
              "   2032101475,\n",
              "   1553167345,\n",
              "   945761546,\n",
              "   4260065773,\n",
              "   273066799,\n",
              "   189262593,\n",
              "   3476027533,\n",
              "   3233814315,\n",
              "   1005783980,\n",
              "   1164826063,\n",
              "   989116115,\n",
              "   3872829981,\n",
              "   982556856,\n",
              "   1701701189,\n",
              "   569308866,\n",
              "   728487644,\n",
              "   339478471,\n",
              "   3425584443,\n",
              "   2830370693,\n",
              "   422208903,\n",
              "   659326392,\n",
              "   115441729,\n",
              "   4006988776,\n",
              "   2843452807],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [115441729,\n",
              "   4006988776,\n",
              "   2843452807,\n",
              "   2218697184,\n",
              "   3915229131,\n",
              "   2295538017,\n",
              "   1733861963,\n",
              "   1563317370,\n",
              "   3520027802,\n",
              "   2707362363,\n",
              "   414100959,\n",
              "   2898978278,\n",
              "   3096200065,\n",
              "   1455707387,\n",
              "   2094241111,\n",
              "   442064690,\n",
              "   4174290103,\n",
              "   2468952573,\n",
              "   570652574,\n",
              "   4150915742,\n",
              "   3660156378,\n",
              "   30662561,\n",
              "   2152401260,\n",
              "   2529529491,\n",
              "   1438822346,\n",
              "   270780933,\n",
              "   2577858874,\n",
              "   891354358,\n",
              "   2179962017,\n",
              "   1665891490,\n",
              "   125777136,\n",
              "   1204375150,\n",
              "   2301044897,\n",
              "   2236453805,\n",
              "   1330437081,\n",
              "   189262593,\n",
              "   2894772111,\n",
              "   3967169986,\n",
              "   2429889109],\n",
              "  'values': [0.025,\n",
              "   0.09302325581395349,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.04878048780487805,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025,\n",
              "   0.025]},\n",
              " {'indices': [3967169986,\n",
              "   2429889109,\n",
              "   4006988776,\n",
              "   2953188479,\n",
              "   983281070,\n",
              "   989116115,\n",
              "   640124220,\n",
              "   3773617540,\n",
              "   989509788,\n",
              "   2291919351,\n",
              "   2768784282,\n",
              "   3891556496,\n",
              "   1583132830,\n",
              "   182814590,\n",
              "   240480551,\n",
              "   1455707387,\n",
              "   4071218396,\n",
              "   2150714867,\n",
              "   3675491650,\n",
              "   1563317370,\n",
              "   3009029569,\n",
              "   3561151932,\n",
              "   699262512,\n",
              "   3737140849,\n",
              "   1912107568,\n",
              "   1005783980,\n",
              "   3476027533,\n",
              "   2895605406,\n",
              "   3377905009,\n",
              "   1285655645,\n",
              "   1119423170,\n",
              "   1039287905,\n",
              "   3233814315,\n",
              "   3425584443,\n",
              "   2768410132,\n",
              "   4077204723,\n",
              "   3722213172,\n",
              "   2301044897,\n",
              "   881664426,\n",
              "   2633291327,\n",
              "   414100959,\n",
              "   405598066],\n",
              "  'values': [0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.06711409395973154,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726]},\n",
              " {'indices': [405598066,\n",
              "   989509788,\n",
              "   2650797237,\n",
              "   3589965190,\n",
              "   1455707387,\n",
              "   1853937968,\n",
              "   1905940299,\n",
              "   2473649715,\n",
              "   504851561,\n",
              "   4071218396,\n",
              "   125777136,\n",
              "   3743430521,\n",
              "   3778852250,\n",
              "   1058501323,\n",
              "   3734248682,\n",
              "   1481737067,\n",
              "   2871008955,\n",
              "   648501015,\n",
              "   3377905009,\n",
              "   1721290637,\n",
              "   622902531,\n",
              "   989116115,\n",
              "   2970988990,\n",
              "   2247749524,\n",
              "   1563317370,\n",
              "   3284862352,\n",
              "   4006988776,\n",
              "   620220149,\n",
              "   111228364,\n",
              "   1731757335,\n",
              "   3177874309,\n",
              "   1005783980,\n",
              "   2177509083,\n",
              "   3096200065,\n",
              "   1667662100,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   4051297737,\n",
              "   1253056104,\n",
              "   1701701189,\n",
              "   891354358,\n",
              "   2179962017,\n",
              "   2568877688,\n",
              "   1955147705,\n",
              "   2815972317],\n",
              "  'values': [0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [1955147705,\n",
              "   2815972317,\n",
              "   1731862276,\n",
              "   2502307765,\n",
              "   3748190670,\n",
              "   640124220,\n",
              "   420159263,\n",
              "   1235209082,\n",
              "   3737140849,\n",
              "   3979495055,\n",
              "   2970988990,\n",
              "   3194111925,\n",
              "   312314994,\n",
              "   553238108,\n",
              "   1494846643,\n",
              "   3096200065,\n",
              "   452255852,\n",
              "   989509788,\n",
              "   3928038441,\n",
              "   341476526,\n",
              "   1556311309,\n",
              "   1563317370,\n",
              "   1704236722,\n",
              "   150695120,\n",
              "   2301044897,\n",
              "   2177509083,\n",
              "   1308688855,\n",
              "   1196854555,\n",
              "   3411418812,\n",
              "   3619432518,\n",
              "   1678348498,\n",
              "   1857269791,\n",
              "   2695422133,\n",
              "   1050319643,\n",
              "   1918674444,\n",
              "   1790325311,\n",
              "   2871008955,\n",
              "   2568877688,\n",
              "   1391849172],\n",
              "  'values': [0.08421052631578947,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.06451612903225806,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [1731862276,\n",
              "   1391849172,\n",
              "   1955147705,\n",
              "   2970988990,\n",
              "   3589965190,\n",
              "   1678348498,\n",
              "   1144259690,\n",
              "   1747585916,\n",
              "   553238108,\n",
              "   2095749492,\n",
              "   3131368799,\n",
              "   3194111925,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   100532018,\n",
              "   3962831319,\n",
              "   125777136,\n",
              "   1704236722,\n",
              "   3054746445,\n",
              "   3928038441,\n",
              "   3990417100,\n",
              "   989116115,\n",
              "   2291919351,\n",
              "   3915229131,\n",
              "   1350333277,\n",
              "   1723824186,\n",
              "   3361871542,\n",
              "   4040843919,\n",
              "   989509788,\n",
              "   838568274,\n",
              "   4058690009,\n",
              "   2707362363,\n",
              "   1155714481,\n",
              "   3005552705,\n",
              "   4795507,\n",
              "   2484513939,\n",
              "   238865545,\n",
              "   1039112339,\n",
              "   4176811240,\n",
              "   385392376,\n",
              "   1401524087,\n",
              "   115441729,\n",
              "   2877471145,\n",
              "   309400477,\n",
              "   3335033140],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [309400477,\n",
              "   3335033140,\n",
              "   4795507,\n",
              "   3465648511,\n",
              "   2479011578,\n",
              "   888000370,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   2301044897,\n",
              "   763520878,\n",
              "   3377652727,\n",
              "   946828419,\n",
              "   2578007438,\n",
              "   4006988776,\n",
              "   1912107568,\n",
              "   989509788,\n",
              "   3979495055,\n",
              "   27895541,\n",
              "   2447331368,\n",
              "   3385369385,\n",
              "   569308866,\n",
              "   189262593,\n",
              "   1758224456,\n",
              "   964745590,\n",
              "   1041526299,\n",
              "   1172383616,\n",
              "   3194111925,\n",
              "   771713658,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   1053941712,\n",
              "   1769338146,\n",
              "   125777136,\n",
              "   2910905616,\n",
              "   2476870971,\n",
              "   3570688678,\n",
              "   2609322308,\n",
              "   3662309742,\n",
              "   1966445650,\n",
              "   2768410132,\n",
              "   1277177331],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [1966445650,\n",
              "   2768410132,\n",
              "   1277177331,\n",
              "   3076548668,\n",
              "   3361871542,\n",
              "   1350333277,\n",
              "   927500150,\n",
              "   553238108,\n",
              "   150695120,\n",
              "   2177509083,\n",
              "   1308688855,\n",
              "   3523328611,\n",
              "   609543353,\n",
              "   4247088402,\n",
              "   1612531086,\n",
              "   881664426,\n",
              "   2291919351,\n",
              "   2095749492,\n",
              "   3425584443,\n",
              "   2233892242,\n",
              "   4054825975,\n",
              "   1172383616,\n",
              "   1667662100,\n",
              "   2957388266,\n",
              "   2707362363,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   4186256544,\n",
              "   1912107568,\n",
              "   640124220,\n",
              "   2447331368,\n",
              "   3385369385,\n",
              "   58671053,\n",
              "   3854475,\n",
              "   2307803212,\n",
              "   3850563250,\n",
              "   1563317370,\n",
              "   189262593,\n",
              "   3540324611,\n",
              "   1706587157,\n",
              "   1523929128,\n",
              "   2566440236,\n",
              "   3461421941,\n",
              "   3194111925],\n",
              "  'values': [0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [3461421941,\n",
              "   3194111925,\n",
              "   4158184310,\n",
              "   504851561,\n",
              "   4075116728,\n",
              "   1669811416,\n",
              "   2557468570,\n",
              "   1265018197,\n",
              "   2099264464,\n",
              "   1590456296,\n",
              "   291948513,\n",
              "   2446608323,\n",
              "   2764928117,\n",
              "   1308688855,\n",
              "   648501015,\n",
              "   3327252652,\n",
              "   831070715,\n",
              "   2836570682,\n",
              "   3903932205,\n",
              "   2871008955,\n",
              "   1955147705,\n",
              "   737551030,\n",
              "   4286712296,\n",
              "   2683075451,\n",
              "   2695422133,\n",
              "   3361444614,\n",
              "   728008763,\n",
              "   3523328611,\n",
              "   358389376,\n",
              "   2099560782,\n",
              "   414100959,\n",
              "   891354358,\n",
              "   1563317370,\n",
              "   2295538017,\n",
              "   640124220,\n",
              "   553238108,\n",
              "   3758910623,\n",
              "   3331990572,\n",
              "   3425508159,\n",
              "   3589630101,\n",
              "   2940979805,\n",
              "   1364383302,\n",
              "   125777136,\n",
              "   2301044897,\n",
              "   3650065742,\n",
              "   1196854555],\n",
              "  'values': [0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.05319148936170213,\n",
              "   0.01838235294117647,\n",
              "   0.08561643835616438,\n",
              "   0.01838235294117647,\n",
              "   0.06968641114982578,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647]},\n",
              " {'indices': [3650065742,\n",
              "   1196854555,\n",
              "   640124220,\n",
              "   808170570,\n",
              "   553238108,\n",
              "   4006988776,\n",
              "   3499530140,\n",
              "   504851561,\n",
              "   2733467792,\n",
              "   1598346136,\n",
              "   3425508159,\n",
              "   4054825975,\n",
              "   1531182245,\n",
              "   2764928117,\n",
              "   2722752205,\n",
              "   302265356,\n",
              "   242017537,\n",
              "   407983593,\n",
              "   1646279392,\n",
              "   3182414933,\n",
              "   1669811416,\n",
              "   3411418812,\n",
              "   3523328611,\n",
              "   2301044897,\n",
              "   2218326882,\n",
              "   734978415,\n",
              "   335279705,\n",
              "   2044745418,\n",
              "   2557468570,\n",
              "   2940979805,\n",
              "   4286712296,\n",
              "   1939759115,\n",
              "   3756646148,\n",
              "   2012469550,\n",
              "   648501015,\n",
              "   1430125705],\n",
              "  'values': [0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.054945054945054944,\n",
              "   0.07194244604316546,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.07194244604316546,\n",
              "   0.054945054945054944,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.08833922261484099,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463]},\n",
              " {'indices': [2557468570,\n",
              "   1430125705,\n",
              "   946828419,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   2301044897,\n",
              "   1262037066,\n",
              "   4006988776,\n",
              "   2484513939,\n",
              "   2099560782,\n",
              "   3878672364,\n",
              "   808170570,\n",
              "   553238108,\n",
              "   3485312465,\n",
              "   125777136,\n",
              "   2087367745,\n",
              "   496830140,\n",
              "   2800534748,\n",
              "   3425508159,\n",
              "   504851561,\n",
              "   3233814315,\n",
              "   2295538017,\n",
              "   4058690009,\n",
              "   358389376,\n",
              "   2725039967,\n",
              "   90097469,\n",
              "   3411418812,\n",
              "   1538063088,\n",
              "   3377905009,\n",
              "   804460016,\n",
              "   3284862352,\n",
              "   648501015,\n",
              "   1531182245,\n",
              "   554831995,\n",
              "   1590456296,\n",
              "   998499238,\n",
              "   3838814518,\n",
              "   2722752205,\n",
              "   504085140,\n",
              "   3743430521,\n",
              "   1364383302],\n",
              "  'values': [0.07312614259597806,\n",
              "   0.037950664136622396,\n",
              "   0.037950664136622396,\n",
              "   0.037950664136622396,\n",
              "   0.037950664136622396,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.07312614259597806,\n",
              "   0.037950664136622396,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.037950664136622396,\n",
              "   0.0558659217877095,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.037950664136622396,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684,\n",
              "   0.019342359767891684]},\n",
              " {'indices': [3743430521,\n",
              "   1364383302,\n",
              "   4006988776,\n",
              "   2484513939,\n",
              "   998499238,\n",
              "   2557468570,\n",
              "   553238108,\n",
              "   2301044897,\n",
              "   2910549482,\n",
              "   4234231580,\n",
              "   3770184132,\n",
              "   1144259690,\n",
              "   91662462,\n",
              "   1553167345,\n",
              "   1531182245,\n",
              "   1028984916,\n",
              "   3233814315,\n",
              "   3282398576,\n",
              "   2695422133,\n",
              "   1037662226,\n",
              "   159811567,\n",
              "   1401524087,\n",
              "   2307803212,\n",
              "   150695120,\n",
              "   3660156378,\n",
              "   804460016,\n",
              "   3540324611,\n",
              "   2179962017,\n",
              "   3355129947,\n",
              "   4158184310,\n",
              "   50099679,\n",
              "   3831243209,\n",
              "   4153030385,\n",
              "   2072640357,\n",
              "   4068491112,\n",
              "   441260191,\n",
              "   1769338146,\n",
              "   3194111925,\n",
              "   2064885619,\n",
              "   3023675989,\n",
              "   1659620524],\n",
              "  'values': [0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.08113590263691683,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [3023675989,\n",
              "   1659620524,\n",
              "   28880144,\n",
              "   553238108,\n",
              "   442064690,\n",
              "   3231131346,\n",
              "   1350333277,\n",
              "   3460643800,\n",
              "   989509788,\n",
              "   88743764,\n",
              "   3425508159,\n",
              "   504851561,\n",
              "   113387672,\n",
              "   997549709,\n",
              "   795485492,\n",
              "   1758470515,\n",
              "   4287741883,\n",
              "   301705055,\n",
              "   1296924235,\n",
              "   452255852,\n",
              "   3540324611,\n",
              "   4006988776,\n",
              "   3685696496,\n",
              "   1769338146,\n",
              "   4241220812,\n",
              "   1554236172,\n",
              "   806976768,\n",
              "   3551371075,\n",
              "   916214203,\n",
              "   4071218396,\n",
              "   4091827966,\n",
              "   3461421941,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   2557468570,\n",
              "   4051061832,\n",
              "   946828419,\n",
              "   4051235863,\n",
              "   640124220],\n",
              "  'values': [0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.06711409395973154,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726]},\n",
              " {'indices': [4006988776,\n",
              "   640124220,\n",
              "   1767380095,\n",
              "   3341589273,\n",
              "   1028900885,\n",
              "   55464758,\n",
              "   1175805827,\n",
              "   3215393521,\n",
              "   4113533787,\n",
              "   171266656,\n",
              "   554831995,\n",
              "   3177173382,\n",
              "   3157974603,\n",
              "   4051061832,\n",
              "   737551030,\n",
              "   3427431433,\n",
              "   2141082694,\n",
              "   4158184310,\n",
              "   4091827966,\n",
              "   648501015,\n",
              "   2557468570,\n",
              "   963753705,\n",
              "   2471982452,\n",
              "   1024449246,\n",
              "   1477105254,\n",
              "   3023675989,\n",
              "   1595953974,\n",
              "   3796074982,\n",
              "   1572011726,\n",
              "   1993503267,\n",
              "   3361871542,\n",
              "   3425508159,\n",
              "   1302889928,\n",
              "   1062750627,\n",
              "   2066971792,\n",
              "   3425584443,\n",
              "   448220673,\n",
              "   504851561,\n",
              "   2514386435],\n",
              "  'values': [0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.07827788649706457,\n",
              "   0.04073319755600815,\n",
              "   0.059880239520958084,\n",
              "   0.07827788649706457,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788]},\n",
              " {'indices': [2514386435,\n",
              "   648501015,\n",
              "   2557468570,\n",
              "   4158184310,\n",
              "   2471982452,\n",
              "   55464758,\n",
              "   1175805827,\n",
              "   1024449246,\n",
              "   3341589273,\n",
              "   3796074982,\n",
              "   30662561,\n",
              "   2473649715,\n",
              "   3551371075,\n",
              "   3828252484,\n",
              "   3589630101,\n",
              "   1082867806,\n",
              "   1913459993,\n",
              "   504851561,\n",
              "   4071218396,\n",
              "   171266656,\n",
              "   1564465246,\n",
              "   554831995,\n",
              "   2642462021,\n",
              "   4051061832,\n",
              "   3427431433,\n",
              "   2141082694,\n",
              "   2267101260,\n",
              "   1767380095,\n",
              "   4006988776,\n",
              "   3174900812,\n",
              "   818459139,\n",
              "   2484513939,\n",
              "   570652574,\n",
              "   4091827966,\n",
              "   4051297737,\n",
              "   275574541,\n",
              "   301705055,\n",
              "   3923460179,\n",
              "   3096200065],\n",
              "  'values': [0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.09765625000000001,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.06097560975609757,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104]},\n",
              " {'indices': [301705055,\n",
              "   3923460179,\n",
              "   3096200065,\n",
              "   1169667353,\n",
              "   2848887788,\n",
              "   648501015,\n",
              "   1037662226,\n",
              "   1034394088,\n",
              "   2733467792,\n",
              "   3540324611,\n",
              "   125777136,\n",
              "   4006988776,\n",
              "   4022339390,\n",
              "   4071218396,\n",
              "   771713658,\n",
              "   1042626614,\n",
              "   1394226660,\n",
              "   2150507160,\n",
              "   4158184310,\n",
              "   3551371075,\n",
              "   2165730276,\n",
              "   1909934694,\n",
              "   641155872,\n",
              "   2876684594,\n",
              "   1936903680,\n",
              "   818459139,\n",
              "   2484513939,\n",
              "   553238108,\n",
              "   385392376,\n",
              "   4131889752,\n",
              "   1296157733,\n",
              "   2437397365,\n",
              "   1733861963,\n",
              "   2295538017,\n",
              "   1769338146,\n",
              "   1554236172,\n",
              "   4241220812,\n",
              "   1563317370,\n",
              "   492661292,\n",
              "   3899452313,\n",
              "   2913146506,\n",
              "   1767380095,\n",
              "   422208903],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [3899452313,\n",
              "   4131889752,\n",
              "   2913146506,\n",
              "   1767380095,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   1050319643,\n",
              "   1909934694,\n",
              "   2932171215,\n",
              "   125777136,\n",
              "   640124220,\n",
              "   4006988776,\n",
              "   19522071,\n",
              "   504085140,\n",
              "   2301044897,\n",
              "   407983593,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   2557468570,\n",
              "   2485669278,\n",
              "   2395889254,\n",
              "   1590456296,\n",
              "   3182414933,\n",
              "   4051235863,\n",
              "   946828419,\n",
              "   604168759,\n",
              "   3903932205,\n",
              "   3427431433,\n",
              "   2141082694,\n",
              "   264741300,\n",
              "   526748264,\n",
              "   3341589273,\n",
              "   1848516122,\n",
              "   3796074982,\n",
              "   91662462,\n",
              "   554831995,\n",
              "   3177173382,\n",
              "   1553167345,\n",
              "   2900966224,\n",
              "   4158184310,\n",
              "   3778137224,\n",
              "   3491502467,\n",
              "   640477688,\n",
              "   4091827966,\n",
              "   2514386435],\n",
              "  'values': [0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.05405405405405406,\n",
              "   0.08695652173913043,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.05405405405405406,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728]},\n",
              " {'indices': [640477688,\n",
              "   4158184310,\n",
              "   4091827966,\n",
              "   2514386435,\n",
              "   58671053,\n",
              "   1769813804,\n",
              "   1070064657,\n",
              "   2225624884,\n",
              "   640124220,\n",
              "   2482994121,\n",
              "   520935151,\n",
              "   4006988776,\n",
              "   113387672,\n",
              "   4213540094,\n",
              "   88743764,\n",
              "   504851561,\n",
              "   2645357763,\n",
              "   2557468570,\n",
              "   3341589273,\n",
              "   3796074982,\n",
              "   3981855590,\n",
              "   4113533787,\n",
              "   3898348400,\n",
              "   3589630101,\n",
              "   407983593,\n",
              "   2876684594,\n",
              "   2548177168,\n",
              "   3177173382,\n",
              "   1144259690,\n",
              "   91662462,\n",
              "   1553167345,\n",
              "   3427431433,\n",
              "   264741300,\n",
              "   2890116975,\n",
              "   1498444896,\n",
              "   2940979805,\n",
              "   3915229131,\n",
              "   3420564022,\n",
              "   100532018,\n",
              "   3040371067,\n",
              "   3086851070,\n",
              "   2473649715,\n",
              "   198593717,\n",
              "   2194093370],\n",
              "  'values': [0.017513134851138354,\n",
              "   0.03442340791738382,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.03442340791738382,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.03442340791738382,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.03442340791738382,\n",
              "   0.017513134851138354,\n",
              "   0.1382488479262673,\n",
              "   0.017513134851138354,\n",
              "   0.03442340791738382,\n",
              "   0.0966183574879227,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354,\n",
              "   0.017513134851138354]},\n",
              " {'indices': [198593717,\n",
              "   2557468570,\n",
              "   2194093370,\n",
              "   442064690,\n",
              "   1655132647,\n",
              "   844376589,\n",
              "   964114575,\n",
              "   2876684594,\n",
              "   4158184310,\n",
              "   1762032986,\n",
              "   2932171215,\n",
              "   2059779546,\n",
              "   226376294,\n",
              "   1332462848,\n",
              "   648501015,\n",
              "   3341589273,\n",
              "   1325492893,\n",
              "   1477105254,\n",
              "   3677720983,\n",
              "   504851561,\n",
              "   3919195202,\n",
              "   2142141949,\n",
              "   2165730276,\n",
              "   553238108,\n",
              "   2236453805,\n",
              "   88743764,\n",
              "   4006988776,\n",
              "   2484513939,\n",
              "   640124220,\n",
              "   4054825975,\n",
              "   3425508159,\n",
              "   823134346,\n",
              "   1590456296,\n",
              "   2501256772,\n",
              "   2534330448,\n",
              "   1751941134],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.10504201680672269,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [2534330448,\n",
              "   1751941134,\n",
              "   1308688855,\n",
              "   4158184310,\n",
              "   2044745418,\n",
              "   3359694854,\n",
              "   125777136,\n",
              "   3985184762,\n",
              "   4268784288,\n",
              "   504851561,\n",
              "   640124220,\n",
              "   4006988776,\n",
              "   3778137224,\n",
              "   4071218396,\n",
              "   2473649715,\n",
              "   648501015,\n",
              "   1175805827,\n",
              "   4054825975,\n",
              "   100532018,\n",
              "   3675491650,\n",
              "   2210526334,\n",
              "   1650054722,\n",
              "   4257564859,\n",
              "   2501256772,\n",
              "   554831995,\n",
              "   3377652727,\n",
              "   3944559304,\n",
              "   30662561,\n",
              "   3631500069,\n",
              "   2231220596,\n",
              "   1909934694,\n",
              "   3491502467,\n",
              "   3979495055,\n",
              "   2484513939,\n",
              "   1364383302,\n",
              "   442064690],\n",
              "  'values': [0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.08421052631578947,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.06451612903225806,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [442064690,\n",
              "   125777136,\n",
              "   1999194864,\n",
              "   953824239,\n",
              "   771713658,\n",
              "   4071218396,\n",
              "   1394226660,\n",
              "   3985184762,\n",
              "   2263091519,\n",
              "   4176811240,\n",
              "   3465648511,\n",
              "   264741300,\n",
              "   3471348524,\n",
              "   602572328,\n",
              "   4192813138,\n",
              "   2724250463,\n",
              "   3117484998,\n",
              "   1400299369,\n",
              "   3778137224,\n",
              "   1191192916,\n",
              "   496426677,\n",
              "   863853060,\n",
              "   19522071,\n",
              "   3874893223,\n",
              "   301951318,\n",
              "   3954990653,\n",
              "   2327368754,\n",
              "   2025509876,\n",
              "   1651554039,\n",
              "   755629816,\n",
              "   2268050145,\n",
              "   3430258219,\n",
              "   3150645931,\n",
              "   3530670207,\n",
              "   4131889752,\n",
              "   2510335750,\n",
              "   1296157733,\n",
              "   3923460179,\n",
              "   1961940076,\n",
              "   1452798995,\n",
              "   1918674444,\n",
              "   2044716865,\n",
              "   2093513605,\n",
              "   1594086824,\n",
              "   1305218356,\n",
              "   3870102732,\n",
              "   1698708618,\n",
              "   278577074,\n",
              "   4070606901,\n",
              "   1005783980,\n",
              "   3935005093,\n",
              "   330588669,\n",
              "   3066577729,\n",
              "   1350333277,\n",
              "   2177509083,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   3748190670,\n",
              "   504851561],\n",
              "  'values': [0.011402508551881414,\n",
              "   0.05452562704471101,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.02254791431792559,\n",
              "   0.044101433296582136,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.033444816053511704,\n",
              "   0.011402508551881414,\n",
              "   0.033444816053511704,\n",
              "   0.011402508551881414,\n",
              "   0.044101433296582136,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.044101433296582136,\n",
              "   0.02254791431792559,\n",
              "   0.011402508551881414,\n",
              "   0.02254791431792559,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.044101433296582136,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.033444816053511704,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.044101433296582136,\n",
              "   0.02254791431792559,\n",
              "   0.044101433296582136,\n",
              "   0.044101433296582136,\n",
              "   0.033444816053511704,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414,\n",
              "   0.011402508551881414]},\n",
              " {'indices': [647677686,\n",
              "   3748190670,\n",
              "   504851561,\n",
              "   989116115,\n",
              "   2558003982,\n",
              "   2910905616,\n",
              "   2032101475,\n",
              "   3469675055,\n",
              "   2095749492,\n",
              "   2541144706,\n",
              "   2368482328,\n",
              "   276260029,\n",
              "   1564510983,\n",
              "   569308866,\n",
              "   3677720983,\n",
              "   3500039081,\n",
              "   1253056104,\n",
              "   2391722386,\n",
              "   963753705,\n",
              "   2815972317,\n",
              "   1955147705,\n",
              "   1731862276,\n",
              "   640124220,\n",
              "   3476647774,\n",
              "   2970988990,\n",
              "   927500150,\n",
              "   1745114270,\n",
              "   380762419,\n",
              "   14784032,\n",
              "   2289031202,\n",
              "   3699493211,\n",
              "   1833634097,\n",
              "   3540324611,\n",
              "   125777136,\n",
              "   1470320597,\n",
              "   2932171215],\n",
              "  'values': [0.04310344827586207,\n",
              "   0.10121457489878542,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [125777136,\n",
              "   1470320597,\n",
              "   2932171215,\n",
              "   504851561,\n",
              "   2800534748,\n",
              "   640124220,\n",
              "   380762419,\n",
              "   2940979805,\n",
              "   58671053,\n",
              "   3778137224,\n",
              "   1308688855,\n",
              "   2386266869,\n",
              "   808170570,\n",
              "   553238108,\n",
              "   4006988776,\n",
              "   4146668087,\n",
              "   998499238,\n",
              "   30662561,\n",
              "   1101668368,\n",
              "   4173428777,\n",
              "   420159263,\n",
              "   1912107568,\n",
              "   1214258741,\n",
              "   881664426,\n",
              "   1181726436,\n",
              "   2473649715,\n",
              "   1564510983,\n",
              "   2557986934,\n",
              "   2892062428,\n",
              "   3286166600,\n",
              "   1364383302,\n",
              "   385392376,\n",
              "   2399467628,\n",
              "   3476027533,\n",
              "   2485669278,\n",
              "   3203885003,\n",
              "   3699493211,\n",
              "   1563317370,\n",
              "   3469675055,\n",
              "   2095749492,\n",
              "   339478471,\n",
              "   358389376,\n",
              "   2045916435,\n",
              "   2257684172,\n",
              "   650821568],\n",
              "  'values': [0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.057803468208092484,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.057803468208092484,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064]},\n",
              " {'indices': [358389376,\n",
              "   2045916435,\n",
              "   1563317370,\n",
              "   2257684172,\n",
              "   650821568,\n",
              "   125777136,\n",
              "   882820413,\n",
              "   1489355757,\n",
              "   2585038467,\n",
              "   915649341,\n",
              "   2067535044,\n",
              "   3852803777,\n",
              "   3491502467,\n",
              "   1325492893,\n",
              "   3350921818,\n",
              "   1300972172,\n",
              "   2951258741,\n",
              "   2245569254,\n",
              "   2821442271,\n",
              "   2541144706,\n",
              "   640124220,\n",
              "   2236453805,\n",
              "   3662309742,\n",
              "   3664949805,\n",
              "   318824902,\n",
              "   1909934694,\n",
              "   2064885619,\n",
              "   2202014194,\n",
              "   2857869476,\n",
              "   1407364890,\n",
              "   1053941712,\n",
              "   1737333554,\n",
              "   1706587157,\n",
              "   1986137636,\n",
              "   1093819894,\n",
              "   1119423170,\n",
              "   958659146,\n",
              "   422208903,\n",
              "   2465027848,\n",
              "   1884119058,\n",
              "   928618987,\n",
              "   112136910,\n",
              "   648501015,\n",
              "   2836570682],\n",
              "  'values': [0.04,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.058823529411764705,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612]},\n",
              " {'indices': [112136910,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   2836570682,\n",
              "   3987085787,\n",
              "   2095749492,\n",
              "   1598346136,\n",
              "   2165730276,\n",
              "   569047032,\n",
              "   4086277996,\n",
              "   2141082694,\n",
              "   4113533787,\n",
              "   1214258741,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   2159421842,\n",
              "   1737333554,\n",
              "   3177173382,\n",
              "   2022324337,\n",
              "   549128519,\n",
              "   47979518,\n",
              "   3792961156,\n",
              "   1774861213,\n",
              "   4030957741,\n",
              "   3677720983,\n",
              "   700799762,\n",
              "   1489355757,\n",
              "   173740189,\n",
              "   1909934694,\n",
              "   2585038467,\n",
              "   2842480055,\n",
              "   1706587157,\n",
              "   4158184310,\n",
              "   1325492893,\n",
              "   939215365,\n",
              "   1381880991,\n",
              "   2539759057,\n",
              "   4075116728,\n",
              "   3096200065,\n",
              "   2557468570,\n",
              "   3327252652],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [648501015,\n",
              "   1489355757,\n",
              "   3327252652,\n",
              "   2099264464,\n",
              "   407983593,\n",
              "   1105706408,\n",
              "   3967169986,\n",
              "   1737333554,\n",
              "   2585038467,\n",
              "   2742467748,\n",
              "   4158184310,\n",
              "   1325492893,\n",
              "   3683798579,\n",
              "   3918058432,\n",
              "   4086277996,\n",
              "   700799762,\n",
              "   3096200065,\n",
              "   2557468570,\n",
              "   1646279392,\n",
              "   29146621,\n",
              "   3551371075,\n",
              "   111228364,\n",
              "   3987085787,\n",
              "   1774861213,\n",
              "   2876684594,\n",
              "   2095749492,\n",
              "   2019031726,\n",
              "   2842480055,\n",
              "   2395176886,\n",
              "   728165346,\n",
              "   1214258741,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   3174900812,\n",
              "   358389376,\n",
              "   440359455,\n",
              "   3589195505,\n",
              "   2141082694,\n",
              "   3450118165,\n",
              "   1612531086,\n",
              "   380541707],\n",
              "  'values': [0.06451612903225806,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [3450118165,\n",
              "   3551371075,\n",
              "   1612531086,\n",
              "   380541707,\n",
              "   4086277996,\n",
              "   2851137560,\n",
              "   4051061832,\n",
              "   4006988776,\n",
              "   3778137224,\n",
              "   2876684594,\n",
              "   4158184310,\n",
              "   2485669278,\n",
              "   1391301964,\n",
              "   125777136,\n",
              "   648501015,\n",
              "   1690300841,\n",
              "   29146621,\n",
              "   19522071,\n",
              "   1909934694,\n",
              "   3327252652,\n",
              "   1123242940,\n",
              "   442064690,\n",
              "   1489355757,\n",
              "   3915229131,\n",
              "   1336952346,\n",
              "   504851561,\n",
              "   3476027533,\n",
              "   160656921,\n",
              "   1955147705,\n",
              "   2458314305,\n",
              "   3748190670,\n",
              "   2391722386,\n",
              "   1070064657,\n",
              "   4153030385,\n",
              "   3169584877,\n",
              "   3732798799],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.08583690987124463,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [4006988776,\n",
              "   3732798799,\n",
              "   2391722386,\n",
              "   1671630355,\n",
              "   895820998,\n",
              "   1117261085,\n",
              "   1296924235,\n",
              "   4160846599,\n",
              "   860277086,\n",
              "   2484513939,\n",
              "   4158184310,\n",
              "   189262593,\n",
              "   2689951346,\n",
              "   1489355757,\n",
              "   2585038467,\n",
              "   1670835917,\n",
              "   2091091113,\n",
              "   4051061832,\n",
              "   3778137224,\n",
              "   2876684594,\n",
              "   29146621,\n",
              "   3616355657,\n",
              "   3686012684,\n",
              "   648501015,\n",
              "   2473649715,\n",
              "   1997743268,\n",
              "   3932611348,\n",
              "   1564510983,\n",
              "   2673623443,\n",
              "   4054825975,\n",
              "   2691201840,\n",
              "   640124220,\n",
              "   1936903680,\n",
              "   824622370,\n",
              "   3172858508,\n",
              "   88743764,\n",
              "   3471378517],\n",
              "  'values': [0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [88743764,\n",
              "   2691201840,\n",
              "   3471378517,\n",
              "   1564510983,\n",
              "   1391301964,\n",
              "   3763885419,\n",
              "   4113533787,\n",
              "   4006988776,\n",
              "   3778137224,\n",
              "   264741300,\n",
              "   3377905009,\n",
              "   3523328611,\n",
              "   3019051052,\n",
              "   640124220,\n",
              "   2815972317,\n",
              "   927500150,\n",
              "   1955147705,\n",
              "   2516331022,\n",
              "   3748190670,\n",
              "   2821147143,\n",
              "   1489355757,\n",
              "   1230423685,\n",
              "   270780933,\n",
              "   1062750627,\n",
              "   2032101475,\n",
              "   2616950127,\n",
              "   1277427225,\n",
              "   609543353,\n",
              "   1330437081,\n",
              "   4160846599,\n",
              "   4086277996,\n",
              "   1706587157,\n",
              "   19522071,\n",
              "   1909934694,\n",
              "   3341589273,\n",
              "   422208903,\n",
              "   648501015,\n",
              "   3327252652],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.08264462809917356,\n",
              "   0.022026431718061675,\n",
              "   0.06329113924050633,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [422208903,\n",
              "   648501015,\n",
              "   3327252652,\n",
              "   1391301964,\n",
              "   806976768,\n",
              "   3169584877,\n",
              "   4006988776,\n",
              "   19522071,\n",
              "   2851137560,\n",
              "   2386266869,\n",
              "   4051061832,\n",
              "   3445135950,\n",
              "   2557468570,\n",
              "   2484513939,\n",
              "   492661292,\n",
              "   3936462175,\n",
              "   997012898,\n",
              "   1590456296,\n",
              "   3182414933,\n",
              "   398718796,\n",
              "   2395889254,\n",
              "   553238108,\n",
              "   448220673,\n",
              "   3420564022,\n",
              "   504851561,\n",
              "   3748190670,\n",
              "   1564510983,\n",
              "   2064885619,\n",
              "   2473649715,\n",
              "   3756646148,\n",
              "   3981855590,\n",
              "   1181726436,\n",
              "   380762419,\n",
              "   2940979805,\n",
              "   1364383302,\n",
              "   1308688855,\n",
              "   2557986934,\n",
              "   1912107568,\n",
              "   3469675055,\n",
              "   881664426,\n",
              "   330588669,\n",
              "   1564465246],\n",
              "  'values': [0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104]},\n",
              " {'indices': [648501015,\n",
              "   1564465246,\n",
              "   4051061832,\n",
              "   2792217549,\n",
              "   2557468570,\n",
              "   3182414933,\n",
              "   1553167345,\n",
              "   2141082694,\n",
              "   3510466679,\n",
              "   946828419,\n",
              "   1590456296,\n",
              "   1196854555,\n",
              "   2764928117,\n",
              "   3915229131,\n",
              "   293497446,\n",
              "   4006988776,\n",
              "   19522071,\n",
              "   3988520219,\n",
              "   1366137814,\n",
              "   1909934694,\n",
              "   4022495362,\n",
              "   3981855590,\n",
              "   3117484998,\n",
              "   1669811416,\n",
              "   685898275,\n",
              "   3796074982,\n",
              "   3420564022,\n",
              "   2194093370,\n",
              "   442064690,\n",
              "   1721290637,\n",
              "   1308688855,\n",
              "   2150507160,\n",
              "   3449948193,\n",
              "   3172858508,\n",
              "   264741300,\n",
              "   1665612518,\n",
              "   4160846599,\n",
              "   2876684594,\n",
              "   609092270,\n",
              "   2578007438,\n",
              "   700799762,\n",
              "   1489355757,\n",
              "   125777136,\n",
              "   1181726436,\n",
              "   1391301964,\n",
              "   1956977255],\n",
              "  'values': [0.03861003861003861,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.10752688172043011,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.03861003861003861,\n",
              "   0.01968503937007874,\n",
              "   0.03861003861003861,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.03861003861003861,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874]},\n",
              " {'indices': [1391301964,\n",
              "   1956977255,\n",
              "   1564510983,\n",
              "   3341589273,\n",
              "   883040885,\n",
              "   1175805827,\n",
              "   4054825975,\n",
              "   2557468570,\n",
              "   1830646559,\n",
              "   422208903,\n",
              "   171266656,\n",
              "   3756646148,\n",
              "   3171191275,\n",
              "   3177173382,\n",
              "   2900966224,\n",
              "   3427431433,\n",
              "   2473649715,\n",
              "   1590456296,\n",
              "   4022495362,\n",
              "   2792217549,\n",
              "   1646279392,\n",
              "   1360961965,\n",
              "   2339220210,\n",
              "   2691201840,\n",
              "   3449948193,\n",
              "   100532018,\n",
              "   804460016,\n",
              "   554831995,\n",
              "   1889379433,\n",
              "   895820998,\n",
              "   1330437081,\n",
              "   4071218396,\n",
              "   1382617884,\n",
              "   3471378517,\n",
              "   3686012684,\n",
              "   47431185,\n",
              "   151069542,\n",
              "   2141082694,\n",
              "   1277427225,\n",
              "   358389376,\n",
              "   1198964877,\n",
              "   390204765],\n",
              "  'values': [0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.057803468208092484,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.12522361359570663,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.057803468208092484,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064]},\n",
              " {'indices': [358389376,\n",
              "   1198964877,\n",
              "   390204765,\n",
              "   700799762,\n",
              "   989116115,\n",
              "   2989052340,\n",
              "   4158184310,\n",
              "   1665612518,\n",
              "   4160846599,\n",
              "   1350333277,\n",
              "   380762419,\n",
              "   2940979805,\n",
              "   1123242940,\n",
              "   1909934694,\n",
              "   4006988776,\n",
              "   150695120,\n",
              "   2557986934,\n",
              "   1308688855,\n",
              "   2150507160,\n",
              "   4194061280,\n",
              "   3449948193,\n",
              "   330588669,\n",
              "   648501015,\n",
              "   3465648511,\n",
              "   4123297836,\n",
              "   2853636491,\n",
              "   946828419,\n",
              "   3377652727,\n",
              "   3985184762,\n",
              "   1028984916,\n",
              "   3233814315,\n",
              "   1590456296,\n",
              "   2236729753,\n",
              "   1062750627,\n",
              "   3743430521,\n",
              "   4173428777,\n",
              "   24515841,\n",
              "   1477105254,\n",
              "   3927490055,\n",
              "   953824239,\n",
              "   3425508159,\n",
              "   448220673,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   62284129,\n",
              "   4086277996],\n",
              "  'values': [0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788]},\n",
              " {'indices': [62284129,\n",
              "   4086277996,\n",
              "   2876684594,\n",
              "   989116115,\n",
              "   2989052340,\n",
              "   3985184762,\n",
              "   2871160520,\n",
              "   1553167345,\n",
              "   109492400,\n",
              "   1028984916,\n",
              "   125777136,\n",
              "   3233814315,\n",
              "   2557986934,\n",
              "   1322743076,\n",
              "   2035475614,\n",
              "   3440744434,\n",
              "   645267917,\n",
              "   2737868476,\n",
              "   647677686,\n",
              "   1807133983,\n",
              "   1034183227,\n",
              "   270780933,\n",
              "   3523328611,\n",
              "   385392376,\n",
              "   728165346,\n",
              "   3474293978,\n",
              "   927500150,\n",
              "   1652275073,\n",
              "   648501015,\n",
              "   2854381695,\n",
              "   3935005093,\n",
              "   2516331022,\n",
              "   2231220596,\n",
              "   4071218396,\n",
              "   4006988776,\n",
              "   19522071,\n",
              "   3778137224,\n",
              "   1364383302,\n",
              "   2399467628,\n",
              "   953824239,\n",
              "   771713658],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [953824239,\n",
              "   771713658,\n",
              "   4071218396,\n",
              "   58671053,\n",
              "   3997447331,\n",
              "   3741174264,\n",
              "   14784032,\n",
              "   4006988776,\n",
              "   2895605406,\n",
              "   4086277996,\n",
              "   2141082694,\n",
              "   3967169986,\n",
              "   1319287133,\n",
              "   640124220,\n",
              "   270780933,\n",
              "   2815972317,\n",
              "   1955147705,\n",
              "   3523328611,\n",
              "   609543353,\n",
              "   1302889928,\n",
              "   2876684594,\n",
              "   1296157733,\n",
              "   1372955919,\n",
              "   4131135811,\n",
              "   504851561,\n",
              "   2616950127,\n",
              "   3561151932,\n",
              "   2295538017,\n",
              "   3284862352,\n",
              "   1912107568,\n",
              "   275574541,\n",
              "   818459139,\n",
              "   3778137224,\n",
              "   2733467792,\n",
              "   1733861963,\n",
              "   87532744,\n",
              "   2848735744],\n",
              "  'values': [0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.06849315068493152,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555]},\n",
              " {'indices': [2295538017,\n",
              "   87532744,\n",
              "   2848735744,\n",
              "   648501015,\n",
              "   2150507160,\n",
              "   3235437686,\n",
              "   3430258219,\n",
              "   3096200065,\n",
              "   1296157733,\n",
              "   4071218396,\n",
              "   125777136,\n",
              "   173740189,\n",
              "   264404082,\n",
              "   4158184310,\n",
              "   2333687351,\n",
              "   1308688855,\n",
              "   1909934694,\n",
              "   397493074,\n",
              "   310274930,\n",
              "   4282979635,\n",
              "   640124220,\n",
              "   4086277996,\n",
              "   4051061832,\n",
              "   275574541,\n",
              "   1214258741,\n",
              "   2510335750,\n",
              "   1752981687,\n",
              "   385392376,\n",
              "   818459139,\n",
              "   3778137224,\n",
              "   1062750627,\n",
              "   2399467628,\n",
              "   1559397529,\n",
              "   3005552705,\n",
              "   2633291327,\n",
              "   1733861963,\n",
              "   2733467792,\n",
              "   1350333277,\n",
              "   270780933,\n",
              "   3523328611],\n",
              "  'values': [0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.08113590263691683,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [3523328611,\n",
              "   4086277996,\n",
              "   2876684594,\n",
              "   1486317183,\n",
              "   385392376,\n",
              "   2399467628,\n",
              "   4131889752,\n",
              "   1296157733,\n",
              "   4158184310,\n",
              "   1909934694,\n",
              "   2263091519,\n",
              "   125777136,\n",
              "   3985184762,\n",
              "   648501015,\n",
              "   1372955919,\n",
              "   504851561,\n",
              "   3510466679,\n",
              "   640124220,\n",
              "   270780933,\n",
              "   818459139,\n",
              "   3778137224,\n",
              "   1786548735,\n",
              "   570652574,\n",
              "   3234527682,\n",
              "   1152900861,\n",
              "   97992994,\n",
              "   1299890214,\n",
              "   943451358,\n",
              "   3284422637,\n",
              "   1545193637,\n",
              "   2231220596,\n",
              "   2541144706,\n",
              "   1999194864,\n",
              "   771713658,\n",
              "   4071218396,\n",
              "   1336003538,\n",
              "   655540619,\n",
              "   3664949805,\n",
              "   1986137636,\n",
              "   1737333554,\n",
              "   983281070],\n",
              "  'values': [0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555]},\n",
              " {'indices': [1737333554,\n",
              "   983281070,\n",
              "   3286500216,\n",
              "   2821442271,\n",
              "   2236453805,\n",
              "   1677271114,\n",
              "   1986137636,\n",
              "   3881069374,\n",
              "   2557986934,\n",
              "   3619432518,\n",
              "   2150562353,\n",
              "   958659146,\n",
              "   65094886,\n",
              "   2585038467,\n",
              "   553238108,\n",
              "   2301044897,\n",
              "   1034183227,\n",
              "   1053941712,\n",
              "   1563317370,\n",
              "   3143659061,\n",
              "   520409122,\n",
              "   2386266869,\n",
              "   1673618911,\n",
              "   2177509083,\n",
              "   1489355757,\n",
              "   2194093370,\n",
              "   3346195724,\n",
              "   3233814315,\n",
              "   1590456296,\n",
              "   3935005093,\n",
              "   125777136,\n",
              "   3743430521,\n",
              "   2361787631,\n",
              "   645267917,\n",
              "   648501015,\n",
              "   3852803777],\n",
              "  'values': [0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.045766590389016024,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.08752735229759301,\n",
              "   0.045766590389016024,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726,\n",
              "   0.0234192037470726]},\n",
              " {'indices': [645267917,\n",
              "   648501015,\n",
              "   3852803777,\n",
              "   1774861213,\n",
              "   1489355757,\n",
              "   520409122,\n",
              "   1053941712,\n",
              "   125777136,\n",
              "   2401651339,\n",
              "   442064690,\n",
              "   2365762688,\n",
              "   1508140589,\n",
              "   3125914747,\n",
              "   1090888193,\n",
              "   275574541,\n",
              "   4051061832,\n",
              "   2257684172,\n",
              "   358389376,\n",
              "   3066577729,\n",
              "   1701593959,\n",
              "   3989698211,\n",
              "   2695422133,\n",
              "   629153050,\n",
              "   275763029,\n",
              "   1267828134,\n",
              "   1087278016,\n",
              "   2585038467,\n",
              "   640124220,\n",
              "   2929822643,\n",
              "   881664426,\n",
              "   385392376,\n",
              "   1022332462,\n",
              "   1563317370,\n",
              "   2932171215,\n",
              "   4071218396,\n",
              "   2456699241,\n",
              "   698882315,\n",
              "   1396786097,\n",
              "   548955463,\n",
              "   1131517175,\n",
              "   4276043801,\n",
              "   2292879366,\n",
              "   3124259531,\n",
              "   2758886917,\n",
              "   1684568639,\n",
              "   3874893223,\n",
              "   824622370,\n",
              "   3026269382,\n",
              "   2002612373,\n",
              "   2829998679,\n",
              "   403150886,\n",
              "   1564510983,\n",
              "   4238889041,\n",
              "   3699493211],\n",
              "  'values': [0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.036101083032490974,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647,\n",
              "   0.01838235294117647]},\n",
              " {'indices': [4238889041,\n",
              "   3699493211,\n",
              "   1563317370,\n",
              "   3469675055,\n",
              "   2541144706,\n",
              "   2095749492,\n",
              "   4144206424,\n",
              "   3987085787,\n",
              "   31598678,\n",
              "   3385369385,\n",
              "   2695422133,\n",
              "   339478471,\n",
              "   2177509083,\n",
              "   1005783980,\n",
              "   1494846643,\n",
              "   125777136,\n",
              "   1564510983,\n",
              "   3066577729,\n",
              "   4030957741,\n",
              "   2421602144,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   553238108,\n",
              "   330588669,\n",
              "   436751995,\n",
              "   624846797,\n",
              "   1936903680,\n",
              "   3774761357,\n",
              "   275574541,\n",
              "   640124220,\n",
              "   943451358,\n",
              "   3096200065,\n",
              "   520409122,\n",
              "   3985184762,\n",
              "   3631500069,\n",
              "   97992994,\n",
              "   648501015,\n",
              "   1672272942,\n",
              "   3831243209,\n",
              "   397493074,\n",
              "   310274930,\n",
              "   149223823,\n",
              "   2236453805],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [2236453805,\n",
              "   275574541,\n",
              "   2679053747,\n",
              "   358389376,\n",
              "   4160846599,\n",
              "   2851137560,\n",
              "   2733467792,\n",
              "   1733861963,\n",
              "   2295538017,\n",
              "   125777136,\n",
              "   2150507160,\n",
              "   3854588405,\n",
              "   1299890214,\n",
              "   943451358,\n",
              "   1128198904,\n",
              "   4071218396,\n",
              "   771713658,\n",
              "   1169667353,\n",
              "   1909934694,\n",
              "   1214258741,\n",
              "   1308688855,\n",
              "   648501015,\n",
              "   734978415,\n",
              "   3631500069,\n",
              "   97992994,\n",
              "   3662309742,\n",
              "   3419414488,\n",
              "   3632927698,\n",
              "   1336003538,\n",
              "   4158184310,\n",
              "   3143659061,\n",
              "   3962831319,\n",
              "   397493074],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.08583690987124463,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.10504201680672269,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [1909934694,\n",
              "   648501015,\n",
              "   397493074,\n",
              "   310274930,\n",
              "   149223823,\n",
              "   943451358,\n",
              "   3096200065,\n",
              "   2940655442,\n",
              "   3425584443,\n",
              "   3774761357,\n",
              "   1486317183,\n",
              "   1018887719,\n",
              "   2095749492,\n",
              "   3540170031,\n",
              "   881664426,\n",
              "   385392376,\n",
              "   2359104239,\n",
              "   1049114592,\n",
              "   4160846599,\n",
              "   964114575,\n",
              "   65094886,\n",
              "   824622370,\n",
              "   640124220,\n",
              "   624846797,\n",
              "   2541144706,\n",
              "   3852803777,\n",
              "   734978415,\n",
              "   520409122,\n",
              "   645267917,\n",
              "   4086277996,\n",
              "   2876684594,\n",
              "   3987085787,\n",
              "   3743430521,\n",
              "   442064690],\n",
              "  'values': [0.09111617312072894,\n",
              "   0.06993006993006994,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.06993006993006994,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.0477326968973747,\n",
              "   0.0477326968973747,\n",
              "   0.0477326968973747,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125,\n",
              "   0.02444987775061125]},\n",
              " {'indices': [3987085787,\n",
              "   3743430521,\n",
              "   442064690,\n",
              "   3720223994,\n",
              "   1909934694,\n",
              "   2501256772,\n",
              "   1997743268,\n",
              "   1564510983,\n",
              "   1222283305,\n",
              "   4187000482,\n",
              "   275574541,\n",
              "   953824239,\n",
              "   1296157733,\n",
              "   4086277996,\n",
              "   4146668087,\n",
              "   1762032986,\n",
              "   1308688855,\n",
              "   824622370,\n",
              "   624846797,\n",
              "   1049114592,\n",
              "   2541144706,\n",
              "   2095749492,\n",
              "   4160846599,\n",
              "   2099560782,\n",
              "   818459139,\n",
              "   1394226660,\n",
              "   553238108,\n",
              "   881664426,\n",
              "   400114344,\n",
              "   3465648511,\n",
              "   3951743159,\n",
              "   1594086824,\n",
              "   3222141584,\n",
              "   192565064,\n",
              "   1504740848,\n",
              "   125777136,\n",
              "   3985184762,\n",
              "   97992994,\n",
              "   648501015,\n",
              "   832098838,\n",
              "   1397977347,\n",
              "   3543704982,\n",
              "   1105706408,\n",
              "   19522071,\n",
              "   4032787524],\n",
              "  'values': [0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.04395604395604396,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955,\n",
              "   0.02247191011235955]},\n",
              " {'indices': [1397977347,\n",
              "   3543704982,\n",
              "   1105706408,\n",
              "   19522071,\n",
              "   4032787524,\n",
              "   722829366,\n",
              "   436751995,\n",
              "   275574541,\n",
              "   339478471,\n",
              "   125777136,\n",
              "   3985184762,\n",
              "   3631500069,\n",
              "   97992994,\n",
              "   3194111925,\n",
              "   2177509083,\n",
              "   1308688855,\n",
              "   2333687351,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   3355546462,\n",
              "   824622370,\n",
              "   648501015,\n",
              "   2484513939,\n",
              "   2566440236,\n",
              "   2263091519,\n",
              "   624846797,\n",
              "   553238108,\n",
              "   3420564022,\n",
              "   1975257448,\n",
              "   2344072812,\n",
              "   2473556485,\n",
              "   3023675989,\n",
              "   134749957,\n",
              "   3398935115,\n",
              "   2064885619,\n",
              "   1364383302,\n",
              "   3143659061,\n",
              "   3234527682,\n",
              "   1062750627,\n",
              "   1253056104],\n",
              "  'values': [0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.07692307692307693,\n",
              "   0.09433962264150944,\n",
              "   0.02040816326530612,\n",
              "   0.058823529411764705,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612]},\n",
              " {'indices': [1253056104,\n",
              "   1308688855,\n",
              "   1909934694,\n",
              "   824622370,\n",
              "   264741300,\n",
              "   19522071,\n",
              "   446656910,\n",
              "   3143659061,\n",
              "   1059399276,\n",
              "   3886613225,\n",
              "   1774861213,\n",
              "   2236453805,\n",
              "   2633291327,\n",
              "   3419414488,\n",
              "   275574541,\n",
              "   2695422133,\n",
              "   4086277996,\n",
              "   2876684594,\n",
              "   645267917,\n",
              "   4158184310,\n",
              "   1034183227,\n",
              "   2165730276,\n",
              "   3053812161,\n",
              "   881664426,\n",
              "   553238108,\n",
              "   818459139,\n",
              "   3856021305,\n",
              "   82883857,\n",
              "   3928038441,\n",
              "   1350333277,\n",
              "   3040819345,\n",
              "   2691201840,\n",
              "   2177509083,\n",
              "   1198964877,\n",
              "   3449948193,\n",
              "   3172858508,\n",
              "   100532018,\n",
              "   3474293978,\n",
              "   1489355757,\n",
              "   125777136,\n",
              "   2910905616,\n",
              "   2391722386,\n",
              "   4071218396,\n",
              "   2957388266,\n",
              "   2095749492,\n",
              "   2541144706],\n",
              "  'values': [0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.07968127490039842,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104]},\n",
              " {'indices': [2095749492,\n",
              "   2541144706,\n",
              "   1563718956,\n",
              "   881664426,\n",
              "   3313823817,\n",
              "   1909934694,\n",
              "   818459139,\n",
              "   670727360,\n",
              "   4292301820,\n",
              "   4158184310,\n",
              "   3420564022,\n",
              "   963753705,\n",
              "   3023675989,\n",
              "   1325492893,\n",
              "   4291385346,\n",
              "   1491351846,\n",
              "   3326482461,\n",
              "   1053941712,\n",
              "   3852803777,\n",
              "   3197025135,\n",
              "   2177509083,\n",
              "   778446678,\n",
              "   3792961156,\n",
              "   1774861213,\n",
              "   3987085787,\n",
              "   442064690,\n",
              "   997512866,\n",
              "   100532018,\n",
              "   3135012503,\n",
              "   4071218396,\n",
              "   3143659061,\n",
              "   3030143974,\n",
              "   953824239,\n",
              "   2202014194,\n",
              "   2236453805,\n",
              "   824622370,\n",
              "   1267455128,\n",
              "   2099560782,\n",
              "   2892062428,\n",
              "   3286166600,\n",
              "   3174900812,\n",
              "   3355546462],\n",
              "  'values': [0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [3143659061,\n",
              "   3355546462,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   100532018,\n",
              "   4086277996,\n",
              "   2141082694,\n",
              "   3987085787,\n",
              "   3852803777,\n",
              "   3197025135,\n",
              "   645267917,\n",
              "   648501015,\n",
              "   3796669908,\n",
              "   446319932,\n",
              "   824622370,\n",
              "   1267455128,\n",
              "   1536651520,\n",
              "   2236453805,\n",
              "   1399735160,\n",
              "   2876684594,\n",
              "   1774861213,\n",
              "   125777136,\n",
              "   3985184762,\n",
              "   3758910623,\n",
              "   97992994,\n",
              "   640124220,\n",
              "   2510335750,\n",
              "   4146668087,\n",
              "   3631500069,\n",
              "   2643791821,\n",
              "   330588669,\n",
              "   1296157733,\n",
              "   497334170,\n",
              "   4173428777,\n",
              "   4051061832,\n",
              "   3326482461,\n",
              "   643573837,\n",
              "   436751995],\n",
              "  'values': [0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.08113590263691683,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [1909934694,\n",
              "   330588669,\n",
              "   436751995,\n",
              "   3852803777,\n",
              "   2534330448,\n",
              "   645267917,\n",
              "   387750413,\n",
              "   648501015,\n",
              "   2257684172,\n",
              "   1774861213,\n",
              "   1296157733,\n",
              "   3420564022,\n",
              "   881664426,\n",
              "   1053941712,\n",
              "   2932171215,\n",
              "   1563317370,\n",
              "   3631500069,\n",
              "   3313823817,\n",
              "   818459139,\n",
              "   670727360,\n",
              "   1267455128,\n",
              "   1214258741,\n",
              "   264741300,\n",
              "   824622370,\n",
              "   624846797,\n",
              "   1049114592,\n",
              "   2095749492,\n",
              "   1364383302,\n",
              "   2325784421,\n",
              "   3720223994,\n",
              "   62284129,\n",
              "   3419414488,\n",
              "   275574541,\n",
              "   3971053758,\n",
              "   3729500624,\n",
              "   1308688855,\n",
              "   491140522,\n",
              "   3570117707,\n",
              "   1975257448,\n",
              "   3475938527,\n",
              "   832098838,\n",
              "   112136910,\n",
              "   4158184310],\n",
              "  'values': [0.07827788649706457,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.07827788649706457,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.059880239520958084,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788]},\n",
              " {'indices': [112136910,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   2095749492,\n",
              "   3475938527,\n",
              "   2957388266,\n",
              "   1477105254,\n",
              "   3852803777,\n",
              "   3985184762,\n",
              "   3197025135,\n",
              "   2177509083,\n",
              "   3469107893,\n",
              "   1846065449,\n",
              "   640124220,\n",
              "   4086277996,\n",
              "   2876684594,\n",
              "   3570117707,\n",
              "   4027033650,\n",
              "   194714415,\n",
              "   553238108,\n",
              "   1758470515,\n",
              "   1774861213,\n",
              "   2236453805,\n",
              "   3729500624,\n",
              "   824622370,\n",
              "   818459139,\n",
              "   602572328,\n",
              "   2840212248,\n",
              "   881664426,\n",
              "   3967169986,\n",
              "   1308688855,\n",
              "   150695120,\n",
              "   3792961156,\n",
              "   3180462103,\n",
              "   2210721991,\n",
              "   749129358,\n",
              "   311579140,\n",
              "   3181939508,\n",
              "   388471277,\n",
              "   2954459956,\n",
              "   2407948362,\n",
              "   4176811240,\n",
              "   2706808493,\n",
              "   3018291027,\n",
              "   1175800309,\n",
              "   3642524058,\n",
              "   4227742184,\n",
              "   2600936954,\n",
              "   3537305573,\n",
              "   1275100136,\n",
              "   2510335750],\n",
              "  'values': [0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463]},\n",
              " {'indices': [3018291027,\n",
              "   1175800309,\n",
              "   3642524058,\n",
              "   4227742184,\n",
              "   2600936954,\n",
              "   3537305573,\n",
              "   1275100136,\n",
              "   2510335750,\n",
              "   264741300,\n",
              "   4052411414,\n",
              "   1479036434,\n",
              "   1394226660,\n",
              "   916704248,\n",
              "   2152937842,\n",
              "   749129358,\n",
              "   2484513939,\n",
              "   1520550099,\n",
              "   3428733953,\n",
              "   2407948362,\n",
              "   4131889752,\n",
              "   613148321,\n",
              "   3786971068,\n",
              "   3182414933,\n",
              "   3530670207,\n",
              "   3180462103,\n",
              "   2055324972,\n",
              "   2263091519,\n",
              "   2407597162,\n",
              "   3538239229,\n",
              "   3778137224,\n",
              "   1836344936,\n",
              "   2626552127,\n",
              "   4025975524,\n",
              "   2953872454,\n",
              "   535856140,\n",
              "   1748990464,\n",
              "   3566684679,\n",
              "   2526975768,\n",
              "   505928984,\n",
              "   3896036072,\n",
              "   1811445730,\n",
              "   2236453805,\n",
              "   2478534286,\n",
              "   3420564022,\n",
              "   2733467792,\n",
              "   275574541,\n",
              "   436751995,\n",
              "   1774861213,\n",
              "   3288097382,\n",
              "   3543704982,\n",
              "   818459139,\n",
              "   670727360,\n",
              "   832098838,\n",
              "   881664426,\n",
              "   1918674444,\n",
              "   2929822643,\n",
              "   1053747404,\n",
              "   1336003538,\n",
              "   97992994,\n",
              "   2541144706,\n",
              "   125777136,\n",
              "   151069542,\n",
              "   4086277996,\n",
              "   2141082694,\n",
              "   824622370,\n",
              "   4146668087,\n",
              "   3631500069,\n",
              "   75784423],\n",
              "  'values': [0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.03636363636363636,\n",
              "   0.03636363636363636,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.03636363636363636,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.04790419161676647,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.024539877300613498,\n",
              "   0.024539877300613498,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.024539877300613498,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204,\n",
              "   0.012422360248447204]},\n",
              " {'indices': [824622370,\n",
              "   4146668087,\n",
              "   3631500069,\n",
              "   75784423,\n",
              "   436751995,\n",
              "   1774861213,\n",
              "   645267917,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   97992994,\n",
              "   648501015,\n",
              "   1489355757,\n",
              "   315674746,\n",
              "   3677720983,\n",
              "   3325228835,\n",
              "   1687946627,\n",
              "   3743430521,\n",
              "   2105217563,\n",
              "   125777136,\n",
              "   3786633265,\n",
              "   3234527682,\n",
              "   2578949454,\n",
              "   991601241,\n",
              "   2876684594,\n",
              "   590228230,\n",
              "   4062668894,\n",
              "   2202014194,\n",
              "   1563317370,\n",
              "   407983593,\n",
              "   3979495055,\n",
              "   2095749492,\n",
              "   1598346136,\n",
              "   504851561,\n",
              "   4086277996,\n",
              "   1005783980,\n",
              "   2344072812,\n",
              "   3063998852,\n",
              "   1308688855,\n",
              "   4068491112,\n",
              "   818459139,\n",
              "   602572328,\n",
              "   4160846599],\n",
              "  'values': [0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [818459139,\n",
              "   602572328,\n",
              "   4158184310,\n",
              "   4160846599,\n",
              "   1005783980,\n",
              "   3063998852,\n",
              "   1665612518,\n",
              "   1909934694,\n",
              "   2887480931,\n",
              "   1350333277,\n",
              "   2443146540,\n",
              "   1564510983,\n",
              "   2773108416,\n",
              "   640124220,\n",
              "   1750676654,\n",
              "   824622370,\n",
              "   1706587157,\n",
              "   442064690,\n",
              "   3444258836,\n",
              "   553238108,\n",
              "   881664426,\n",
              "   1925969450,\n",
              "   3471348524,\n",
              "   1253056104,\n",
              "   332723732,\n",
              "   2842073998,\n",
              "   3286166600,\n",
              "   1590456296,\n",
              "   1308688855,\n",
              "   4086277996,\n",
              "   4192298249,\n",
              "   3683798579,\n",
              "   4071218396,\n",
              "   3143659061,\n",
              "   2695422133,\n",
              "   2786759275,\n",
              "   3289946745,\n",
              "   3778852250,\n",
              "   2510335750,\n",
              "   3194111925,\n",
              "   3354572132,\n",
              "   2194093370,\n",
              "   2542857079,\n",
              "   4051061832,\n",
              "   2263091519,\n",
              "   4146668087],\n",
              "  'values': [0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.07079646017699115,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728]},\n",
              " {'indices': [2263091519,\n",
              "   824622370,\n",
              "   4146668087,\n",
              "   1583132830,\n",
              "   3562189416,\n",
              "   553238108,\n",
              "   2957388266,\n",
              "   3444258836,\n",
              "   881664426,\n",
              "   4183835765,\n",
              "   659326392,\n",
              "   2932171215,\n",
              "   2851137560,\n",
              "   3850563250,\n",
              "   622902531,\n",
              "   4006988776,\n",
              "   2687174735,\n",
              "   173740189,\n",
              "   4071218396,\n",
              "   3962831319,\n",
              "   125777136,\n",
              "   640124220,\n",
              "   609543353,\n",
              "   1246395387,\n",
              "   3985184762,\n",
              "   1364383302,\n",
              "   795485492,\n",
              "   3234527682,\n",
              "   2257684172,\n",
              "   408935845,\n",
              "   3786633265,\n",
              "   3096200065,\n",
              "   2456699241,\n",
              "   1598346136,\n",
              "   3476796706,\n",
              "   2059378300,\n",
              "   4086277996,\n",
              "   2141082694,\n",
              "   700799762],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.10504201680672269,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [4071218396,\n",
              "   700799762,\n",
              "   125777136,\n",
              "   3411418812,\n",
              "   3172858508,\n",
              "   3953363255,\n",
              "   640124220,\n",
              "   2932171215,\n",
              "   4086277996,\n",
              "   659326392,\n",
              "   1987842029,\n",
              "   4238889041,\n",
              "   2541144706,\n",
              "   760117322,\n",
              "   3922242777,\n",
              "   2095749492,\n",
              "   339478471,\n",
              "   2311206319,\n",
              "   1893044414,\n",
              "   648501015,\n",
              "   536145832,\n",
              "   3066577729,\n",
              "   624846797,\n",
              "   3194111925,\n",
              "   1909934694,\n",
              "   4158184310,\n",
              "   553238108,\n",
              "   100532018,\n",
              "   2058205993,\n",
              "   881664426,\n",
              "   2311717350,\n",
              "   2958420989,\n",
              "   2836249828,\n",
              "   1979787966,\n",
              "   4116694779,\n",
              "   65977483,\n",
              "   1162154495,\n",
              "   3380305552,\n",
              "   3234527682,\n",
              "   1727802518,\n",
              "   2871008955,\n",
              "   2837188459,\n",
              "   989116115],\n",
              "  'values': [0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.04672897196261683,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555,\n",
              "   0.023923444976076555]},\n",
              " {'indices': [2871008955,\n",
              "   2837188459,\n",
              "   989116115,\n",
              "   3337197764,\n",
              "   4006988776,\n",
              "   2745649079,\n",
              "   488935008,\n",
              "   1630975408,\n",
              "   2855734398,\n",
              "   1687577678,\n",
              "   3820896027,\n",
              "   1666820582,\n",
              "   3874841413,\n",
              "   149650409,\n",
              "   1202469361,\n",
              "   653774019,\n",
              "   4174290103,\n",
              "   1978991596,\n",
              "   2355389064,\n",
              "   1455707387,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   1612531086,\n",
              "   1034394088,\n",
              "   1854078523,\n",
              "   1309863403,\n",
              "   2935326242,\n",
              "   2484513939,\n",
              "   1682245331,\n",
              "   1917768591,\n",
              "   3800896210,\n",
              "   3243552961,\n",
              "   1537103009,\n",
              "   3809349619,\n",
              "   3516514289,\n",
              "   1293336596,\n",
              "   3589965190,\n",
              "   2950220234,\n",
              "   2344072812,\n",
              "   629533374,\n",
              "   4137710966,\n",
              "   2334776983,\n",
              "   1444314200],\n",
              "  'values': [0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.03929273084479371,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064,\n",
              "   0.02004008016032064]},\n",
              " {'indices': [2334776983,\n",
              "   1309863403,\n",
              "   1444314200,\n",
              "   412017637,\n",
              "   609543353,\n",
              "   4109718427,\n",
              "   3205086630,\n",
              "   197807508,\n",
              "   1524915916,\n",
              "   3981855590,\n",
              "   3597663484,\n",
              "   422208903,\n",
              "   4020980221,\n",
              "   1868044035,\n",
              "   1883800778,\n",
              "   3800896210,\n",
              "   1544235557,\n",
              "   2811973580,\n",
              "   258882976,\n",
              "   2176769521,\n",
              "   846066356,\n",
              "   2504924635,\n",
              "   2169313169,\n",
              "   737230783,\n",
              "   281657603,\n",
              "   378174453,\n",
              "   813560164,\n",
              "   254839692,\n",
              "   3595204732,\n",
              "   4218656810,\n",
              "   270780933,\n",
              "   3489784202,\n",
              "   553238108,\n",
              "   1164826063,\n",
              "   2263326288,\n",
              "   629533374,\n",
              "   1996750941,\n",
              "   3451163774,\n",
              "   2560416690,\n",
              "   4257916789,\n",
              "   673586547,\n",
              "   275178387,\n",
              "   3672272643,\n",
              "   2950293008,\n",
              "   2745649079,\n",
              "   385463627,\n",
              "   2824940628,\n",
              "   1162154495,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   2301044897,\n",
              "   761976698],\n",
              "  'values': [0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463]},\n",
              " {'indices': [3650065742,\n",
              "   1196854555,\n",
              "   2301044897,\n",
              "   761976698,\n",
              "   1034394088,\n",
              "   629533374,\n",
              "   72180827,\n",
              "   2334776983,\n",
              "   1721061591,\n",
              "   1444314200,\n",
              "   1841201231,\n",
              "   4006988776,\n",
              "   1959167377,\n",
              "   1506997547,\n",
              "   197807508,\n",
              "   4206423020,\n",
              "   3981855590,\n",
              "   2922379624,\n",
              "   2119238398,\n",
              "   91759785,\n",
              "   804460016,\n",
              "   1098657283,\n",
              "   3765376047,\n",
              "   3098576852,\n",
              "   1555494940,\n",
              "   884471572,\n",
              "   927860567,\n",
              "   3934511974,\n",
              "   3569226459,\n",
              "   1977863934,\n",
              "   759214369,\n",
              "   1439614754,\n",
              "   4041998218,\n",
              "   3432358790,\n",
              "   2135250061,\n",
              "   1193012878,\n",
              "   1615792474,\n",
              "   3178849318,\n",
              "   270780933,\n",
              "   3647400625,\n",
              "   2095749492,\n",
              "   1611841122,\n",
              "   3008497247],\n",
              "  'values': [0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [2095749492,\n",
              "   1611841122,\n",
              "   2135250061,\n",
              "   884471572,\n",
              "   3008497247,\n",
              "   3537131429,\n",
              "   3337365784,\n",
              "   1012258574,\n",
              "   891192980,\n",
              "   2752207398,\n",
              "   3432495100,\n",
              "   3915866596,\n",
              "   2247749524,\n",
              "   3018615358,\n",
              "   2501919960,\n",
              "   3275843443,\n",
              "   609543353,\n",
              "   3556558201,\n",
              "   1856538418,\n",
              "   3250766381,\n",
              "   521893222,\n",
              "   1435077832,\n",
              "   3336724273,\n",
              "   3005474304,\n",
              "   1458569306,\n",
              "   3487894951,\n",
              "   4156701178,\n",
              "   2690197783,\n",
              "   273066799,\n",
              "   696559717,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   629533374,\n",
              "   18664153,\n",
              "   2139336747,\n",
              "   3066577729,\n",
              "   2650797237,\n",
              "   779789755,\n",
              "   3999900376,\n",
              "   197807508,\n",
              "   1464654873],\n",
              "  'values': [0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612]},\n",
              " {'indices': [2690197783,\n",
              "   273066799,\n",
              "   696559717,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   629533374,\n",
              "   18664153,\n",
              "   2139336747,\n",
              "   3275843443,\n",
              "   3066577729,\n",
              "   2650797237,\n",
              "   779789755,\n",
              "   3999900376,\n",
              "   197807508,\n",
              "   1464654873,\n",
              "   3981855590,\n",
              "   3892058430,\n",
              "   2267101260,\n",
              "   609543353,\n",
              "   2198099337,\n",
              "   422208903,\n",
              "   4020980221,\n",
              "   1868044035,\n",
              "   3799337368,\n",
              "   3800896210,\n",
              "   3816991351,\n",
              "   338167866,\n",
              "   2534815797,\n",
              "   1321536731,\n",
              "   3719150348,\n",
              "   653926039,\n",
              "   1012258574,\n",
              "   241803172,\n",
              "   407704269,\n",
              "   766949965,\n",
              "   491140522,\n",
              "   515089360,\n",
              "   1771061213,\n",
              "   781931119,\n",
              "   1020437592,\n",
              "   1905221157,\n",
              "   41739140,\n",
              "   125777136,\n",
              "   1202643662,\n",
              "   2257684172,\n",
              "   1893044414,\n",
              "   2236453805,\n",
              "   1289061206,\n",
              "   22917276,\n",
              "   2501919960,\n",
              "   1664868690,\n",
              "   989116115],\n",
              "  'values': [0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728,\n",
              "   0.03669724770642202,\n",
              "   0.018691588785046728,\n",
              "   0.018691588785046728]},\n",
              " {'indices': [989116115,\n",
              "   1202643662,\n",
              "   2501919960,\n",
              "   609543353,\n",
              "   2119238398,\n",
              "   1789020513,\n",
              "   1955864723,\n",
              "   4049471024,\n",
              "   197807508,\n",
              "   2682182922,\n",
              "   3800896210,\n",
              "   1774054858,\n",
              "   3702646756,\n",
              "   1155045541,\n",
              "   422052908,\n",
              "   1733729088,\n",
              "   4006988776,\n",
              "   270780933,\n",
              "   3559133972,\n",
              "   2301044897,\n",
              "   629533374,\n",
              "   907601888,\n",
              "   2334776983,\n",
              "   1444314200,\n",
              "   79735003,\n",
              "   2343679677,\n",
              "   687308760,\n",
              "   422208903,\n",
              "   4020980221,\n",
              "   2852861332,\n",
              "   3150645931,\n",
              "   1309863403,\n",
              "   1868044035,\n",
              "   185267246,\n",
              "   1031919918,\n",
              "   4043503531,\n",
              "   965795621,\n",
              "   908059709,\n",
              "   457688939,\n",
              "   3913993219,\n",
              "   1907066230,\n",
              "   1939853753,\n",
              "   3717335183,\n",
              "   685309509,\n",
              "   1081635533,\n",
              "   441050101,\n",
              "   4002386100,\n",
              "   29938846,\n",
              "   949492066,\n",
              "   2678323572,\n",
              "   1180146263,\n",
              "   187103058,\n",
              "   3731327931,\n",
              "   1087744415,\n",
              "   1418598973],\n",
              "  'values': [0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.051546391752577324,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824]},\n",
              " {'indices': [187103058,\n",
              "   3731327931,\n",
              "   1087744415,\n",
              "   1418598973,\n",
              "   1707350732,\n",
              "   791735855,\n",
              "   2828350884,\n",
              "   2650797237,\n",
              "   149060006,\n",
              "   804460016,\n",
              "   883390095,\n",
              "   3324292644,\n",
              "   3368723024,\n",
              "   629533374,\n",
              "   2488251227,\n",
              "   2139336747,\n",
              "   3275843443,\n",
              "   481329573,\n",
              "   553238108,\n",
              "   989116115,\n",
              "   1202643662,\n",
              "   3708711684,\n",
              "   1739069269,\n",
              "   2157113562,\n",
              "   1207234426,\n",
              "   2267101260,\n",
              "   609543353,\n",
              "   2198099337,\n",
              "   422208903,\n",
              "   4020980221,\n",
              "   1868044035,\n",
              "   197807508,\n",
              "   3180462103,\n",
              "   744372458,\n",
              "   3758669267,\n",
              "   1019234111,\n",
              "   3677720983,\n",
              "   221386808,\n",
              "   1627368638,\n",
              "   90832388,\n",
              "   3277210626,\n",
              "   378174453,\n",
              "   3807156195,\n",
              "   2503871247,\n",
              "   1397373123,\n",
              "   524852419,\n",
              "   842430915,\n",
              "   446319932,\n",
              "   2943003715,\n",
              "   2449698989,\n",
              "   2315665429],\n",
              "  'values': [0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612]},\n",
              " {'indices': [378174453,\n",
              "   2315665429,\n",
              "   884471572,\n",
              "   3775966135,\n",
              "   3930888363,\n",
              "   738271952,\n",
              "   1975727636,\n",
              "   3099115666,\n",
              "   659036163,\n",
              "   515089360,\n",
              "   1495242551,\n",
              "   262760917,\n",
              "   2637546168,\n",
              "   1430125705,\n",
              "   2007913377,\n",
              "   3471745442,\n",
              "   1508140589,\n",
              "   4238889041,\n",
              "   989116115,\n",
              "   1289061206,\n",
              "   270780933,\n",
              "   3234527682,\n",
              "   553238108,\n",
              "   212808005,\n",
              "   1996750941,\n",
              "   3451163774,\n",
              "   3075297601,\n",
              "   264741300,\n",
              "   1575930469,\n",
              "   3800896210,\n",
              "   2078353033,\n",
              "   2748929750,\n",
              "   761976698,\n",
              "   1771061213,\n",
              "   1155045541,\n",
              "   2179848572,\n",
              "   4251704716,\n",
              "   3395913258,\n",
              "   2996671233,\n",
              "   1388932778,\n",
              "   2905275168,\n",
              "   496830140,\n",
              "   2940979805,\n",
              "   2139336747,\n",
              "   2961533103,\n",
              "   853122056,\n",
              "   2121584349,\n",
              "   1340347458,\n",
              "   543259558,\n",
              "   3775620926,\n",
              "   1775728044],\n",
              "  'values': [0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612]},\n",
              " {'indices': [543259558,\n",
              "   3775620926,\n",
              "   1775728044,\n",
              "   264741300,\n",
              "   4251704716,\n",
              "   2948455259,\n",
              "   884471572,\n",
              "   174685629,\n",
              "   3484407787,\n",
              "   401514366,\n",
              "   2045807628,\n",
              "   3485167083,\n",
              "   1321536731,\n",
              "   3800896210,\n",
              "   588210248,\n",
              "   2279902893,\n",
              "   2535026928,\n",
              "   2380688312,\n",
              "   2604486002,\n",
              "   2637546168,\n",
              "   2359104239,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   553238108,\n",
              "   3425508159,\n",
              "   3403498167,\n",
              "   504851561,\n",
              "   719045731,\n",
              "   4191350549,\n",
              "   1394226660,\n",
              "   3084497347,\n",
              "   2786385053,\n",
              "   2219246736,\n",
              "   82800614,\n",
              "   3161669527,\n",
              "   2564350943,\n",
              "   2187862112,\n",
              "   2899586618,\n",
              "   3915866596,\n",
              "   4089761956,\n",
              "   4246958034,\n",
              "   1943344364,\n",
              "   2639104761,\n",
              "   3310518706,\n",
              "   3840914573,\n",
              "   2855734398,\n",
              "   153011701,\n",
              "   4627470,\n",
              "   1036792120,\n",
              "   1197719001,\n",
              "   2513480436,\n",
              "   4284639390,\n",
              "   4049471024,\n",
              "   197807508],\n",
              "  'values': [0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.03496503496503497,\n",
              "   0.03496503496503497,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824]},\n",
              " {'indices': [1197719001,\n",
              "   2513480436,\n",
              "   4284639390,\n",
              "   4049471024,\n",
              "   197807508,\n",
              "   653774019,\n",
              "   4174290103,\n",
              "   660400430,\n",
              "   2468952573,\n",
              "   2195305700,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   719013046,\n",
              "   2471982452,\n",
              "   982556856,\n",
              "   1701701189,\n",
              "   629533374,\n",
              "   719859670,\n",
              "   2334776983,\n",
              "   1309863403,\n",
              "   1444314200,\n",
              "   412017637,\n",
              "   609543353,\n",
              "   2296008564,\n",
              "   1506997547,\n",
              "   1524915916,\n",
              "   3981855590,\n",
              "   1400299369,\n",
              "   422208903,\n",
              "   4020980221,\n",
              "   1868044035,\n",
              "   344790953,\n",
              "   217071724,\n",
              "   1321536731,\n",
              "   1152674778,\n",
              "   508305679,\n",
              "   3513329071,\n",
              "   137084899,\n",
              "   4091715614,\n",
              "   378174453,\n",
              "   3589965190,\n",
              "   125777136,\n",
              "   3284862352,\n",
              "   2278160816,\n",
              "   504851561,\n",
              "   1747721372,\n",
              "   553238108,\n",
              "   1164826063,\n",
              "   989116115,\n",
              "   4137505215,\n",
              "   880265190],\n",
              "  'values': [0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.054945054945054944,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463]},\n",
              " {'indices': [989116115,\n",
              "   4137505215,\n",
              "   880265190,\n",
              "   813259836,\n",
              "   2254107776,\n",
              "   43461414,\n",
              "   1573809,\n",
              "   2758889528,\n",
              "   102143549,\n",
              "   412787427,\n",
              "   553238108,\n",
              "   2257684172,\n",
              "   1893044414,\n",
              "   1955147705,\n",
              "   4154584606,\n",
              "   286434387,\n",
              "   1853176582,\n",
              "   629533374,\n",
              "   2501919960,\n",
              "   2139336747,\n",
              "   3275843443,\n",
              "   2592961336,\n",
              "   3566872252,\n",
              "   1904070401,\n",
              "   2876684594,\n",
              "   2245720737,\n",
              "   2502307765,\n",
              "   3835740180,\n",
              "   449741002,\n",
              "   2581599568,\n",
              "   2580097488,\n",
              "   4177595877,\n",
              "   1679100045,\n",
              "   3018737127,\n",
              "   3800896210,\n",
              "   1509277697,\n",
              "   481331329,\n",
              "   3424771412,\n",
              "   1780432506,\n",
              "   1223236950,\n",
              "   1293336596,\n",
              "   300413161,\n",
              "   504851561,\n",
              "   1455707387,\n",
              "   2225624884,\n",
              "   524852419,\n",
              "   404451581],\n",
              "  'values': [0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.058823529411764705,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.04,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612,\n",
              "   0.02040816326530612]},\n",
              " {'indices': [404451581,\n",
              "   2139336747,\n",
              "   3275843443,\n",
              "   34379837,\n",
              "   2206024373,\n",
              "   179760401,\n",
              "   1130829428,\n",
              "   2152058021,\n",
              "   1234720811,\n",
              "   3981855590,\n",
              "   3597663484,\n",
              "   2808114888,\n",
              "   1682104160,\n",
              "   4196162101,\n",
              "   1724271785,\n",
              "   3433931060,\n",
              "   3197978882,\n",
              "   2359104239,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   1321536731,\n",
              "   2575419383,\n",
              "   3800896210,\n",
              "   3108558791,\n",
              "   3475019488,\n",
              "   1189334739,\n",
              "   1551373038,\n",
              "   2528438356,\n",
              "   1171518223,\n",
              "   1076669682,\n",
              "   1293336596,\n",
              "   1314217647,\n",
              "   1455707387,\n",
              "   212808005,\n",
              "   1996750941,\n",
              "   3451163774,\n",
              "   613148321,\n",
              "   264741300,\n",
              "   2497134227,\n",
              "   3323502893,\n",
              "   4287218285,\n",
              "   3874408517,\n",
              "   1322003948,\n",
              "   3816061911,\n",
              "   2192922049,\n",
              "   944031007,\n",
              "   3544886112,\n",
              "   3312441868,\n",
              "   3524562480,\n",
              "   2409022403,\n",
              "   3459027589,\n",
              "   1995412393],\n",
              "  'values': [0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.03861003861003861,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.03861003861003861,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874,\n",
              "   0.01968503937007874]},\n",
              " {'indices': [2409022403,\n",
              "   3459027589,\n",
              "   1995412393,\n",
              "   2075248789,\n",
              "   2637546168,\n",
              "   1833634097,\n",
              "   2359104239,\n",
              "   285545133,\n",
              "   3935005093,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   553238108,\n",
              "   1691351615,\n",
              "   4054825975,\n",
              "   728487644,\n",
              "   3741620795,\n",
              "   3647400625,\n",
              "   2876684594,\n",
              "   2095749492,\n",
              "   3047429373,\n",
              "   2334776983,\n",
              "   3275843443,\n",
              "   3681035454,\n",
              "   3117178777,\n",
              "   1711251571,\n",
              "   2594023371,\n",
              "   1328615756,\n",
              "   4285011529,\n",
              "   2023443967,\n",
              "   385463627,\n",
              "   3427813681,\n",
              "   237353020,\n",
              "   1157887085,\n",
              "   1435077832,\n",
              "   3336724273,\n",
              "   3528409054,\n",
              "   3981855590,\n",
              "   3221627484,\n",
              "   2070772726,\n",
              "   2514386435,\n",
              "   2673099881,\n",
              "   557212525,\n",
              "   3888488261,\n",
              "   649096907,\n",
              "   3178962249],\n",
              "  'values': [0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.07827788649706457,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.04073319755600815,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788,\n",
              "   0.020790020790020788]},\n",
              " {'indices': [3888488261,\n",
              "   649096907,\n",
              "   3178962249,\n",
              "   884471572,\n",
              "   1013532565,\n",
              "   634720285,\n",
              "   2604486002,\n",
              "   4072748504,\n",
              "   1451453885,\n",
              "   663955784,\n",
              "   1555675492,\n",
              "   952259111,\n",
              "   1087744415,\n",
              "   760114740,\n",
              "   4245647333,\n",
              "   1508140589,\n",
              "   3019051052,\n",
              "   3850563250,\n",
              "   270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   553238108,\n",
              "   2943003715,\n",
              "   1615103833,\n",
              "   2378830330,\n",
              "   3800896210,\n",
              "   234736064,\n",
              "   1697289817,\n",
              "   639783596,\n",
              "   2032790449,\n",
              "   3693276247,\n",
              "   767998484,\n",
              "   1397600260,\n",
              "   2195305700,\n",
              "   518587678,\n",
              "   2996671233,\n",
              "   150695120,\n",
              "   4144206424,\n",
              "   2251694205],\n",
              "  'values': [0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.051020408163265314,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.051020408163265314,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192,\n",
              "   0.026178010471204192]},\n",
              " {'indices': [4144206424,\n",
              "   2251694205,\n",
              "   989509788,\n",
              "   1164826063,\n",
              "   2263326288,\n",
              "   629533374,\n",
              "   4096295326,\n",
              "   2139336747,\n",
              "   3275843443,\n",
              "   2177509083,\n",
              "   989116115,\n",
              "   3284862352,\n",
              "   1996750941,\n",
              "   3981855590,\n",
              "   1400299369,\n",
              "   153011701,\n",
              "   4627470,\n",
              "   1036792120,\n",
              "   1197719001,\n",
              "   2513480436,\n",
              "   4284639390,\n",
              "   4049471024,\n",
              "   197807508,\n",
              "   856687811,\n",
              "   884471572,\n",
              "   927860567,\n",
              "   1236050050,\n",
              "   818459139,\n",
              "   613148321,\n",
              "   553238108,\n",
              "   4185449961,\n",
              "   1394226660,\n",
              "   1296157733,\n",
              "   3617140732,\n",
              "   1909934694,\n",
              "   3031079984,\n",
              "   4158184310,\n",
              "   2932171215,\n",
              "   1504740848,\n",
              "   1376542356,\n",
              "   2532207530,\n",
              "   648501015,\n",
              "   3514215162,\n",
              "   640477688,\n",
              "   1563317370,\n",
              "   385392376,\n",
              "   737551030,\n",
              "   3543704982,\n",
              "   2295538017,\n",
              "   1554236172,\n",
              "   125777136,\n",
              "   3465648511,\n",
              "   2695422133,\n",
              "   755629816,\n",
              "   4251414675,\n",
              "   1070380000,\n",
              "   3117484998],\n",
              "  'values': [0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.051546391752577324,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824]},\n",
              " {'indices': [3465648511,\n",
              "   2695422133,\n",
              "   613148321,\n",
              "   755629816,\n",
              "   4251414675,\n",
              "   1070380000,\n",
              "   3117484998,\n",
              "   1400299369,\n",
              "   496426677,\n",
              "   1394226660,\n",
              "   3874893223,\n",
              "   3778137224,\n",
              "   2025509876,\n",
              "   3620677820,\n",
              "   3150645931,\n",
              "   4246786155,\n",
              "   2922379624,\n",
              "   3530670207,\n",
              "   4131889752,\n",
              "   2510335750,\n",
              "   388471277,\n",
              "   1296157733,\n",
              "   3903456136,\n",
              "   2906913618,\n",
              "   492661292,\n",
              "   3293566676,\n",
              "   794808985,\n",
              "   2547461524,\n",
              "   1874285967,\n",
              "   818459139,\n",
              "   2263091519,\n",
              "   553238108,\n",
              "   385392376,\n",
              "   2932171215,\n",
              "   3430258219,\n",
              "   2840212248,\n",
              "   1504740848,\n",
              "   2484513939,\n",
              "   648501015,\n",
              "   1786548735,\n",
              "   2733467792,\n",
              "   645267917,\n",
              "   1336003538,\n",
              "   1360744857,\n",
              "   3514215162,\n",
              "   640477688,\n",
              "   1563317370,\n",
              "   1554236172,\n",
              "   125777136,\n",
              "   2087367745,\n",
              "   2236453805,\n",
              "   3327252652,\n",
              "   245221680,\n",
              "   2633291327,\n",
              "   1028984916,\n",
              "   3971053758],\n",
              "  'values': [0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.04132231404958678,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.04132231404958678,\n",
              "   0.02793296089385475,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085,\n",
              "   0.0141643059490085]},\n",
              " {'indices': [1028984916,\n",
              "   3971053758,\n",
              "   320874481,\n",
              "   2542944140,\n",
              "   14784032,\n",
              "   3570117707,\n",
              "   553238108,\n",
              "   881664426,\n",
              "   4261322163,\n",
              "   1096360994,\n",
              "   818459139,\n",
              "   2560416690,\n",
              "   570652574,\n",
              "   640124220,\n",
              "   2932171215,\n",
              "   3377905009,\n",
              "   4071218396,\n",
              "   125777136,\n",
              "   4146668087,\n",
              "   1982334159,\n",
              "   2236453805,\n",
              "   2105217563,\n",
              "   3786633265,\n",
              "   1554236172,\n",
              "   3234527682,\n",
              "   3019051052,\n",
              "   1833634097,\n",
              "   2541144706,\n",
              "   245221680,\n",
              "   19522071,\n",
              "   663941294,\n",
              "   1571837593,\n",
              "   976863851,\n",
              "   3929887467,\n",
              "   97992994,\n",
              "   2069901329,\n",
              "   173740189,\n",
              "   3677720983],\n",
              "  'values': [0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.08264462809917356,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.06329113924050633,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.04310344827586207,\n",
              "   0.04310344827586207,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675,\n",
              "   0.022026431718061675]},\n",
              " {'indices': [173740189,\n",
              "   3677720983,\n",
              "   125777136,\n",
              "   3510466679,\n",
              "   3589965190,\n",
              "   3005552705,\n",
              "   150695120,\n",
              "   2932171215,\n",
              "   1336003538,\n",
              "   275574541,\n",
              "   3967169986,\n",
              "   1152900861,\n",
              "   818459139,\n",
              "   264741300,\n",
              "   640124220,\n",
              "   4079661781,\n",
              "   888000370,\n",
              "   24515841,\n",
              "   989116115,\n",
              "   2291919351,\n",
              "   1563718956,\n",
              "   1559397529,\n",
              "   385392376,\n",
              "   553238108,\n",
              "   867533374,\n",
              "   2560416690,\n",
              "   2236453805,\n",
              "   1399735160,\n",
              "   1774861213,\n",
              "   4158184310,\n",
              "   2315598161,\n",
              "   1394226660,\n",
              "   2263091519,\n",
              "   4176811240,\n",
              "   3985184762,\n",
              "   4034710138,\n",
              "   1338150097,\n",
              "   2105217563],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.12345679012345678,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " {'indices': [1338150097,\n",
              "   125777136,\n",
              "   2105217563,\n",
              "   2236453805,\n",
              "   1554236172,\n",
              "   2087367745,\n",
              "   2830457679,\n",
              "   4071218396,\n",
              "   1028984916,\n",
              "   1152900861,\n",
              "   1553167345,\n",
              "   2737868476,\n",
              "   492661292,\n",
              "   2236729753,\n",
              "   2633291327,\n",
              "   2345323206,\n",
              "   553238108,\n",
              "   385392376,\n",
              "   2025509876,\n",
              "   1807167981,\n",
              "   2743016522,\n",
              "   171266656,\n",
              "   3967169986,\n",
              "   2836570682,\n",
              "   2819132543,\n",
              "   881664426,\n",
              "   1733861963,\n",
              "   1563317370,\n",
              "   2295538017,\n",
              "   2542857079,\n",
              "   3313717465,\n",
              "   946828419,\n",
              "   2484513939,\n",
              "   3570117707,\n",
              "   192565064,\n",
              "   275574541,\n",
              "   4231297415,\n",
              "   3631500069,\n",
              "   4131135811,\n",
              "   3005552705],\n",
              "  'values': [0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.06097560975609757,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.041493775933609964,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104,\n",
              "   0.021186440677966104]},\n",
              " {'indices': [3631500069,\n",
              "   4131135811,\n",
              "   3005552705,\n",
              "   1733861963,\n",
              "   1563317370,\n",
              "   881664426,\n",
              "   385392376,\n",
              "   2012469550,\n",
              "   2484513939,\n",
              "   548313874,\n",
              "   3570117707,\n",
              "   570652574,\n",
              "   2305334529,\n",
              "   3887810730,\n",
              "   854880822,\n",
              "   1152900861,\n",
              "   1554236172,\n",
              "   818459139,\n",
              "   3075297601,\n",
              "   3420564022,\n",
              "   3396792551,\n",
              "   4189473447,\n",
              "   2391722386,\n",
              "   647677686,\n",
              "   125777136,\n",
              "   2542857079,\n",
              "   3313717465,\n",
              "   553238108,\n",
              "   150695120,\n",
              "   1818572693,\n",
              "   2743016522,\n",
              "   171266656,\n",
              "   580887246,\n",
              "   3181830330,\n",
              "   1026137023,\n",
              "   3597663484,\n",
              "   1852771076,\n",
              "   2633291327],\n",
              "  'values': [0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.06211180124223603,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.042283298097251586,\n",
              "   0.042283298097251586,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.06211180124223603,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944,\n",
              "   0.021598272138228944]},\n",
              " {'indices': [553238108,\n",
              "   881664426,\n",
              "   1554236172,\n",
              "   2087367745,\n",
              "   53184412,\n",
              "   2932171215,\n",
              "   1028984916,\n",
              "   3743737023,\n",
              "   1778032728,\n",
              "   2236453805,\n",
              "   2159421842,\n",
              "   4261322163,\n",
              "   1096360994,\n",
              "   1099939840,\n",
              "   2484513939,\n",
              "   3016322872,\n",
              "   2263091519,\n",
              "   2633291327,\n",
              "   2025509876,\n",
              "   1400299369,\n",
              "   3471348524,\n",
              "   385392376,\n",
              "   3129216100,\n",
              "   3465648511,\n",
              "   1818572693,\n",
              "   3377652727,\n",
              "   492661292,\n",
              "   3005552705,\n",
              "   3270687257,\n",
              "   1942290985,\n",
              "   2399467628,\n",
              "   818459139,\n",
              "   987377478,\n",
              "   2231220596,\n",
              "   3485312465,\n",
              "   4192846608,\n",
              "   640124220,\n",
              "   570652574],\n",
              "  'values': [0.03731343283582089,\n",
              "   0.03731343283582089,\n",
              "   0.03731343283582089,\n",
              "   0.054945054945054944,\n",
              "   0.019011406844106463,\n",
              "   0.054945054945054944,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.054945054945054944,\n",
              "   0.03731343283582089,\n",
              "   0.07194244604316546,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.03731343283582089,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463,\n",
              "   0.019011406844106463]},\n",
              " {'indices': [640124220,\n",
              "   3485312465,\n",
              "   3005552705,\n",
              "   570652574,\n",
              "   2273346096,\n",
              "   385392376,\n",
              "   664667393,\n",
              "   4795507,\n",
              "   2484513939,\n",
              "   3016322872,\n",
              "   2263091519,\n",
              "   3129216100,\n",
              "   3465648511,\n",
              "   2025509876,\n",
              "   3587378368,\n",
              "   1999194864,\n",
              "   3471348524,\n",
              "   1818572693,\n",
              "   1430088939,\n",
              "   553238108,\n",
              "   3377652727,\n",
              "   1028984916,\n",
              "   492661292,\n",
              "   3270687257,\n",
              "   1400299369,\n",
              "   2399467628,\n",
              "   2601157554,\n",
              "   881664426,\n",
              "   2257684172,\n",
              "   1774861213,\n",
              "   1296157733,\n",
              "   2165730276,\n",
              "   2345323206,\n",
              "   832098838,\n",
              "   3596807593],\n",
              "  'values': [0.018083182640144666,\n",
              "   0.0686106346483705,\n",
              "   0.03552397868561279,\n",
              "   0.0686106346483705,\n",
              "   0.018083182640144666,\n",
              "   0.08431703204047218,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.03552397868561279,\n",
              "   0.05235602094240838,\n",
              "   0.018083182640144666,\n",
              "   0.0686106346483705,\n",
              "   0.03552397868561279,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.03552397868561279,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.05235602094240838,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666]},\n",
              " {'indices': [3016322872,\n",
              "   2263091519,\n",
              "   192565064,\n",
              "   2257684172,\n",
              "   1774861213,\n",
              "   1296157733,\n",
              "   97992994,\n",
              "   2541144706,\n",
              "   1336003538,\n",
              "   275574541,\n",
              "   818459139,\n",
              "   3597663484,\n",
              "   2301044897,\n",
              "   881664426,\n",
              "   1554236172,\n",
              "   2182198932,\n",
              "   1195989500,\n",
              "   2932171215,\n",
              "   4795507,\n",
              "   2484513939,\n",
              "   2025509876,\n",
              "   1400299369,\n",
              "   3471348524,\n",
              "   3282398576,\n",
              "   1852771076,\n",
              "   3129216100,\n",
              "   3465648511,\n",
              "   987377478,\n",
              "   2273346096,\n",
              "   553238108,\n",
              "   4261322163,\n",
              "   3485312465,\n",
              "   125777136],\n",
              "  'values': [0.03552397868561279,\n",
              "   0.05235602094240838,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.0686106346483705,\n",
              "   0.018083182640144666,\n",
              "   0.05235602094240838,\n",
              "   0.05235602094240838,\n",
              "   0.05235602094240838,\n",
              "   0.05235602094240838,\n",
              "   0.05235602094240838,\n",
              "   0.0686106346483705,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.03552397868561279,\n",
              "   0.05235602094240838,\n",
              "   0.05235602094240838,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.018083182640144666,\n",
              "   0.03552397868561279,\n",
              "   0.018083182640144666]},\n",
              " {'indices': [2263091519,\n",
              "   3465648511,\n",
              "   2932171215,\n",
              "   125777136,\n",
              "   4176811240,\n",
              "   1296157733,\n",
              "   4158184310,\n",
              "   2315598161,\n",
              "   1394226660,\n",
              "   2175570781,\n",
              "   2484513939,\n",
              "   19522071,\n",
              "   264741300,\n",
              "   1767380095,\n",
              "   3923460179,\n",
              "   3729500624,\n",
              "   553238108,\n",
              "   3377652727,\n",
              "   3985184762,\n",
              "   1028984916,\n",
              "   1155045541,\n",
              "   4051061832,\n",
              "   1774861213,\n",
              "   2854372894,\n",
              "   3967169986,\n",
              "   824622370,\n",
              "   1267455128,\n",
              "   446319932,\n",
              "   4051297737,\n",
              "   881664426,\n",
              "   818459139,\n",
              "   3180462103,\n",
              "   1152900861,\n",
              "   2479842747,\n",
              "   1008711726,\n",
              "   832098838,\n",
              "   640124220,\n",
              "   4131889752,\n",
              "   2510335750,\n",
              "   4146668087,\n",
              "   270780933,\n",
              "   1897759866,\n",
              "   2236453805,\n",
              "   358389376,\n",
              "   1050319643,\n",
              "   284628886,\n",
              "   3743737023],\n",
              "  'values': [0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.051546391752577324,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.051546391752577324,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.06756756756756757,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.051546391752577324,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.03496503496503497,\n",
              "   0.03496503496503497,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824,\n",
              "   0.017793594306049824]},\n",
              " {'indices': [358389376,\n",
              "   1050319643,\n",
              "   284628886,\n",
              "   3743737023,\n",
              "   3758910623,\n",
              "   2903753601,\n",
              "   4158184310,\n",
              "   1909934694,\n",
              "   1665612518,\n",
              "   4160846599,\n",
              "   679262712,\n",
              "   818459139,\n",
              "   553238108],\n",
              "  'values': [0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693,\n",
              "   0.07692307692307693]}]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freshdisk_sembeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f495a3-37b8-4573-afca-3c8bfe6fb08f",
      "metadata": {
        "id": "02f495a3-37b8-4573-afca-3c8bfe6fb08f"
      },
      "outputs": [],
      "source": [
        "# We want the # of chunks per PDF to be equal to the # of sparse embeddings we've generated. Let's check that:\n",
        "\n",
        "assert len(freshdisk_sembeddings) == len(chunked_files.get('freshdisk'))\n",
        "assert len(hnsw_sembeddings) == len(chunked_files.get('hnsw'))\n",
        "assert len(ivfpq_sembeddings) == len(chunked_files.get('ivfpq'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece747e9-abc4-4289-aac2-b2fef0831339",
      "metadata": {
        "id": "ece747e9-abc4-4289-aac2-b2fef0831339"
      },
      "source": [
        "# Getting Our Embeddings into Pinecone\n",
        "\n",
        "Now that we have made our sparse and dense embeddings, it's time to index them into our Pinecone index.\n",
        "\n",
        "One thing to note is that only [p1 and s1 pods support hybrid search](https://docs.pinecone.io/docs/indexes). Since we're not concerned about high throughput for a demo, we'll go with s1, which is optimized for storage over throughput.\n",
        "\n",
        "Hybrid search indexes inherently also need `\"dotproduct\"` as their similarity `metric`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe1431b-82be-4318-9b79-b485234bf25c",
      "metadata": {
        "id": "afe1431b-82be-4318-9b79-b485234bf25c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from pinecone import PodSpec\n",
        "pc = Pinecone(\n",
        "   api_key=pinecone_api_key,\n",
        ")\n",
        "\n",
        "# choose a name for our index\n",
        "index_name = \"hybrid-search-demo-oct23\"\n",
        "\n",
        "# create our index\n",
        "pc.create_index(\n",
        "   name = index_name,\n",
        "   dimension = 384,  # must match the dimensionality of our (dense) vectors\n",
        "   metric = \"dotproduct\",\n",
        "   spec=PodSpec(\n",
        "        environment='gcp-starter'\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8840e747-8d7e-4911-8b76-73d7b852b15d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8840e747-8d7e-4911-8b76-73d7b852b15d",
        "outputId": "50410d03-fce6-4eb2-bf8a-812cf9341f21",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'host': 'hybrid-search-demo-oct23-ggbh3ob.svc.gcp-starter.pinecone.io',\n",
              " 'metric': 'dotproduct',\n",
              " 'name': 'hybrid-search-demo-oct23',\n",
              " 'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                  'pod_type': 'starter',\n",
              "                  'pods': 1,\n",
              "                  'replicas': 1,\n",
              "                  'shards': 1}},\n",
              " 'status': {'ready': True, 'state': 'Ready'}}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's confirm everything looks good with our index\n",
        "\n",
        "pc.describe_index('hybrid-search-demo-oct23')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb3e59a-2656-457f-aa88-e54fa60b2a63",
      "metadata": {
        "id": "9bb3e59a-2656-457f-aa88-e54fa60b2a63"
      },
      "source": [
        "We'll create an index object out of the index we just made. We'll make this with Pinecone's [GRPC client](https://docs.pinecone.io/docs/performance-tuning#using-the-grpc-client-to-get-higher-upsert-speeds), since it's a little faster for upserts:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f20b672-860d-4f9a-aa9a-6aff955542d8",
      "metadata": {
        "id": "5f20b672-860d-4f9a-aa9a-6aff955542d8"
      },
      "outputs": [],
      "source": [
        "index = pc.Index(\"hybrid-search-demo-oct23\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89dc6979-bd52-4080-b7cc-80689b6daf91",
      "metadata": {
        "id": "89dc6979-bd52-4080-b7cc-80689b6daf91"
      },
      "source": [
        "We'll need to make unique IDs for all of our objects, which is easy with the `uuid` library in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06205558-1994-466b-b1fd-f8b5a824e742",
      "metadata": {
        "id": "06205558-1994-466b-b1fd-f8b5a824e742"
      },
      "outputs": [],
      "source": [
        "def create_ids(chunks: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Create unique IDs for each document (chunk) in our index.\n",
        "\n",
        "    :param chunks: Chunks of our PDF file.\n",
        "\n",
        "    :return: Unique IDs for chunks.\n",
        "    \"\"\"\n",
        "    return [str(uuid4()) for _ in range(len(chunks))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "468968b1-dfc1-495c-8de1-dd8c40cf43e2",
      "metadata": {
        "id": "468968b1-dfc1-495c-8de1-dd8c40cf43e2"
      },
      "outputs": [],
      "source": [
        "freshdisk_ids = create_ids(chunked_files.get('freshdisk'))\n",
        "hnsw_ids = create_ids(chunked_files.get('hnsw'))\n",
        "ivfpq_ids = create_ids(chunked_files.get('ivfpq'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a855b9ff-7dcc-4543-933f-64815f9d8972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a855b9ff-7dcc-4543-933f-64815f9d8972",
        "outputId": "afc0f89e-3e77-4106-abb4-488464da2ff6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'a0b2c849-e1fb-4166-9be1-4dffa369c23f'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's preview one of our IDs:\n",
        "\n",
        "freshdisk_ids[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46051402-3950-4c6c-a0ab-ac6b3a08e389",
      "metadata": {
        "id": "46051402-3950-4c6c-a0ab-ac6b3a08e389"
      },
      "outputs": [],
      "source": [
        "# Let's make sure we have the same # of IDs as there are chunks:\n",
        "\n",
        "assert len(freshdisk_ids) == len(chunked_files.get('freshdisk'))\n",
        "assert len(hnsw_ids) == len(chunked_files.get('hnsw'))\n",
        "assert len(ivfpq_ids) == len(chunked_files.get('ivfpq'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eef3d9c-94f0-40d6-8c6c-7fef149c4152",
      "metadata": {
        "id": "7eef3d9c-94f0-40d6-8c6c-7fef149c4152"
      },
      "source": [
        "Now that we have our IDs, we can make our composite sparse-dense objects that we'll index into Pinecone. These will take 4 components:\n",
        "- Our IDs\n",
        "- Our sparse embeddings\n",
        "- Our dense embeddings\n",
        "- Our chunks\n",
        "\n",
        "We'll use the actual text content of our PDFs (stored in our chunks) as metadata. This allows the end user to see the content of what's being returned by their search instead of just the sparse/dense vectors. In order to store our chunks' textual data in digestible metadata object for Pinecone, we'll want to turn each chunk into a dict that has a `'text'` key to hold the chunk value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f994d0a-6167-4157-8e7f-0e450d164197",
      "metadata": {
        "id": "9f994d0a-6167-4157-8e7f-0e450d164197"
      },
      "outputs": [],
      "source": [
        "def create_metadata_objs(doc: List[str]) -> List[dict[str]]:\n",
        "    \"\"\"\n",
        "    Create objects to store as metadata alongside our sparse and dense vectors in our hybird Pinecone index.\n",
        "\n",
        "    :param doc: Chunks of a document we'd like to use while creating metadata objects.\n",
        "\n",
        "    :return: Metadata objects with a \"text\" key and a value that points to the text content of each chunk.\n",
        "    \"\"\"\n",
        "    return [{'text': d} for d in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874f6265-5c21-4169-a8b9-2bd65f5b4a57",
      "metadata": {
        "id": "874f6265-5c21-4169-a8b9-2bd65f5b4a57"
      },
      "outputs": [],
      "source": [
        "freshdisk_metadata = create_metadata_objs(chunked_files.get('freshdisk'))\n",
        "hnsw_metadata = create_metadata_objs(chunked_files.get('hnsw'))\n",
        "ivfpq_metadata = create_metadata_objs(chunked_files.get('ivfpq'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a6a557-49cc-4dbf-9c00-f02c447c4c48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6a6a557-49cc-4dbf-9c00-f02c447c4c48",
        "outputId": "d35e83ba-b9b4-4920-9c16-9eecc08a02df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Approximate nearest neighbor search (ANNS) is a fundamental building block in information retrieval with graphbased indices being the current state-of-the-art  and widely used in the industry. Recent advances  in graph-based indices have made it possible to index and search billion-point datasets with high recall and millisecond-level latency on a single commodity machine with an SSD. In this paper, we present the first graph-based ANNS index that reflects corpus updates into the index in real-time without'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview\n",
        "\n",
        "freshdisk_metadata[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2add63-efaa-4022-bf18-1472ae8aacee",
      "metadata": {
        "id": "9e2add63-efaa-4022-bf18-1472ae8aacee"
      },
      "outputs": [],
      "source": [
        "def create_composite_objs(ids: str, sembeddings: List[Dict[str, List[Any]]], dembeddings: List[float], metadata: Dict[str, str]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Create objects for indexing into Pinecone. Each object contains a document ID (which corresponds to the chunk, not the larger document),\n",
        "    the chunk's sparse embedding, the chunk's dense embedding, and the chunk's corresponding metadata object.\n",
        "\n",
        "    :param ids: Unique ID of a chunk we want to index.\n",
        "    :param sembeddings: Sparse embedding representation of a chunk we want to index.\n",
        "    :param dembeddings: Dense embedding representation of a chunk we want to index.\n",
        "    :param metadata: Metadata objects with a \"text\" key and a value that points to the text content of each chunk.\n",
        "\n",
        "    :return: Composite objects in the correct format for ingest into Pinecone.\n",
        "    \"\"\"\n",
        "    to_index = []\n",
        "\n",
        "    for i in range(len(metadata)):\n",
        "        to_index_obj = {\n",
        "                'id': ids[i],\n",
        "                'sparse_values': sembeddings[i],\n",
        "                'values': dembeddings[i],\n",
        "                'metadata': metadata[i]\n",
        "            }\n",
        "        to_index.append(to_index_obj)\n",
        "    return to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f44a46-a6b8-4778-bab7-429e8733c181",
      "metadata": {
        "id": "57f44a46-a6b8-4778-bab7-429e8733c181"
      },
      "outputs": [],
      "source": [
        "freshdisk_com_objs = create_composite_objs(freshdisk_ids, freshdisk_sembeddings, freshdisk_dembeddings, freshdisk_metadata)\n",
        "hnsw_com_objs = create_composite_objs(hnsw_ids, hnsw_sembeddings, hnsw_dembeddings, hnsw_metadata)\n",
        "ivfpq_com_objs = create_composite_objs(ivfpq_ids, ivfpq_sembeddings, ivfpq_dembeddings, ivfpq_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "938a4954-ecf5-4491-87e6-597a83956024",
      "metadata": {
        "id": "938a4954-ecf5-4491-87e6-597a83956024",
        "outputId": "d4cc78e9-9941-463b-89f9-5b703eda30b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'a0b2c849-e1fb-4166-9be1-4dffa369c23f',\n",
              " 'sparse_values': {'indices': [270780933,\n",
              "   3650065742,\n",
              "   1196854555,\n",
              "   553238108,\n",
              "   891354358,\n",
              "   3429613387,\n",
              "   2087367745,\n",
              "   2691201840,\n",
              "   3647400625,\n",
              "   2455432819,\n",
              "   3850563250,\n",
              "   1563317370,\n",
              "   407983593,\n",
              "   2307803212,\n",
              "   2751533102,\n",
              "   640124220,\n",
              "   91759785,\n",
              "   569308866,\n",
              "   728487644,\n",
              "   414100959,\n",
              "   3452949137,\n",
              "   3927490055,\n",
              "   125777136,\n",
              "   3935005093,\n",
              "   3096200065,\n",
              "   1612531086,\n",
              "   385392376,\n",
              "   3453722252,\n",
              "   881664426,\n",
              "   1691351615,\n",
              "   536145832,\n",
              "   3066577729,\n",
              "   1564510983,\n",
              "   4183835765,\n",
              "   2165730276,\n",
              "   2851137560,\n",
              "   173740189,\n",
              "   1330873646,\n",
              "   4071218396,\n",
              "   1651775491,\n",
              "   1477105254],\n",
              "  'values': [0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.04484304932735426,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.06578947368421052,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376,\n",
              "   0.02293577981651376]},\n",
              " 'values': array([-7.05589801e-02, -6.87261447e-02,  9.44810640e-03,  8.10440816e-03,\n",
              "         2.09856033e-02, -8.01880844e-03, -1.45745963e-01,  1.51017588e-02,\n",
              "        -2.76319962e-02, -3.02547999e-02,  6.72971085e-02, -9.63658560e-03,\n",
              "         1.43581610e-02, -4.38161232e-02, -9.05692130e-02, -7.55782872e-02,\n",
              "         1.94339454e-01,  7.08889365e-02,  1.57732125e-02, -6.09086826e-02,\n",
              "        -3.51914018e-02,  4.34460714e-02,  3.10931564e-03, -8.95346573e-04,\n",
              "         1.62576418e-02, -6.67105168e-02, -1.13743707e-03,  3.96166444e-02,\n",
              "         3.12499818e-03, -8.02538991e-02, -1.60129201e-02,  3.60529646e-02,\n",
              "         6.68585300e-02,  5.77961802e-02, -3.81306186e-03, -2.48537008e-02,\n",
              "        -8.61331075e-03,  8.58636573e-02,  1.32496450e-02, -6.19558319e-02,\n",
              "         3.08233369e-02, -1.55239208e-02,  3.79861258e-02,  9.91949961e-02,\n",
              "         2.83789691e-02, -2.89505217e-02, -6.15981482e-02,  1.88310854e-02,\n",
              "         1.45127659e-03, -3.67059559e-02, -2.74486206e-02,  4.73517887e-02,\n",
              "         9.51784849e-03, -2.17345916e-02,  2.70487666e-02,  8.18445459e-02,\n",
              "         6.68833479e-02, -7.52784014e-02, -1.95142236e-02,  5.01705781e-02,\n",
              "         6.77077249e-02,  3.95623967e-02,  3.96396481e-02, -9.58393444e-04,\n",
              "         6.65243343e-03, -2.53186282e-02,  8.77363458e-02, -1.28753139e-02,\n",
              "         2.11256985e-02, -9.29649472e-02,  7.82034826e-03,  5.13574518e-02,\n",
              "        -1.13010190e-01,  1.11585207e-01, -8.38983431e-02, -1.58216450e-02,\n",
              "        -7.94113241e-03, -7.93980528e-03,  1.84463412e-02, -5.59161007e-02,\n",
              "        -6.63294196e-02, -3.10303979e-02,  2.89941486e-02, -9.29232612e-02,\n",
              "         1.53141161e-02, -1.24835975e-01,  9.92735326e-02, -7.62093440e-02,\n",
              "         6.34818673e-02, -2.87126116e-02, -4.48064022e-02, -2.68579926e-02,\n",
              "         4.07000221e-02, -5.13108000e-02,  2.95225382e-02,  1.40104620e-02,\n",
              "         5.78940697e-02,  1.10296942e-01,  2.55669449e-02,  1.98032912e-02,\n",
              "        -9.54577141e-03,  9.24139321e-02, -8.94624889e-02,  2.88267341e-02,\n",
              "         2.62004212e-02, -3.31143849e-02, -1.96639448e-02,  1.64372455e-02,\n",
              "         2.71554906e-02,  8.03032704e-03,  4.54506688e-02,  4.93250825e-02,\n",
              "        -1.14539396e-02,  4.81998511e-02,  3.77848931e-02, -5.64093255e-02,\n",
              "         5.66299297e-02, -4.49485099e-03, -2.15463750e-02,  6.65575862e-02,\n",
              "        -7.87767097e-02,  2.54582502e-02, -1.81310773e-02, -2.95809209e-02,\n",
              "         3.30861770e-02, -7.76849017e-02, -2.50439942e-02,  3.31076309e-02,\n",
              "         9.85948667e-02, -2.01358721e-02,  4.68313769e-02, -2.96400171e-02,\n",
              "        -3.13611031e-02,  5.36714273e-04, -1.61858927e-02,  5.82353137e-02,\n",
              "        -8.78220946e-02, -5.97979613e-02, -4.43050377e-02,  9.90376547e-02,\n",
              "        -3.87214385e-02,  4.02534790e-02, -3.04042757e-03,  7.62172714e-02,\n",
              "         4.59010527e-02,  4.44253124e-02, -3.58308665e-02, -3.73459160e-02,\n",
              "         2.78047882e-02, -1.32160172e-01,  2.53135934e-02, -5.54689616e-02,\n",
              "         2.54254304e-02,  1.09743848e-02,  4.76833954e-02, -8.55527073e-02,\n",
              "         1.08574212e-01,  1.67110655e-02, -2.24485947e-03, -5.81993870e-02,\n",
              "        -1.68190971e-02,  3.04826535e-02, -6.21523969e-02, -2.88254283e-02,\n",
              "        -2.65777316e-02, -6.30283654e-02, -3.74921337e-02, -2.35360358e-02,\n",
              "        -5.04603721e-02, -6.16202736e-03,  1.03659578e-01, -3.21553275e-02,\n",
              "        -4.94560711e-02,  6.11036643e-02, -2.02440619e-02, -1.63121112e-02,\n",
              "         2.13905078e-05, -3.28019969e-02,  1.07294746e-01,  1.12182014e-02,\n",
              "        -2.23489311e-02,  3.80335003e-02,  6.22763857e-02,  4.92714755e-02,\n",
              "         1.98833086e-02, -1.19497972e-02,  3.82480696e-02,  8.31843391e-02,\n",
              "         2.06941757e-02,  1.89698357e-02, -6.07435405e-03,  2.86257407e-03,\n",
              "         3.51129547e-02,  8.13371874e-03, -1.86637100e-02, -1.68447848e-02,\n",
              "         4.33547236e-02, -4.40289117e-02,  1.33668371e-02,  3.37923109e-03,\n",
              "         3.75428684e-02, -4.59321849e-02, -4.26345039e-03,  8.56257156e-02,\n",
              "         6.26526400e-02, -4.33720089e-02, -3.53628956e-02, -6.52644634e-02,\n",
              "        -2.13820376e-02, -3.61827649e-02, -9.27158352e-03,  5.35358861e-02,\n",
              "         2.21298151e-02, -1.69901922e-02,  7.47643337e-02, -6.85721636e-02,\n",
              "         9.65783838e-03, -1.03089221e-01, -3.85339856e-02,  2.97250636e-02,\n",
              "         1.77250318e-02, -8.47306922e-02, -4.49845418e-02,  4.48644170e-33,\n",
              "         3.71793658e-02, -4.07028235e-02, -7.05140159e-02,  7.29849115e-02,\n",
              "         1.06432931e-02, -7.60457525e-03,  3.00466027e-02,  5.91120534e-02,\n",
              "        -3.67854089e-02,  1.43255955e-02, -8.25418085e-02, -2.39878930e-02,\n",
              "        -3.63157652e-02, -2.24814285e-03, -8.65115225e-03,  6.74473345e-02,\n",
              "         8.50458890e-02,  5.05133644e-02,  1.67696923e-02,  8.77494216e-02,\n",
              "         6.07133508e-02, -4.62369360e-02, -2.38598720e-03,  8.68166462e-02,\n",
              "         8.41386430e-03,  3.23634944e-03,  1.44006163e-02, -3.53819914e-02,\n",
              "        -8.19396824e-02, -6.23543113e-02, -5.85028790e-02, -1.22606298e-02,\n",
              "         1.71730500e-02, -3.37228440e-02,  3.19708660e-02,  1.13529712e-01,\n",
              "         1.05475508e-01, -7.67600387e-02, -2.48393863e-02, -4.44270065e-03,\n",
              "         8.57112482e-02,  6.69525266e-02, -4.29973602e-02, -2.06702426e-02,\n",
              "        -1.24675520e-02, -2.33806763e-03, -1.31397456e-01,  5.49771786e-02,\n",
              "        -2.62236148e-02,  2.47432720e-02, -4.54810273e-04, -8.85106158e-03,\n",
              "         8.46381858e-02, -7.23898830e-03, -5.53668328e-02,  3.44064496e-02,\n",
              "        -7.85462409e-02, -3.75488400e-02,  8.11473653e-03, -5.95599823e-02,\n",
              "        -2.79995706e-02, -3.16355638e-02, -5.21195233e-02,  3.06905117e-02,\n",
              "        -2.76158787e-02, -1.51280649e-02, -1.73203237e-02, -6.40102243e-03,\n",
              "        -4.39584516e-02, -7.68150240e-02, -5.69163263e-02, -6.25414774e-02,\n",
              "         2.54207030e-02, -3.08512878e-02, -2.96741612e-02, -2.27834899e-02,\n",
              "         2.03918125e-02, -6.30590469e-02, -2.43722051e-02, -5.56498766e-02,\n",
              "         1.48576749e-02,  3.74138877e-02,  5.34711443e-02, -6.23396672e-02,\n",
              "         1.13135017e-02,  9.84239876e-02,  8.86763912e-03,  6.62978813e-02,\n",
              "         4.95284460e-02,  4.59361030e-03,  5.39333485e-02, -1.57378651e-02,\n",
              "        -5.58821261e-02,  4.50500548e-02, -2.51527852e-03,  3.10548386e-32,\n",
              "        -4.45453115e-02,  4.60870154e-02, -2.15591677e-02,  7.43628293e-02,\n",
              "         1.28170161e-03, -5.98024316e-02,  2.92950422e-02,  7.60265961e-02,\n",
              "         3.45759769e-03,  1.88332535e-02,  7.79588073e-02, -4.65151779e-02,\n",
              "        -4.10600975e-02, -6.43647625e-04,  4.51539457e-02, -5.13405204e-02,\n",
              "         3.72336358e-02, -1.53081976e-02,  1.55503768e-02, -7.25890091e-03,\n",
              "         7.76851270e-03,  7.99205005e-02,  1.23206034e-01, -3.92353311e-02,\n",
              "        -3.85524891e-02,  2.66900957e-02, -1.22261816e-03,  5.84613904e-02,\n",
              "         1.56755242e-02, -1.30304163e-02, -4.52691950e-02,  1.13392412e-03,\n",
              "        -5.84739372e-02,  3.84007171e-02, -2.33264416e-02,  6.65067136e-02,\n",
              "         2.11761016e-02,  4.86971252e-02,  2.49629635e-02,  1.94349438e-02,\n",
              "         1.41990334e-02, -5.51384613e-02,  2.32641865e-03,  2.16693748e-02,\n",
              "         4.92930263e-02, -1.82445087e-02, -2.97825933e-02, -4.15598415e-02,\n",
              "         5.34707159e-02, -9.73151401e-02, -4.47202213e-02, -8.22010115e-02,\n",
              "         5.63183129e-02,  3.67105589e-03,  9.83771905e-02,  1.49584496e-02,\n",
              "        -6.48408488e-04,  8.29082390e-04, -9.32982285e-03,  1.26922764e-02,\n",
              "         3.01587135e-02, -9.11302194e-02, -5.66401370e-02, -9.92193893e-02],\n",
              "       dtype=float32),\n",
              " 'metadata': {'text': 'Approximate nearest neighbor search (ANNS) is a fundamental building block in information retrieval with graphbased indices being the current state-of-the-art  and widely used in the industry. Recent advances  in graph-based indices have made it possible to index and search billion-point datasets with high recall and millisecond-level latency on a single commodity machine with an SSD. In this paper, we present the first graph-based ANNS index that reflects corpus updates into the index in real-time without'}}"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freshdisk_com_objs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7bc28e-5ead-4d44-a2af-287ee3efd712",
      "metadata": {
        "id": "db7bc28e-5ead-4d44-a2af-287ee3efd712"
      },
      "source": [
        "Now we can index (\"upsert\") our objects into our Pinecone index!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aaaaf91-2353-430b-aec6-0e843c499bd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aaaaf91-2353-430b-aec6-0e843c499bd7",
        "outputId": "0a9e7ab7-5c8f-4dab-9b0b-2c836b7c218a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 59}"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.upsert(freshdisk_com_objs)\n",
        "index.upsert(hnsw_com_objs)\n",
        "index.upsert(ivfpq_com_objs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29feb6c2-e6ad-47c4-834a-91ba08a72927",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29feb6c2-e6ad-47c4-834a-91ba08a72927",
        "outputId": "50f5b394-3952-4b3e-9512-61955fd07127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Woo we have our vectors (252) in our index!\n",
        "\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f16c883-9892-49a6-99b5-846b356b3258",
      "metadata": {
        "id": "4f16c883-9892-49a6-99b5-846b356b3258"
      },
      "source": [
        "# Query Our Hybrid Docs\n",
        "\n",
        "Now that we have all of our hybrid vector objects in our Pinecone index, we can issue some queries!\n",
        "\n",
        "Since issuing a query to a vector index requires the query to be vectorized in the same way as the objects in the index are vectorized (so they can match up in vector space), for hybrid queries we'll have to vectorize the query *twice*! Once as a sparse vector and once as a dense vector. We then send both of those vectors to Pinecone to get items back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3802bd10-1a66-4a9b-b5c6-56a2779f30d9",
      "metadata": {
        "id": "3802bd10-1a66-4a9b-b5c6-56a2779f30d9"
      },
      "outputs": [],
      "source": [
        "query = \"What are nearest neighbors?\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0303a36-1bb0-40d5-85a3-eed31d003cab",
      "metadata": {
        "id": "c0303a36-1bb0-40d5-85a3-eed31d003cab",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "Create sparse embedding from query\n",
        "\n",
        "Note: do *not* refit the bm25 model here. We want to keep the token frequencies etc from when we fit it to the text from our PDFs!\n",
        "\n",
        "You might be wondering how the model gets \"refit\" when the corpus changes, the answer is a little complicated, but essentially this is a special implementation of BM25 (which usually runs online) that has precomputed frequencies for English words, based off the MSMarco dataset. So, when you add new docs to the corpus, you don't have to \"refit\" the BM25 model, it just finds the word frequencies in the MSMarco dataset.\n",
        "\n",
        "More here: https://github.com/pinecone-io/pinecone-text/blob/main/pinecone_text/sparse/bm25_encoder.py#L255\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd44e1c5-5ccc-4e94-8247-d83f2a32f02a",
      "metadata": {
        "id": "fd44e1c5-5ccc-4e94-8247-d83f2a32f02a"
      },
      "outputs": [],
      "source": [
        "query_sembedding = bm25.encode_queries(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4644d3a3-d5e3-4e6e-8383-ccd214bd0eaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4644d3a3-d5e3-4e6e-8383-ccd214bd0eaf",
        "outputId": "3888c25e-f743-4db6-c3d0-669167b17fff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'indices': [3650065742, 1196854555], 'values': [0.5, 0.5]}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cool! We can see there are only two values in here, because BM25 automatically removed stop word like \"what\" and \"is\"\n",
        "\n",
        "query_sembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e4ad1b-418b-4865-9995-45bb8a351efb",
      "metadata": {
        "id": "20e4ad1b-418b-4865-9995-45bb8a351efb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create dense embedding\n",
        "\n",
        "query_dembedding = produce_embeddings([query])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c366ef74-e1cd-46d1-b7a2-e856acb6ce8a",
      "metadata": {
        "id": "c366ef74-e1cd-46d1-b7a2-e856acb6ce8a",
        "scrolled": true,
        "outputId": "97d4bcff-388b-40b7-de39-6960843b3e9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([ 3.93597968e-02, -4.73917834e-02, -4.04572822e-02, -3.46426181e-02,\n",
              "        -9.91900731e-03,  9.67433769e-03, -7.91810825e-02,  5.16992621e-02,\n",
              "        -1.95026845e-02, -1.82915609e-02,  4.21764627e-02, -2.76289210e-02,\n",
              "         3.47405002e-02, -2.30831876e-02, -1.08419947e-01,  3.71121243e-02,\n",
              "         6.21360615e-02, -2.54765134e-02, -3.14433910e-02, -5.88753298e-02,\n",
              "        -7.58902580e-02,  1.44599723e-02,  2.41217650e-02,  2.67990362e-02,\n",
              "         6.24472909e-02, -6.25005811e-02,  6.11938909e-02, -4.98113455e-03,\n",
              "         1.92482844e-02, -1.17263822e-02, -5.68607412e-02,  7.51190856e-02,\n",
              "         6.08491302e-02,  2.20751557e-02,  3.56491730e-02,  1.04025407e-02,\n",
              "        -4.32657963e-03,  8.42948183e-02, -5.93699813e-02,  2.46451106e-02,\n",
              "         1.37929812e-01, -4.35611792e-02,  6.47360906e-02,  4.99044023e-02,\n",
              "        -6.89831302e-02, -8.31327401e-03,  3.35846990e-02, -5.25765773e-03,\n",
              "        -3.74430493e-02, -1.05748348e-01, -4.40458506e-02, -4.96782102e-02,\n",
              "        -5.08965366e-02,  8.45378079e-03,  6.94194660e-02,  3.64613533e-02,\n",
              "        -4.05794522e-03, -3.45807225e-02, -6.77225040e-03,  3.48999463e-02,\n",
              "         9.92610306e-02, -3.36857140e-02, -4.88350205e-02, -2.51160804e-02,\n",
              "         4.89612557e-02, -6.30404055e-02,  4.71218601e-02, -1.73964519e-02,\n",
              "        -6.67371899e-02, -2.51267534e-02,  7.10095372e-03, -1.10116247e-02,\n",
              "        -6.27903044e-02,  4.95913364e-02, -1.59268547e-02, -1.45717170e-02,\n",
              "        -1.18428487e-02, -1.45136649e-02, -9.25995503e-03, -1.20642580e-01,\n",
              "        -4.04333994e-02,  2.69383788e-02, -5.21945469e-02, -1.43754678e-02,\n",
              "         5.43207936e-02,  2.01791693e-02,  7.72846565e-02, -4.85578403e-02,\n",
              "         4.94589582e-02,  4.49723843e-03,  1.73856709e-02, -1.86130889e-02,\n",
              "        -5.22232428e-03, -2.21952144e-03,  2.62321085e-02, -8.47557485e-02,\n",
              "         5.61136529e-02, -6.49122000e-02,  4.15397080e-04,  1.08235739e-01,\n",
              "         3.67102586e-02,  8.07013065e-02, -3.32275406e-02,  3.67525145e-02,\n",
              "         5.71005559e-03, -2.88595520e-02, -6.22151159e-02, -2.91857608e-02,\n",
              "         9.71401408e-02, -1.50304269e-02, -2.74635125e-02,  1.89166199e-02,\n",
              "        -8.62699524e-02,  7.14267604e-03,  9.25469026e-02, -1.28796041e-01,\n",
              "         3.09114661e-02,  5.41532692e-03,  1.89184360e-02, -1.69682670e-02,\n",
              "        -6.42077252e-02, -1.32298656e-02, -9.16228220e-02, -4.65411767e-02,\n",
              "         5.29012196e-02, -1.34298548e-01, -1.05446436e-01,  2.04564258e-02,\n",
              "         5.86174317e-02, -3.54858339e-02, -4.64328425e-03, -6.45381361e-02,\n",
              "         3.33550125e-02,  2.58269310e-02, -2.83511523e-02,  3.38219143e-02,\n",
              "         6.99535199e-03, -3.04461159e-02, -2.02894490e-02, -4.34528943e-03,\n",
              "         9.70935747e-02, -6.54397607e-02,  7.11764023e-02,  2.02885810e-02,\n",
              "        -7.33104954e-03,  3.09603922e-02, -4.84921001e-02,  5.68908863e-02,\n",
              "         1.63496807e-02,  5.35477092e-03,  6.42970055e-02,  2.83099967e-03,\n",
              "         5.59217716e-03, -2.36086641e-03, -1.04888109e-02, -5.54178730e-02,\n",
              "         3.72617617e-02, -1.48542309e-02,  7.36343265e-02,  1.13627792e-03,\n",
              "         7.33837038e-02, -1.13070368e-04,  6.06073625e-02,  4.59511690e-02,\n",
              "        -4.44170311e-02, -6.55937493e-02,  6.51025493e-03, -1.37721216e-02,\n",
              "        -2.45315041e-02,  9.26493853e-03,  2.84311660e-02, -3.02948505e-02,\n",
              "         8.13365728e-02,  9.07868296e-02, -1.94042232e-02,  2.62346845e-02,\n",
              "        -7.44900480e-02, -1.52261993e-02,  3.73626687e-02,  4.41401312e-03,\n",
              "        -6.28267080e-02,  6.49549738e-02, -1.39942057e-02, -1.55411828e-02,\n",
              "        -4.97228745e-03, -1.47579638e-02, -5.17161153e-02,  1.90039836e-02,\n",
              "         3.33682410e-02, -2.88447738e-02,  1.30981850e-02, -2.87897084e-02,\n",
              "         8.42450410e-02, -1.40978936e-02,  1.83698311e-02, -1.94788408e-02,\n",
              "         1.11046113e-01, -7.90092070e-03,  2.94558797e-02,  1.99567433e-02,\n",
              "        -3.54968458e-02,  5.80346386e-04, -3.42198536e-02,  2.18468234e-02,\n",
              "        -4.51281220e-02, -1.90469977e-02,  5.49115650e-02, -6.87332526e-02,\n",
              "        -8.18926618e-02,  6.91324323e-02, -1.11318648e-01,  1.10114161e-02,\n",
              "        -2.57205646e-02, -6.82387641e-03, -3.81267332e-02, -3.06496713e-02,\n",
              "         1.36233531e-02, -8.34717751e-02, -1.01576978e-02,  1.57713164e-02,\n",
              "         7.60303624e-03, -1.04666732e-01, -9.04123709e-02,  1.27806799e-32,\n",
              "         2.19749343e-02, -2.71324646e-02,  1.18809193e-02, -6.89412979e-03,\n",
              "        -2.48183291e-02, -1.99351776e-02,  1.00636914e-01,  8.18512887e-02,\n",
              "        -2.92302053e-02,  2.81028580e-02, -1.66526571e-01, -3.08759958e-02,\n",
              "         5.14358096e-02, -2.01871097e-02,  5.53445071e-02,  3.58568281e-02,\n",
              "         1.12418897e-01, -5.78038022e-02, -8.10662806e-02, -2.56199725e-02,\n",
              "         8.55984166e-02,  6.69106841e-03, -2.66639236e-02,  1.30641758e-01,\n",
              "         1.09034507e-02,  4.32362184e-02, -4.77037719e-03, -3.26438993e-03,\n",
              "        -7.61050358e-02, -8.47583488e-02,  3.51457819e-02,  5.73902973e-04,\n",
              "         4.00871783e-02,  1.32538006e-02,  8.59421305e-03,  1.42975092e-01,\n",
              "         1.05862044e-01, -4.50029559e-02, -7.44314399e-03, -9.36007202e-02,\n",
              "         6.06717169e-02,  1.37858875e-02,  1.63629986e-02,  4.65090014e-02,\n",
              "         4.83797910e-03,  4.46671881e-02,  2.55772546e-02, -1.75294932e-02,\n",
              "        -5.44632189e-02, -3.72105315e-02, -3.32027413e-02,  4.76207696e-02,\n",
              "        -4.52524470e-03,  2.80866139e-02, -4.01536860e-02,  2.95476709e-02,\n",
              "        -1.03855133e-01,  7.39734620e-02,  6.63676262e-02,  1.98616106e-02,\n",
              "         1.88544039e-02, -2.83820811e-03,  3.06654423e-02,  7.76023343e-02,\n",
              "        -1.03797011e-01, -2.29166858e-02, -4.79308963e-02,  2.65569463e-02,\n",
              "         4.06076014e-02,  2.30044071e-02, -2.17699334e-02,  2.49742214e-02,\n",
              "         7.42306188e-02, -5.54240085e-02, -1.21673644e-01,  2.28644479e-02,\n",
              "         7.34749958e-02, -6.85746819e-02, -2.28439830e-02,  9.65602696e-03,\n",
              "        -4.51028533e-02,  1.50079709e-02,  3.36108021e-02,  5.93978800e-02,\n",
              "         8.23037350e-04,  2.58279517e-02,  7.96455964e-02,  3.92440036e-02,\n",
              "         5.10406420e-02, -3.25842462e-02,  3.62097137e-02, -4.35827747e-02,\n",
              "        -3.28230634e-02, -2.25594194e-05, -8.68363865e-03,  8.02051551e-33,\n",
              "        -3.01315393e-02,  2.44644694e-02, -4.30793576e-02,  8.99002329e-02,\n",
              "        -2.12881900e-02,  1.13659777e-01,  1.91479474e-02,  1.41622663e-01,\n",
              "        -3.59222740e-02,  6.19793348e-02,  2.30135396e-03,  2.48523876e-02,\n",
              "        -4.82555218e-02,  4.42216992e-02,  3.06331646e-02, -1.53303342e-02,\n",
              "         4.42981198e-02, -3.39191109e-02,  1.44827727e-03,  8.87605473e-02,\n",
              "        -4.36704494e-02,  4.61561680e-02, -5.28984144e-03,  9.24225606e-04,\n",
              "        -1.30231334e-02,  8.19946751e-02, -3.76788713e-02,  7.46938363e-02,\n",
              "         2.82603074e-02,  4.19141650e-02, -1.69296283e-03,  1.51931252e-02,\n",
              "        -8.92071202e-02,  7.97290262e-03, -3.00492346e-02, -1.64085289e-03,\n",
              "         2.52018925e-02,  4.23559360e-02, -8.52368996e-02,  1.34124570e-02,\n",
              "        -8.15865956e-03, -4.60262671e-02,  1.23688346e-02,  7.49970749e-02,\n",
              "         8.76439512e-02, -6.34369301e-03,  7.91479554e-03, -6.95919320e-02,\n",
              "         7.33645773e-03, -7.72208422e-02, -4.92108427e-02, -1.06459064e-02,\n",
              "         2.72609815e-02, -7.58421840e-03, -7.99316838e-02, -4.50155176e-02,\n",
              "         5.15184477e-02, -3.38265523e-02,  1.04297055e-02,  1.17999725e-02,\n",
              "        -4.29891981e-02,  4.46786806e-02, -4.31763707e-03, -1.84930637e-02],\n",
              "       dtype=float32)]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_dembedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ebc12c-a6a2-4834-b6ec-749fd61f32ae",
      "metadata": {
        "id": "06ebc12c-a6a2-4834-b6ec-749fd61f32ae"
      },
      "source": [
        "Pinecone vector search has a cool user feature where you can weight the sparse vectors higher or lower (i.e. of more or less importance) than the dense vectors. This is controlled by the `alpha` parameter. An `alpha` of 0 means you're doing a totally keyword-based search (i.e. only over sparse vectors), while an `alpha` of 1 means you're doing a totally semantic search (i.e. only over dense vectors).\n",
        "\n",
        "Let's make a function that'll let us weight our vectors by alpha.\n",
        "\n",
        "(We'll also include `k`, which is the number of docs we want to retrieve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b61142a-192e-4b73-87f1-eeb68e8c4998",
      "metadata": {
        "id": "6b61142a-192e-4b73-87f1-eeb68e8c4998"
      },
      "outputs": [],
      "source": [
        "# Integrate alpha and top-k\n",
        "\n",
        "def weight_by_alpha(sparse_embedding: Dict[str, List[Any]], dense_embedding: List[float], alpha: float) -> Tuple[Dict[str, List[Any]], List[float]]:\n",
        "    \"\"\"\n",
        "    Weight the values of our sparse and dense embeddings by the parameter alpha (0-1).\n",
        "\n",
        "    :param sparse_embedding: Sparse embedding representation of one of our documents (or chunks).\n",
        "    :param dense_embedding: Dense embedding representation of one of our documents (or chunks).\n",
        "    :param alpha: Weighting parameter between 0-1 that controls the impact of sparse or dense embeddings on the retrieval and ranking\n",
        "        of returned docs (chunks) in our index.\n",
        "\n",
        "    :return: Weighted sparse and dense embeddings for one of our documents (chunks).\n",
        "    \"\"\"\n",
        "    if alpha < 0 or alpha > 1:\n",
        "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
        "    hsparse = {\n",
        "        'indices': sparse_embedding['indices'],\n",
        "        'values':  [v * (1 - alpha) for v in sparse_embedding['values']]\n",
        "    }\n",
        "    hdense = [v * alpha for v in dense_embedding]\n",
        "    return hsparse, hdense"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c12e86-5a18-41cf-bce0-699df56fbc8c",
      "metadata": {
        "id": "f0c12e86-5a18-41cf-bce0-699df56fbc8c"
      },
      "source": [
        "Now let's make a function that'll query our Pinecone index while taking into account whatever `alpha` and `k` values we want to pass:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787c9898-b1d8-4eea-a8ec-5b24215c2a27",
      "metadata": {
        "id": "787c9898-b1d8-4eea-a8ec-5b24215c2a27"
      },
      "outputs": [],
      "source": [
        "# Note this doesn't have any genAI in it yet\n",
        "\n",
        "\n",
        "def issue_hybrid_query(sparse_embedding: Dict[str, List[Any]], dense_embedding: List[float], alpha: float, top_k: int) -> QueryResponse:\n",
        "    \"\"\"\n",
        "    Send properly formatted hybrid search query to Pinecone index and get back `k` ranked results (ranked by dot product similarity, as\n",
        "        defined when we made our index).\n",
        "\n",
        "    :param sparse_embedding: Sparse embedding representation of one of our documents (or chunks).\n",
        "    :param dense_embedding: Dense embedding representation of one of our documents (or chunks).\n",
        "    :param alpha: Weighting parameter between 0-1 that controls the impact of sparse or dense embeddings on the retrieval and ranking\n",
        "        of returned docs (chunks) in our index.\n",
        "    :param top_k: The number of documents (chunks) we want back from Pinecone.\n",
        "\n",
        "    :return: QueryResponse object from Pinecone containing top-k results.\n",
        "    \"\"\"\n",
        "    scaled_sparse, scaled_dense = weight_by_alpha(sparse_embedding, dense_embedding, alpha)\n",
        "\n",
        "    result = index.query(\n",
        "        vector=scaled_dense,\n",
        "        sparse_vector=scaled_sparse,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "626bffe8-cce1-47b9-84d6-c827e9f5cf07",
      "metadata": {
        "id": "626bffe8-cce1-47b9-84d6-c827e9f5cf07"
      },
      "source": [
        "Let's issue a pure semantic search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea14e5f-20dc-44a1-8793-17583e8689ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cea14e5f-20dc-44a1-8793-17583e8689ef",
        "outputId": "8e9e9f96-13c9-426d-a7a3-f897ed1a5d96",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': 'a295c4d8-29f2-43a1-8bb1-523c24ee5d65',\n",
              "              'metadata': {'text': 'to the closest neighbors in a k-NN graph '\n",
              "                                   'serve as a simple approximation of the '\n",
              "                                   'Delaunay graph  (a graph which guranties '\n",
              "                                   'that the result of a basic greedy graph '\n",
              "                                   'traversal is always the nearest neighbor). '\n",
              "                                   'Unfortunately, Delaunay graph cannot be '\n",
              "                                   'efficiently constructed without prior '\n",
              "                                   'information about the structure of a space '\n",
              "                                   ', but its approximation by the nearest '\n",
              "                                   'neighbors can be done by using only '\n",
              "                                   'distances between the stored elements. It '\n",
              "                                   'was shown that proximity graph approaches '\n",
              "                                   'with such approximation'},\n",
              "              'score': 0.0614340045,\n",
              "              'values': []},\n",
              "             {'id': 'de06cd8b-3f6f-4085-816a-afa32dac9cb9',\n",
              "              'metadata': {'text': 'to database vectors, as this would '\n",
              "                                   'increase the memory usage. 4) add a new '\n",
              "                                   'entry to the inverted list corresponding '\n",
              "                                   'to g-(y). It contains the vector (or '\n",
              "                                   'image) identifier and the binary code (the '\n",
              "                                   'product quantizer’s indexes). Searching '\n",
              "                                   'the nearest neighbor(s) of a query x '\n",
              "                                   'consists of 1) quantize x to its w nearest '\n",
              "                                   'neighbors in the codebook q; with these w '\n",
              "                                   'assignments. The two steps are applied to '\n",
              "                                   'all w assignments. 4) select the K nearest '\n",
              "                                   'neighbors of x based on the estimated '\n",
              "                                   'distances. This is implemented'},\n",
              "              'score': 0.0568181835,\n",
              "              'values': []},\n",
              "             {'id': '6282efd3-f064-43c7-a98b-ac2eee2f1c76',\n",
              "              'metadata': {'text': 'neighbors, the correcting term is likely '\n",
              "                                   'to be higher 0 Ts. L -0.3 -0.2 -0.1 0 0.1 '\n",
              "                                   '0.2 0.3 difference: estimator d(x,y) In '\n",
              "                                   'our experiments, we observe that the '\n",
              "                                   'correction returns inferior results on '\n",
              "                                   'average. Therefore, we advocate the use of '\n",
              "                                   'Equation 13 for the nearest neighbor '\n",
              "                                   'search. The corrected version is useful '\n",
              "                                   'only if we are interested in the distances '\n",
              "                                   'themselves. Approximate nearest neighbor '\n",
              "                                   'search with product quantizers is fast '\n",
              "                                   '(only m additions are required per '\n",
              "                                   'distance calculation) and reduces'},\n",
              "              'score': 0.0512346923,\n",
              "              'values': []},\n",
              "             {'id': '01526940-f5c3-4748-8f9e-281edb5ed654',\n",
              "              'metadata': {'text': 'nearest neighbors is then approximated by '\n",
              "                                   'the search of the nearest neighbors in '\n",
              "                                   'terms of Hamming distances between codes. '\n",
              "                                   'In , spectral hashing (SH) is shown to '\n",
              "                                   'outperform the binary codes generated by '\n",
              "                                   'the restricted Boltzmann machine , '\n",
              "                                   'boosting and LSH. In this paper, we '\n",
              "                                   'construct short codes using quantization. '\n",
              "                                   'The goal is to estimate distances using '\n",
              "                                   'vectorto-centroid distances, i.e., the '\n",
              "                                   'query vector is not quantized, codes are '\n",
              "                                   'assigned to the database vectors only. '\n",
              "                                   'This reduces the quantization noise'},\n",
              "              'score': 0.045766592,\n",
              "              'values': []},\n",
              "             {'id': '52e18d7b-9c61-4de1-89a6-40ae8ba6c61e',\n",
              "              'metadata': {'text': 'Nearest Neighbor Queries in Fixed '\n",
              "                                   'Dimensions. In Proceedings of the Fourth '\n",
              "                                   'Annual ACMSIAM Symposium on Discrete '\n",
              "                                   'Algorithms (Austin, Texas, USA) (SODA '\n",
              "                                   '’93). Society for Industrial and Applied '\n",
              "                                   'Mathematics, Philadelphia, PA, USA, '\n",
              "                                   '271-280. '\n",
              "                                   'http://dl.acm.org/citation.cfm?id=313559.313768 '\n",
              "                                   'Martin Aumiiller, Erik Bernhardsson, and '\n",
              "                                   'Alexander Faithfull. 2020. ANN-Benchmarks: '\n",
              "                                   'A benchmarking tool for approximate '\n",
              "                                   'nearest neighbor algorithms. Information '\n",
              "                                   'Systems 87 (2020). http://www.'},\n",
              "              'score': 0.043103449,\n",
              "              'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note, for our dense embedding (`query_dembedding`), we need to grab the 1st value [0] since Pinecone expects a Numpy array when queried:\n",
        "\n",
        "issue_hybrid_query(query_sembedding, query_dembedding[0], 0.0, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98e72fd-4ace-42dc-8bd2-d086bd0907f4",
      "metadata": {
        "id": "d98e72fd-4ace-42dc-8bd2-d086bd0907f4",
        "scrolled": true
      },
      "source": [
        "And now a pure keyword search. You can see how many more domain-specific words are in these results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6146883-735d-4755-84fc-f234a92725be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6146883-735d-4755-84fc-f234a92725be",
        "outputId": "c7c08eaf-a07f-46df-9788-ab6de4069983",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': '9725e3a3-1c97-4787-9d05-ac4824426f8e',\n",
              "              'metadata': {'text': 'Inc., San Francisco, CA, USA. Piotr Indyk '\n",
              "                                   'and Rajeev Motwani. 1998. Approximate '\n",
              "                                   'Nearest Neighbors: Towards Removing the '\n",
              "                                   'Curse of Dimensionality. In Proceedings of '\n",
              "                                   'the Thirtieth Annual ACM Symposium on '\n",
              "                                   'Theory of Computing (Dallas, Texas, USA) '\n",
              "                                   '(STOC ’98). ACM, New York, NY, USA, '\n",
              "                                   '604-613. M Iwasaki. [n.d.]. '\n",
              "                                   '_https://github.com/yahoojapan/NGT/wiki '\n",
              "                                   'Masajiro Iwasaki and Daisuke Miyazaki. '\n",
              "                                   '2018. Optimization of Indexing Based on '\n",
              "                                   'k-Nearest Neighbor Graph for Proximity '\n",
              "                                   'Search in High-dimensional Data. Herve '\n",
              "                                   'Jegou,'},\n",
              "              'score': 0.721452296,\n",
              "              'values': []},\n",
              "             {'id': 'b97ca99c-6617-486d-a6df-5d93bab0d437',\n",
              "              'metadata': {'text': 'for nearest neighbors using a greedy '\n",
              "                                   'search algorithm. The greedy search '\n",
              "                                   'algorithm traverses the graph starting at '\n",
              "                                   'a designated navigating or start node s € '\n",
              "                                   'P. The search iterates by greedily walking '\n",
              "                                   'from the current node u to a node v € '\n",
              "                                   'Nout(u) that minimizes the distance to the '\n",
              "                                   'query, and terminates when it reaches a '\n",
              "                                   'locally-optimal node, say p*, that has the '\n",
              "                                   'property d(p*,q) < d(p,q) Vp € Nou(p*). '\n",
              "                                   'Greedy search cannot improve distance to '\n",
              "                                   'the query point by navigating out of p* '\n",
              "                                   'and returns it as the'},\n",
              "              'score': 0.708827853,\n",
              "              'values': []},\n",
              "             {'id': 'a43b7d16-8425-4583-8d29-5ef7015e51bc',\n",
              "              'metadata': {'text': 'the 24th International Conference on '\n",
              "                                   'Artificial Intelligence (Buenos Aires, '\n",
              "                                   'Argentina) (IJCAI’15). AAAI Press, '\n",
              "                                   '2248-2254. Header only C++/python library '\n",
              "                                   'for fast approximate nearest neighbors. '\n",
              "                                   '[n.d.]._ https://github.com/nmslib/hnswlib '\n",
              "                                   'Yongjoo Park, Michael Cafarella, and '\n",
              "                                   'Barzan Mozafari. 2015. NeighborSensitive '\n",
              "                                   'Hashing. Proc. VLDB Endow. 9, 3 (Nov. '\n",
              "                                   '2015), 144-155. https: '\n",
              "                                   '//doi.org/10.14778/2850583.2850589 Suhas '\n",
              "                                   'Jayaram Subramanya, Fnu Dewvrit, Rohan '\n",
              "                                   'Kadekodi, Ravishankar Krishnawamy, and '\n",
              "                                   'Harsha Vardhan'},\n",
              "              'score': 0.645047486,\n",
              "              'values': []},\n",
              "             {'id': '988260f4-48f9-4a5d-9089-ca21164c75c6',\n",
              "              'metadata': {'text': 'k-nearest neighbor graphs to solve nearest '\n",
              "                                   'neighbor searches,\" in Advances in Pattern '\n",
              "                                   'Recognition: Springer, 2010, pp. 270-280. '\n",
              "                                   'K. Aoyama, K. Saito, H. Sawada, and N. '\n",
              "                                   'Ueda, \"Fast approximate similarity search '\n",
              "                                   'based on degree-reduced neighborhood. '\n",
              "                                   'graphs,\" in Proceedings of the 17th ACM '\n",
              "                                   'SIGKDD international conference on '\n",
              "                                   'Knowledge discovery and data mining, 2011, '\n",
              "                                   'pp. 10551063: ACM. G. Ruiz, E. Chavez, M. '\n",
              "                                   'Graff, and E. S. Téllez, \"Finding Near '\n",
              "                                   'Neighbors Through Local Search,\" in '\n",
              "                                   'Similarity Search and'},\n",
              "              'score': 0.639513195,\n",
              "              'values': []},\n",
              "             {'id': '30c45da1-54f4-42f4-afa8-65db7f0e4605',\n",
              "              'metadata': {'text': '(it can be random or supplied by a '\n",
              "                                   'separate algorithm) and iteratively '\n",
              "                                   'traverse the graph. At each step of the '\n",
              "                                   'traversal the algorithm examines the '\n",
              "                                   'distances from a query to the neighbors of '\n",
              "                                   'a current base node and then selects as '\n",
              "                                   'the next base node the adjacent node that '\n",
              "                                   'minimizes the distance, while constantly '\n",
              "                                   'keeping track of the best discovered '\n",
              "                                   'neighbors. The search is terminated when '\n",
              "                                   'some stopping condition is met (e.g. the '\n",
              "                                   'number of distance calculations). Links to '\n",
              "                                   'the closest neighbors in a k-NN'},\n",
              "              'score': 0.62882036,\n",
              "              'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "issue_hybrid_query(query_sembedding, query_dembedding[0], 1.0, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "623df78c-e1db-440a-97fb-25d97e6678f0",
      "metadata": {
        "id": "623df78c-e1db-440a-97fb-25d97e6678f0"
      },
      "source": [
        "You can see the differences above: when we issue a purely semantic search, our search results are about what the idea of \"nearest neighbors\" is; in our keyword search, the vast majority of our search results are just exact-word matches for the tokens \"nearest\" and \"neighbors\". Most of them are just citations from the HNSW article's bibliography!\n",
        "\n",
        "Can we get the best of both worlds? In an ideal world, my search results would both tell me \"about\" the concept of nearest neighbors and contain things like citations that I could read more about later.\n",
        "\n",
        "Let's see if we can get a combination of semantic and keyword search by toggling our `alpha` value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19923ef-af08-41cb-976b-f93fd4e0148d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a19923ef-af08-41cb-976b-f93fd4e0148d",
        "outputId": "1613077e-3aa6-4c81-bed1-123e01fc2e52",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': '9725e3a3-1c97-4787-9d05-ac4824426f8e',\n",
              "              'metadata': {'text': 'Inc., San Francisco, CA, USA. Piotr Indyk '\n",
              "                                   'and Rajeev Motwani. 1998. Approximate '\n",
              "                                   'Nearest Neighbors: Towards Removing the '\n",
              "                                   'Curse of Dimensionality. In Proceedings of '\n",
              "                                   'the Thirtieth Annual ACM Symposium on '\n",
              "                                   'Theory of Computing (Dallas, Texas, USA) '\n",
              "                                   '(STOC ’98). ACM, New York, NY, USA, '\n",
              "                                   '604-613. M Iwasaki. [n.d.]. '\n",
              "                                   '_https://github.com/yahoojapan/NGT/wiki '\n",
              "                                   'Masajiro Iwasaki and Daisuke Miyazaki. '\n",
              "                                   '2018. Optimization of Indexing Based on '\n",
              "                                   'k-Nearest Neighbor Graph for Proximity '\n",
              "                                   'Search in High-dimensional Data. Herve '\n",
              "                                   'Jegou,'},\n",
              "              'score': 0.166820392,\n",
              "              'values': []},\n",
              "             {'id': '6282efd3-f064-43c7-a98b-ac2eee2f1c76',\n",
              "              'metadata': {'text': 'neighbors, the correcting term is likely '\n",
              "                                   'to be higher 0 Ts. L -0.3 -0.2 -0.1 0 0.1 '\n",
              "                                   '0.2 0.3 difference: estimator d(x,y) In '\n",
              "                                   'our experiments, we observe that the '\n",
              "                                   'correction returns inferior results on '\n",
              "                                   'average. Therefore, we advocate the use of '\n",
              "                                   'Equation 13 for the nearest neighbor '\n",
              "                                   'search. The corrected version is useful '\n",
              "                                   'only if we are interested in the distances '\n",
              "                                   'themselves. Approximate nearest neighbor '\n",
              "                                   'search with product quantizers is fast '\n",
              "                                   '(only m additions are required per '\n",
              "                                   'distance calculation) and reduces'},\n",
              "              'score': 0.163327545,\n",
              "              'values': []},\n",
              "             {'id': 'a295c4d8-29f2-43a1-8bb1-523c24ee5d65',\n",
              "              'metadata': {'text': 'to the closest neighbors in a k-NN graph '\n",
              "                                   'serve as a simple approximation of the '\n",
              "                                   'Delaunay graph  (a graph which guranties '\n",
              "                                   'that the result of a basic greedy graph '\n",
              "                                   'traversal is always the nearest neighbor). '\n",
              "                                   'Unfortunately, Delaunay graph cannot be '\n",
              "                                   'efficiently constructed without prior '\n",
              "                                   'information about the structure of a space '\n",
              "                                   ', but its approximation by the nearest '\n",
              "                                   'neighbors can be done by using only '\n",
              "                                   'distances between the stored elements. It '\n",
              "                                   'was shown that proximity graph approaches '\n",
              "                                   'with such approximation'},\n",
              "              'score': 0.1614151,\n",
              "              'values': []},\n",
              "             {'id': 'b97ca99c-6617-486d-a6df-5d93bab0d437',\n",
              "              'metadata': {'text': 'for nearest neighbors using a greedy '\n",
              "                                   'search algorithm. The greedy search '\n",
              "                                   'algorithm traverses the graph starting at '\n",
              "                                   'a designated navigating or start node s € '\n",
              "                                   'P. The search iterates by greedily walking '\n",
              "                                   'from the current node u to a node v € '\n",
              "                                   'Nout(u) that minimizes the distance to the '\n",
              "                                   'query, and terminates when it reaches a '\n",
              "                                   'locally-optimal node, say p*, that has the '\n",
              "                                   'property d(p*,q) < d(p,q) Vp € Nou(p*). '\n",
              "                                   'Greedy search cannot improve distance to '\n",
              "                                   'the query point by navigating out of p* '\n",
              "                                   'and returns it as the'},\n",
              "              'score': 0.156974688,\n",
              "              'values': []},\n",
              "             {'id': 'b6362e2e-9fc6-4044-a526-671ed19adbc3',\n",
              "              'metadata': {'text': 'overcome this issue by performing '\n",
              "                                   'approximate nearest neighbor (ANN) search. '\n",
              "                                   'The key idea This work was partly realized '\n",
              "                                   'as part of the Quaero Programme, funded by '\n",
              "                                   'OSEO, French State agency for innovation. '\n",
              "                                   'It was originally published as a technical '\n",
              "                                   'report  in August 2009. It is also related '\n",
              "                                   'to the work  on source coding for nearest '\n",
              "                                   'neighbor search. shared by these '\n",
              "                                   'algorithms is to find the NN with high '\n",
              "                                   'probability “only”, instead of probability '\n",
              "                                   '1. Most of the effort has been devoted to '\n",
              "                                   'the Euclidean'},\n",
              "              'score': 0.155648142,\n",
              "              'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "issue_hybrid_query(query_sembedding, query_dembedding[0], 0.2, 5)  # closer to 1.0 = closer to pure keyword search"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f0e73e1-4ae3-4237-91bc-cea84a810a72",
      "metadata": {
        "id": "6f0e73e1-4ae3-4237-91bc-cea84a810a72"
      },
      "source": [
        "Amazing! You can see that our first couple search results are not very different than our pure keyword search. But when you get further down the results list, you'll see that we get an equation we can use to calculate KNN. That's a bit more useful than #3 in our pure keyword search, which is a bibliography entry. That's likely because we have semantic search in there too -- Pinecone knows we want to know \"about\" KNN, so it fetches items with lots of domain-specific terms (keyword search), but also items that demonstrate the \"aboutness\" of KNN (semantic search).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95fec382-1f9d-4e23-abbe-9897a00d531c",
      "metadata": {
        "id": "95fec382-1f9d-4e23-abbe-9897a00d531c"
      },
      "source": [
        "# Let's take a closer look. For science!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b16ea1f-e70a-4c44-af0a-95666cd212d8",
      "metadata": {
        "id": "8b16ea1f-e70a-4c44-af0a-95666cd212d8"
      },
      "outputs": [],
      "source": [
        "pure_keyword = issue_hybrid_query(query_sembedding, query_dembedding[0], 1.0, 5)\n",
        "pure_semantic = issue_hybrid_query(query_sembedding, query_dembedding[0], 0.0, 5)\n",
        "hybrid_1 = issue_hybrid_query(query_sembedding, query_dembedding[0], 0.1, 5)\n",
        "hybrid_2 = issue_hybrid_query(query_sembedding, query_dembedding[0], 0.2, 5)\n",
        "hybrid_3 = issue_hybrid_query(query_sembedding, query_dembedding[0], 0.3, 5)\n",
        "hybrid_4 = issue_hybrid_query(query_sembedding, query_dembedding[0], 0.4, 5)\n",
        "hybrid_5 = issue_hybrid_query(query_sembedding, query_dembedding[0], 0.5, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de66f2e-7a86-4711-837b-8dfd19785e27",
      "metadata": {
        "id": "6de66f2e-7a86-4711-837b-8dfd19785e27",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Let's turn these all into dataframes and see the different rankings\n",
        "# Feel free to skip this part (it's just an interesting side journey)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.concat([\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'keyword') for i in pure_keyword.get('matches')]),\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'semantic') for i in pure_semantic.get('matches')]),\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'hybrid_1') for i in hybrid_1.get('matches')]),\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'hybrid_2') for i in hybrid_2.get('matches')]),\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'hybrid_3') for i in hybrid_3.get('matches')]),\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'hybrid_4') for i in hybrid_4.get('matches')]),\n",
        "    pd.DataFrame([(i['metadata']['text'], i['score'], 'hybrid_5') for i in hybrid_5.get('matches')]),\n",
        "]).rename(columns={0: 'document', 1: 'score', 2: 'search_type'})\n",
        "\n",
        "# Note: don't pay too much attention to the \"score\" column. This really only matters within the same type of search, for ranking docs.\n",
        "# Don't use it to compare *across* different search types (e.g. keyword search isn't inherently more relevant simply because it has higher\n",
        "# scores overall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9912ce6a-e3bf-48f1-9e51-65c8cc3d8691",
      "metadata": {
        "id": "9912ce6a-e3bf-48f1-9e51-65c8cc3d8691"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6cb84e-21b9-4cd0-b1f1-06c077ea58c0",
      "metadata": {
        "id": "eb6cb84e-21b9-4cd0-b1f1-06c077ea58c0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Let's give each document a label so that it's easier to see their ranking differences per search type\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['document_encoded'] = label_encoder.fit_transform(df['document'])\n",
        "\n",
        "df.head().sort_values(['document_encoded'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6945cec-025c-4425-831e-0aaeb4a83cf6",
      "metadata": {
        "id": "f6945cec-025c-4425-831e-0aaeb4a83cf6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for i, v in df.groupby(['search_type']):\n",
        "    print(v[['search_type', 'document_encoded', 'score']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b268e1e0-d59b-4d40-a19d-f084a8b108b9",
      "metadata": {
        "id": "b268e1e0-d59b-4d40-a19d-f084a8b108b9"
      },
      "source": [
        "Above, you can see the subtle ranking differences across each search type. For the most part, `document 8` is the top documents, except in `hybrid_1`, `hybrid_2` and `semantic`. In those two search types, `document 10` is the top document.\n",
        "\n",
        "It's up to you and your stakeholders to find the ideal `alpha` for your use case(s).\n",
        "\n",
        "Directly, for our use case, it seems anything >= `alpha=0.3` gets us similar results, so the impact of `alpha` is most discernable between `0.0-0.3`.\n",
        "\n",
        "Cool!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb6ece2-cb19-43c0-9ab5-e0c0c09b46a2",
      "metadata": {
        "editable": true,
        "id": "5bb6ece2-cb19-43c0-9ab5-e0c0c09b46a2",
        "tags": []
      },
      "source": [
        "# Incorporating GenAI\n",
        "\n",
        "Now, hybrid search is cool enough, but what if you don't want to spend time sifting through your index's search results? What if you just want a single answer to a query?\n",
        "\n",
        "That's where GenAI comes in.\n",
        "\n",
        "We will make a retrieval augmented generation (RAG) pipeline that will make this happen.\n",
        "\n",
        "Since large language models (LLMs) do not know a ton of specific information (they are trained on the general Internet), especially if the information is from PDFs that it would have to download to have access to (like what are in our index), we need to give it this information!\n",
        "\n",
        "We do this by first sending our query to our Pinecone index and grabbing some search  results. We then attach these search results to our original query and send *both* to the LLM. That way, the LLM both knows what we want to ask it & can pull from its general knowledge store *and* has a specialized knowledge store (our Pinecone search results so that it can get us extra specific information.\n",
        "\n",
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cefb103-621c-4a43-b4e6-caeec5dfccc1",
      "metadata": {
        "id": "9cefb103-621c-4a43-b4e6-caeec5dfccc1"
      },
      "outputs": [],
      "source": [
        "# Let's grab the textual metadata from our search results:\n",
        "\n",
        "hybrid_context = [i.get('metadata').get('text') for i in hybrid_3.get('matches')]\n",
        "pure_keyword_context = [i.get('metadata').get('text') for i in pure_keyword.get('matches')]\n",
        "pure_semantic_context = [i.get('metadata').get('text') for i in pure_semantic.get('matches')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11788caa-ea17-4678-93de-871f74d3057f",
      "metadata": {
        "id": "11788caa-ea17-4678-93de-871f74d3057f"
      },
      "outputs": [],
      "source": [
        "# We are then going to combine this \"context\" with our original query in a format that our LLM likes:\n",
        "\n",
        "hybrid_augmented_query = \"\\n\\n---\\n\\n\".join(hybrid_context)+\"\\n\\n-----\\n\\n\"+query\n",
        "pure_keyword_augmented_query = \"\\n\\n---\\n\\n\".join(pure_keyword_context)+\"\\n\\n-----\\n\\n\"+query\n",
        "pure_semantic_augmented_query = \"\\n\\n---\\n\\n\".join(pure_keyword_context)+\"\\n\\n-----\\n\\n\"+query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705cdd94-39ad-493e-b55b-12516b20ea1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "705cdd94-39ad-493e-b55b-12516b20ea1e",
        "outputId": "5deb46c6-e9ce-4d12-b3d1-854a32e464c5",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inc., San Francisco, CA, USA. Piotr Indyk and Rajeev Motwani. 1998. Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality. In Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing (Dallas, Texas, USA) (STOC ’98). ACM, New York, NY, USA, 604-613. M Iwasaki. [n.d.]. _https://github.com/yahoojapan/NGT/wiki Masajiro Iwasaki and Daisuke Miyazaki. 2018. Optimization of Indexing Based on k-Nearest Neighbor Graph for Proximity Search in High-dimensional Data. Herve Jegou,\n",
            "\n",
            "---\n",
            "\n",
            "for nearest neighbors using a greedy search algorithm. The greedy search algorithm traverses the graph starting at a designated navigating or start node s € P. The search iterates by greedily walking from the current node u to a node v € Nout(u) that minimizes the distance to the query, and terminates when it reaches a locally-optimal node, say p*, that has the property d(p*,q) < d(p,q) Vp € Nou(p*). Greedy search cannot improve distance to the query point by navigating out of p* and returns it as the\n",
            "\n",
            "---\n",
            "\n",
            "neighbors, the correcting term is likely to be higher 0 Ts. L -0.3 -0.2 -0.1 0 0.1 0.2 0.3 difference: estimator d(x,y) In our experiments, we observe that the correction returns inferior results on average. Therefore, we advocate the use of Equation 13 for the nearest neighbor search. The corrected version is useful only if we are interested in the distances themselves. Approximate nearest neighbor search with product quantizers is fast (only m additions are required per distance calculation) and reduces\n",
            "\n",
            "---\n",
            "\n",
            "k-nearest neighbor graphs to solve nearest neighbor searches,\" in Advances in Pattern Recognition: Springer, 2010, pp. 270-280. K. Aoyama, K. Saito, H. Sawada, and N. Ueda, \"Fast approximate similarity search based on degree-reduced neighborhood. graphs,\" in Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, 2011, pp. 10551063: ACM. G. Ruiz, E. Chavez, M. Graff, and E. S. Téllez, \"Finding Near Neighbors Through Local Search,\" in Similarity Search and\n",
            "\n",
            "---\n",
            "\n",
            "(it can be random or supplied by a separate algorithm) and iteratively traverse the graph. At each step of the traversal the algorithm examines the distances from a query to the neighbors of a current base node and then selects as the next base node the adjacent node that minimizes the distance, while constantly keeping track of the best discovered neighbors. The search is terminated when some stopping condition is met (e.g. the number of distance calculations). Links to the closest neighbors in a k-NN\n",
            "\n",
            "-----\n",
            "\n",
            "What are nearest neighbors?\n"
          ]
        }
      ],
      "source": [
        "print(hybrid_augmented_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "384afe12-83bf-4c10-baf0-0241ecd8132f",
      "metadata": {
        "id": "384afe12-83bf-4c10-baf0-0241ecd8132f"
      },
      "outputs": [],
      "source": [
        "# We are then going to give our LLM some instructions for how to act:\n",
        "\n",
        "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
        "user questions based on the information provided by the user above\n",
        "each question. If the information can not be found in the information\n",
        "provided by the user you truthfully say \"I don't know\".\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf840d48-be91-4dd3-b7bb-9d0556da0b80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf840d48-be91-4dd3-b7bb-9d0556da0b80",
        "outputId": "a65b5574-2b78-49cc-c06b-c9122c6e2874",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Nearest neighbors are a set of points in a data set that are closest to a specified point. In the context provided, they are used in certain algorithms to solve problems relating to pattern recognition or similarity search. Usually these are found by calculating the distance between the specified point and others, selecting the ones with the smallest distances.'"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now we query our LLM with our augmented query & our primer!\n",
        "\n",
        "# Our hybrid query:\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "hybrid_res = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": primer},\n",
        "        {\"role\": \"user\", \"content\": hybrid_augmented_query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "hybrid_res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a229cf-3b8c-4d75-b863-f6091c108811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43a229cf-3b8c-4d75-b863-f6091c108811",
        "outputId": "0954f5b2-f3fa-4318-ca33-b8a872a58303",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Nearest neighbors in the context given refer to a type of algorithm in data mining and statistics used for pattern recognition. It\\'s typically used in machine learning to categorize objects based on closest training examples in the feature space, hence the term \"nearest neighbors\". These algorithms work by finding a predetermined number of training samples closest in distance to a new point and predicting the label from them. The number of samples can be a user-defined constant (k-nearest neighbors), or vary based on the local density of points (radius-based neighbor learning).'"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Our pure_keyword query:\n",
        "\n",
        "pure_keyword_res = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": primer},\n",
        "        {\"role\": \"user\", \"content\": pure_keyword_augmented_query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "pure_keyword_res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c198628f-ff63-414e-bd90-eb2fdb07df47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c198628f-ff63-414e-bd90-eb2fdb07df47",
        "outputId": "d778a65d-14cc-4752-e989-2d0851e79900",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Nearest neighbors refers to a type of algorithm in the field of data mining and statistics, particularly used in pattern recognition. The algorithm works by finding the closest points (neighbors) to a designated start or query point in a data set. This technique is commonly used in machine learning for classification and regression.'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Our pure_semantic query:\n",
        "\n",
        "pure_semantic_res = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": primer},\n",
        "        {\"role\": \"user\", \"content\": pure_semantic_augmented_query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "pure_semantic_res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466f61d4-1896-4716-a8e4-b25a4eda97fe",
      "metadata": {
        "id": "466f61d4-1896-4716-a8e4-b25a4eda97fe"
      },
      "source": [
        "You can see subtle differences across the different results above. It's up to you and your stakeholders to figure out what type of search (semantic, keyword, hybrid) offers the most relevant information for your end users"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28051b6-219a-44bf-aee7-5894d6af600b",
      "metadata": {
        "id": "d28051b6-219a-44bf-aee7-5894d6af600b"
      },
      "source": [
        "# What if we take our our Pinecone vectors altogether??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6837f020-3147-4014-b31b-f0b070ae9a69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6837f020-3147-4014-b31b-f0b070ae9a69",
        "outputId": "ffbd78e1-3b06-493d-be79-9f81c3a63ad2",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The information provided does not specify what is meant by \"nearest neighbors.\" I don\\'t have enough context to provide an accurate answer.'"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What if we issue our original query without our Pinecone vectors as context?\n",
        "\n",
        "res = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": primer},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6943af-c430-4a5c-acd7-2a55f53a8f87",
      "metadata": {
        "id": "2b6943af-c430-4a5c-acd7-2a55f53a8f87"
      },
      "source": [
        "We can see that RAG really does have a huge impact! Without our PDFs, ChatGPT doesn't know much helpful detail at all! Nor can it give us bibliographic data for articles we might want to look up later!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc32f342-33ad-47cf-a11b-4b7981405b76",
      "metadata": {
        "id": "fc32f342-33ad-47cf-a11b-4b7981405b76",
        "scrolled": true
      },
      "source": [
        "# All finished!\n",
        "\n",
        "Check out [our documentation on hybrid search](https://docs.pinecone.io/docs/hybrid-search-and-sparse-vectors) and keep building awesome things!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02581d3f611c4d6695fdc5e80a6a2aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d8c818e1f544b54a4532b6e45dc558f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ede41088b81418b8f46393063355852": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46cb7f93a5b3418299de049a988f1ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0bdc65bb5ba4188a8d37bbf680c9a6b",
              "IPY_MODEL_95d42387ac474e2ca20c324354e7278a",
              "IPY_MODEL_ded84f36e8f448a288f9a6f66779dee1"
            ],
            "layout": "IPY_MODEL_ffd326f46dd649ec90f2a3fcce8e861b"
          }
        },
        "7b3a4f088c864ca089a073e7226f9683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "869e80bfc8de4f4d8a7760e950fc8bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d42387ac474e2ca20c324354e7278a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d8c818e1f544b54a4532b6e45dc558f",
            "max": 127531,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b3a4f088c864ca089a073e7226f9683",
            "value": 127531
          }
        },
        "c0bdc65bb5ba4188a8d37bbf680c9a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ede41088b81418b8f46393063355852",
            "placeholder": "​",
            "style": "IPY_MODEL_869e80bfc8de4f4d8a7760e950fc8bb1",
            "value": "100%"
          }
        },
        "ded84f36e8f448a288f9a6f66779dee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e165b164b89a4f64868c5aef9f3d9a4c",
            "placeholder": "​",
            "style": "IPY_MODEL_02581d3f611c4d6695fdc5e80a6a2aa5",
            "value": " 127531/127531 [00:16&lt;00:00, 9188.60it/s]"
          }
        },
        "e165b164b89a4f64868c5aef9f3d9a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd326f46dd649ec90f2a3fcce8e861b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}